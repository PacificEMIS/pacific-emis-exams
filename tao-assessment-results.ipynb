{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03840ac0-cf9c-44b4-aad1-cba586cb7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdfkit\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'path_to_your_file.csv'  # Replace with your actual file path\n",
    "\n",
    "local_path = os.path.abspath('/mnt/h/Development/Pacific EMIS/repositories-data/pacific-emis-exams/')\n",
    "filename = os.path.join(local_path, 'TAO/results_exports/delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365.csv')\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_data = pd.read_csv(filename)\n",
    "\n",
    "print('df_data preview')\n",
    "display(df_data[:3])\n",
    "\n",
    "print('df_date info')\n",
    "print(data.info())\n",
    "\n",
    "print('df_date columns')\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adf4d7-9d81-47db-a7b1-616d8eb72ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns containing 'SCORE' in their names but excluding 'MAXSCORE', 'SCORE_RATIO', 'SCORE_TOTAL', and 'SCORE_TOTAL_MAX'\n",
    "score_columns = [col for col in df_data_filled_missing.columns if 'SCORE' in col and all(exclusion not in col for exclusion in ['MAXSCORE', 'SCORE_RATIO', 'SCORE_TOTAL', 'SCORE_TOTAL_MAX'])]\n",
    "\n",
    "\n",
    "\n",
    "# Extract columns containing 'duration' in their names\n",
    "duration_columns = [col for col in df_data_filled_missing.columns if 'duration' in col]\n",
    "\n",
    "# Summary statistics for each score column\n",
    "score_statistics = df_data[score_columns].describe()\n",
    "score_statistics_filled_missing = df_data_filled_missing[score_columns].describe()\n",
    "\n",
    "# Display the statistics\n",
    "print(\"Summary Statistics for SCORE Columns (original):\")\n",
    "display(score_statistics)\n",
    "print(\"Summary Statistics for SCORE Columns (filled missing):\")\n",
    "display(score_statistics_filled_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c60b24-0e09-4784-b091-e67893ba3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df_data to work on\n",
    "df_data_filled_missing = df_data.copy()\n",
    "\n",
    "# Define the function to fill missing data\n",
    "def fill_missing_data(df, score_col):\n",
    "    item_prefix = score_col.replace('-SCORE', '')\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-MAXSCORE'] = 1\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-RESPONSE'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), score_col] = 0\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-completionStatus'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-duration'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-numAttempts'] = np.nan\n",
    "\n",
    "# Apply the function to each 'SCORE' column\n",
    "for score_col in score_columns:\n",
    "    fill_missing_data(df_data_filled_missing, score_col)\n",
    "\n",
    "# Calculate the total score for each participant as the sum of SCORE = 1 divided by the total number of items\n",
    "computed_scores = df_data_filled_missing[score_columns].sum(axis=1) / len(score_columns)\n",
    "# Identify the position to insert the new column\n",
    "score_ratio_columns = [col for col in df_data_filled_missing.columns if '-SCORE_RATIO' in col]\n",
    "if score_ratio_columns:\n",
    "    insert_position = df_data_filled_missing.columns.get_loc(score_ratio_columns[0]) + 1\n",
    "else:\n",
    "    insert_position = len(df_data_filled_missing.columns)\n",
    "\n",
    "# Insert the new column into the specified position\n",
    "df_data_filled_missing = pd.concat([\n",
    "    df_data_filled_missing.iloc[:, :insert_position],\n",
    "    pd.DataFrame({'Computed_Test_SCORE_RATIO': computed_scores}),\n",
    "    df_data_filled_missing.iloc[:, insert_position:]\n",
    "], axis=1)\n",
    "\n",
    "# Display the first few rows to verify the insertion\n",
    "df_data_filled_missing.head()\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_filename = os.path.join(local_path, 'TAO/results_exports/delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365-filled-missing.csv')\n",
    "df_data_filled_missing.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972afb53-9430-4384-a71c-ed64f76d9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each score column\n",
    "missing_values = df_data[score_columns].isnull().sum()\n",
    "\n",
    "print(\"\\nMissing Values in SCORE Columns (from original):\")\n",
    "print(missing_values)\n",
    "\n",
    "# Identify the unique identifier for users (e.g., email or name)\n",
    "# Assuming 'First Name', 'Last Name', and 'Mail' are the identifiers\n",
    "user_identifiers = ['First Name', 'Last Name', 'Mail']\n",
    "\n",
    "# Create a dictionary to store users who missed each item\n",
    "missing_items = {col: df_data[user_identifiers + [col]][df_data[col].isnull()] for col in score_columns}\n",
    "\n",
    "# Display the users who missed each item\n",
    "#for item, users in missing_items.items():\n",
    "#    print(f\"Users who missed {item}:\")\n",
    "#    print(users[user_identifiers])\n",
    "#    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93142d2d-d9eb-4728-be58-10c8b3ed23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of participants scoring 1 and 0 for each item\n",
    "score_1_counts = df_data_filled_missing[score_columns].apply(lambda x: (x == 1).sum())\n",
    "score_0_counts = df_data_filled_missing[score_columns].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Combine counts into a DataFrame and sort by score_1_counts\n",
    "score_counts = pd.DataFrame({'score_1_counts': score_1_counts, 'score_0_counts': score_0_counts})\n",
    "score_counts = score_counts.sort_values(by='score_1_counts', ascending=False)\n",
    "\n",
    "# Plot the number of participants scoring 1 and 0 for each item in groups of 10\n",
    "group_size = 10\n",
    "num_groups = (len(score_counts) + group_size - 1) // group_size  # Calculate the number of groups\n",
    "\n",
    "for i in range(num_groups):\n",
    "    start = i * group_size\n",
    "    end = start + group_size\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.bar(score_counts.index[start:end], score_counts['score_1_counts'][start:end], color='green', label='SCORE = 1')\n",
    "    plt.bar(score_counts.index[start:end], score_counts['score_0_counts'][start:end], bottom=score_counts['score_1_counts'][start:end], color='red', label='SCORE = 0')\n",
    "    plt.title(f'Number of Participants Scoring 1 and 0 for Items {start + 1} to {min(end, len(score_counts))}')\n",
    "    plt.xlabel('Item')\n",
    "    plt.ylabel('Number of Participants')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436363b-c5f3-4cd6-99f3-ecf137642e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for the report\n",
    "report_df = df_data_filled_missing[['First Name', 'Last Name', 'Mail', 'Computed_Test_SCORE_RATIO']]\n",
    "\n",
    "# Sort the DataFrame by the computed test score in descending order\n",
    "report_df = report_df.sort_values(by='Computed_Test_SCORE_RATIO', ascending=False)\n",
    "\n",
    "# Format the score as percentage using .loc to avoid the warning\n",
    "report_df.loc[:, 'Computed_Test_SCORE_RATIO'] = (report_df['Computed_Test_SCORE_RATIO']*100).map(\"{:.2f}%\".format)\n",
    "\n",
    "# Style the DataFrame for HTML output\n",
    "def color_score(val):\n",
    "    score = float(val[:-1])\n",
    "    color = 'green' if score >= 70.00 else 'red'\n",
    "    return f'color: {color}'\n",
    "\n",
    "styled_report = report_df.style.map(color_score, subset=['Computed_Test_SCORE_RATIO'])\n",
    "\n",
    "# Save the styled DataFrame as an HTML file\n",
    "html_filename = os.path.join(local_path, 'TAO/results_exports/delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365-report.html')\n",
    "excel_filename = os.path.join(local_path, 'TAO/results_exports/delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365-report.xlsx')\n",
    "pdf_filename = os.path.join(local_path, 'TAO/results_exports/delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365-report.pdf')\n",
    "\n",
    "html = styled_report.to_html()\n",
    "with open(html_filename, 'w') as f:\n",
    "    f.write(html)\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "report_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Convert the HTML report to PDF\n",
    "pdfkit.from_file(html_filename, pdf_filename )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
