{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03840ac0-cf9c-44b4-aad1-cba586cb7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdfkit\n",
    "import json\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "\n",
    "# Configuration (initial setup)\n",
    "with open('config.json', 'r') as file:\n",
    "     config = json.load(file)\n",
    "    \n",
    "tao_local_path = config['tao_local_path']\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'path_to_your_file.csv'  # Replace with your actual file path\n",
    "\n",
    "result_dir = os.path.join(tao_local_path, 'results_exports')\n",
    "\n",
    "# Choose with file to work with\n",
    "#result_filename = 'delivery_of_mathematics_practice_test_2020_v1_i16066499465949598_2024070317025365.csv'\n",
    "result_filename = 'delivery_of_english_language_arts_practice_test_2020_v1_i160664998645852_2024070317033875.xlsx'\n",
    "filename = os.path.join(result_dir, result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52866399-a466-4ac4-979f-8bdb3471e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_df(filename):\n",
    "    \"\"\"Loads an Excel filename to a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, required\n",
    "        The filename of the excel file to load\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    file_path = Path(filename)\n",
    "    file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "    if file_extension == 'xlsx':\n",
    "        df = pd.read_excel(filename, index_col=None, header=0, engine='openpyxl')\n",
    "    elif file_extension == 'xls':\n",
    "        df = pd.read_excel(filename, index_col=None, header=0)\n",
    "    elif file_extension == 'csv':\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    else:\n",
    "        raise Exception(\"File not supported\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_df_to_file(df, filename):\n",
    "    \"\"\"Saves an Pandas DataFrame to a file handling the file type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, required\n",
    "        The filename of the excel file to load\n",
    "    df : DataFrame, required\n",
    "        The Pandas DataFramw to save to file\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    file_path = Path(filename)\n",
    "    file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "    if file_extension == 'xlsx':\n",
    "        df.to_excel(filename, index=False)  # index=False to avoid saving the index as a column\n",
    "    elif file_extension == 'xls':\n",
    "        df.to_excel(filename, index=False)  # index=False to avoid saving the index as a column\n",
    "    elif file_extension == 'csv':\n",
    "        df.to_csv(filename, index=False)\n",
    "    else:\n",
    "        raise Exception(f\"File type {file_extension} not supported\")\n",
    "\n",
    "    print(f\"Saved file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d51d1-de12-48f1-a4db-0690306c7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Load the file into a DataFrame\n",
    "################################################################################\n",
    "df_data = load_excel_to_df(filename)\n",
    "\n",
    "print('df_data preview')\n",
    "display(df_data[:3])\n",
    "\n",
    "print('df_date info')\n",
    "print(df_data.info())\n",
    "\n",
    "print('df_date columns')\n",
    "print(list(df_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c60b24-0e09-4784-b091-e67893ba3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df_data to work on\n",
    "df_data_filled_missing = df_data.copy()\n",
    "\n",
    "# Extract columns containing 'SCORE' in their names but excluding 'MAXSCORE', 'SCORE_RATIO', 'SCORE_TOTAL', and 'SCORE_TOTAL_MAX'\n",
    "score_columns = [col for col in df_data_filled_missing.columns if 'SCORE' in col and all(exclusion not in col for exclusion in ['MAXSCORE', 'SCORE_RATIO', 'SCORE_TOTAL', 'SCORE_TOTAL_MAX'])]\n",
    "\n",
    "# Extract columns containing 'duration' in their names\n",
    "duration_columns = [col for col in df_data_filled_missing.columns if 'duration' in col]\n",
    "\n",
    "# Define the function to fill missing data\n",
    "def fill_missing_data(df, score_col):\n",
    "    item_prefix = score_col.replace('-SCORE', '')\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-MAXSCORE'] = 1\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-RESPONSE'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), score_col] = 0\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-completionStatus'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-duration'] = np.nan\n",
    "    df.loc[df[score_col].isnull(), f'{item_prefix}-numAttempts'] = np.nan\n",
    "\n",
    "# Apply the function to each 'SCORE' column\n",
    "for score_col in score_columns:\n",
    "    fill_missing_data(df_data_filled_missing, score_col)\n",
    "\n",
    "# Calculate the total score for each participant as the sum of SCORE = 1 divided by the total number of items\n",
    "computed_scores = df_data_filled_missing[score_columns].sum(axis=1) / len(score_columns)\n",
    "# Identify the position to insert the new column\n",
    "score_ratio_columns = [col for col in df_data_filled_missing.columns if '-SCORE_RATIO' in col]\n",
    "if score_ratio_columns:\n",
    "    insert_position = df_data_filled_missing.columns.get_loc(score_ratio_columns[0]) + 1\n",
    "else:\n",
    "    insert_position = len(df_data_filled_missing.columns)\n",
    "\n",
    "# Insert the new column into the specified position\n",
    "df_data_filled_missing = pd.concat([\n",
    "    df_data_filled_missing.iloc[:, :insert_position],\n",
    "    pd.DataFrame({'Computed_Test_SCORE_RATIO': computed_scores}),\n",
    "    df_data_filled_missing.iloc[:, insert_position:]\n",
    "], axis=1)\n",
    "\n",
    "# Display the first few rows to verify the insertion\n",
    "df_data_filled_missing.head()\n",
    "\n",
    "# Save the modified DataFrame to a new file\n",
    "output_filename = filename.split('.')[0]+'-filled-missing.'+filename.split('.')[1]\n",
    "save_df_to_file(df_data_filled_missing, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adf4d7-9d81-47db-a7b1-616d8eb72ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for each score column\n",
    "score_statistics = df_data[score_columns].describe()\n",
    "score_statistics_filled_missing = df_data_filled_missing[score_columns].describe()\n",
    "\n",
    "# Display the statistics\n",
    "print(\"Summary Statistics for SCORE Columns (original):\")\n",
    "display(score_statistics)\n",
    "print(\"Summary Statistics for SCORE Columns (filled missing):\")\n",
    "display(score_statistics_filled_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972afb53-9430-4384-a71c-ed64f76d9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each score column\n",
    "missing_values = df_data[score_columns].isnull().sum()\n",
    "\n",
    "print(\"\\nMissing Values in SCORE Columns (from original):\")\n",
    "print(missing_values)\n",
    "\n",
    "# Identify the unique identifier for users (e.g., email or name)\n",
    "# Assuming 'First Name', 'Last Name', and 'Mail' are the identifiers\n",
    "user_identifiers = ['First Name', 'Last Name', 'Mail']\n",
    "\n",
    "# Create a dictionary to store users who missed each item\n",
    "missing_items = {col: df_data[user_identifiers + [col]][df_data[col].isnull()] for col in score_columns}\n",
    "\n",
    "# Display the users who missed each item\n",
    "#for item, users in missing_items.items():\n",
    "#    print(f\"Users who missed {item}:\")\n",
    "#    print(users[user_identifiers])\n",
    "#    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93142d2d-d9eb-4728-be58-10c8b3ed23a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Simple plot of the data\n",
    "################################################################################\n",
    "\n",
    "# Count the number of participants scoring 1 and 0 for each item\n",
    "score_1_counts = df_data_filled_missing[score_columns].apply(lambda x: (x == 1).sum())\n",
    "score_0_counts = df_data_filled_missing[score_columns].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Combine counts into a DataFrame and sort by score_1_counts\n",
    "score_counts = pd.DataFrame({'score_1_counts': score_1_counts, 'score_0_counts': score_0_counts})\n",
    "score_counts = score_counts.sort_values(by='score_1_counts', ascending=False)\n",
    "\n",
    "# Plot the number of participants scoring 1 and 0 for each item in groups of 10\n",
    "group_size = 10\n",
    "num_groups = (len(score_counts) + group_size - 1) // group_size  # Calculate the number of groups\n",
    "\n",
    "for i in range(num_groups):\n",
    "    start = i * group_size\n",
    "    end = start + group_size\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.bar(score_counts.index[start:end], score_counts['score_1_counts'][start:end], color='green', label='SCORE = 1')\n",
    "    plt.bar(score_counts.index[start:end], score_counts['score_0_counts'][start:end], bottom=score_counts['score_1_counts'][start:end], color='red', label='SCORE = 0')\n",
    "    plt.title(f'Number of Participants Scoring 1 and 0 for Items {start + 1} to {min(end, len(score_counts))}')\n",
    "    plt.xlabel('Item')\n",
    "    plt.ylabel('Number of Participants')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436363b-c5f3-4cd6-99f3-ecf137642e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process simple reports\n",
    "################################################################################\n",
    "\n",
    "# Select relevant columns for the report\n",
    "report_df = df_data_filled_missing[['First Name', 'Last Name', 'Mail', 'Computed_Test_SCORE_RATIO']]\n",
    "\n",
    "# Sort the DataFrame by the computed test score in descending order\n",
    "report_df = report_df.sort_values(by='Computed_Test_SCORE_RATIO', ascending=False)\n",
    "\n",
    "# Format the score as percentage using .loc to avoid the warning\n",
    "report_df.loc[:, 'Computed_Test_SCORE_RATIO'] = (report_df['Computed_Test_SCORE_RATIO']*100).map(\"{:.2f}%\".format)\n",
    "\n",
    "display(report_df)\n",
    "\n",
    "# Style the DataFrame for HTML output\n",
    "def color_score(val):\n",
    "    score = float(val[:-1])\n",
    "    color = 'green' if score >= 70.00 else 'red'\n",
    "    return f'color: {color}'\n",
    "\n",
    "styled_report = report_df.style.map(color_score, subset=['Computed_Test_SCORE_RATIO'])\n",
    "\n",
    "# Save the styled DataFrame as an HTML file\n",
    "# Save the modified DataFrame to a new file\n",
    "\n",
    "html_filename = filename.split('.')[0]+'-report.html'\n",
    "excel_filename = filename.split('.')[0]+'-report.xlsx'\n",
    "pdf_filename = filename.split('.')[0]+'-report.pdf'\n",
    "\n",
    "html = styled_report.to_html()\n",
    "with open(html_filename, 'w') as f:\n",
    "    f.write(html)\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "save_df_to_file(report_df, excel_filename)\n",
    "\n",
    "# Convert the HTML report to PDF\n",
    "pdfkit.from_file(html_filename, pdf_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952933d-48bb-4d66-a418-4ad2e16546a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Calculate Cronbach's alpha\n",
    "################################################################################\n",
    "\n",
    "# Subset the data to include only the score columns\n",
    "scores_df = df_data_filled_missing[score_columns]\n",
    "\n",
    "# Calculate the number of items\n",
    "n_items = len(score_columns)\n",
    "print(f\"Number of items: {n_items}\")\n",
    "\n",
    "# Calculate the variance for each item\n",
    "item_variances = scores_df.var(axis=0, ddof=1)\n",
    "#print(f\"Item variances: {item_variances}\")\n",
    "print(f\"Sum of item variances: {item_variances.sum()}\")\n",
    "\n",
    "# Calculate the total score for each participant\n",
    "total_scores = scores_df.sum(axis=1)\n",
    "#print(f\"Total scores: {total_scores}\")\n",
    "\n",
    "# Calculate the variance of the total scores\n",
    "total_score_variance = total_scores.var(ddof=1)\n",
    "print(f\"Total scores variance: {total_score_variance}\")\n",
    "\n",
    "# Calculate Cronbach's alpha\n",
    "cronbach_alpha = (n_items / (n_items - 1)) * (1 - (item_variances.sum() / total_score_variance))\n",
    "\n",
    "print(f\"Cronbach's Alpha: {cronbach_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454991a8-471c-429e-8ee3-14d56a23bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Anonymize the data (useful for sharing with ChatGPT or others)\n",
    "################################################################################\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "df_anonymized = df_data_filled_missing.copy()\n",
    "\n",
    "# Function to generate a unique fictitious name\n",
    "def generate_fictitious_name(existing_names):\n",
    "    while True:\n",
    "        name = ''.join(random.choices(string.ascii_uppercase, k=5))\n",
    "        if name not in existing_names:\n",
    "            existing_names.add(name)\n",
    "            return name\n",
    "\n",
    "# Columns of interest to anonymize\n",
    "#'Test Taker', 'Login', 'First Name', 'Last Name', 'Mail',\n",
    "\n",
    "# Initialize sets to keep track of used fictitious names\n",
    "teacher_first_names = set()\n",
    "teacher_last_names = set()\n",
    "\n",
    "# Create mappings for student and teacher names\n",
    "teacher_first_name_mapping = {name: generate_fictitious_name(teacher_first_names) for name in df_anonymized['First Name'].unique()}\n",
    "teacher_last_name_mapping = {name: generate_fictitious_name(teacher_last_names) for name in df_anonymized['Last Name'].unique()}\n",
    "\n",
    "# Replace the names in the DataFrame\n",
    "df_anonymized['First Name'] = df_anonymized['First Name'].map(teacher_first_name_mapping)\n",
    "df_anonymized['Last Name'] = df_anonymized['Last Name'].map(teacher_last_name_mapping)\n",
    "df_anonymized['Test Taker'] = df_anonymized['First Name'] + ' ' + df_anonymized['Last Name']\n",
    "df_anonymized['Login'] = df_anonymized['First Name'] + df_anonymized['Last Name']\n",
    "df_anonymized['Mail'] = df_anonymized['Login'].str.lower() + '@example.com'\n",
    "\n",
    "df_anonymized.insert(0, 'row', range(len(df_anonymized)))\n",
    "\n",
    "# Display the first few rows to verify\n",
    "display(df_anonymized[:3])\n",
    "\n",
    "output_filename = filename.split('.')[0]+'-anonymized.'+filename.split('.')[1]\n",
    "save_df_to_file(df_anonymized, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe8b48-18b0-4f42-8b6a-2b6433f9766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Extract RESPONSEs and SCOREs to analyse them\n",
    "################################################################################\n",
    "\n",
    "# Drop all columns except 'row' and those matching 'RESPONSE' and 'SCORE' but not 'MAXSCORE'\n",
    "columns_to_keep = ['row'] + [col for col in df_anonymized.columns if ('RESPONSE' in col or 'SCORE' in col) and 'MAXSCORE' not in col]\n",
    "df_anonymized_filtered = df_anonymized[columns_to_keep]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "df_anonymized_filtered.head()\n",
    "\n",
    "# Select RESPONSE columns\n",
    "response_columns = [col for col in df_anonymized_filtered.columns if 'RESPONSE' in col]\n",
    "score_columns = [col for col in df_anonymized_filtered.columns if 'SCORE' in col]\n",
    "\n",
    "# Melt the DataFrame to unpivot the RESPONSE columns\n",
    "df_melted_response = df_anonymized_filtered.melt(id_vars=['row'], value_vars=response_columns, \n",
    "                                        var_name='item', value_name='result')\n",
    "df_melted_score = df_anonymized_filtered.melt(id_vars=['row'], value_vars=score_columns, \n",
    "                                        var_name='item', value_name='result')\n",
    "\n",
    "# Extract the actual item name from the column names\n",
    "df_melted_response['item'] = df_melted_response['item'].str.replace('-RESPONSE', '')\n",
    "df_melted_score['item'] = df_melted_score['item'].str.replace('-SCORE', '')\n",
    "\n",
    "# Sort the melted DataFrame by the 'row' column to keep the data for each participant closer\n",
    "df_melted_response = df_melted_response.sort_values(by=['row','item'])\n",
    "df_melted_score = df_melted_score.sort_values(by=['row','item'])\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "display(df_melted_response[:3])\n",
    "display(df_melted_score[:3])\n",
    "\n",
    "# Merge the melted RESPONSE and SCORE DataFrames on 'row' and 'item'\n",
    "df_final = df_melted_response.merge(df_melted_score, on=['row', 'item'], suffixes=('_response', '_score'))\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_final = df_final.rename(columns={'result_response': 'result', 'result_score': 'score'})\n",
    "\n",
    "# Display the first few rows of the final merged DataFrame\n",
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9e174-6c69-47dd-9068-d8dfeca37926",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Create a pivot table to summarize the scores\n",
    "# Used to compare with Excel pivot table from SQL processed data as verification\n",
    "################################################################################\n",
    "pivot_table = df_final.pivot_table(values='row', index='item', columns='score', aggfunc='count', fill_value=0)\n",
    "\n",
    "# Plot the pivot table with lighter colors and numbers on the bars\n",
    "ax = pivot_table.plot(kind='bar', stacked=True, figsize=(14, 8), colormap='Pastel1')\n",
    "plt.title('Summary of Scores by Item')\n",
    "plt.xlabel('Item')\n",
    "plt.ylabel('Count of Scores')\n",
    "plt.legend(title='Score')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# Add numbers on the bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97445a-df70-40df-bb6d-13463712ee03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
