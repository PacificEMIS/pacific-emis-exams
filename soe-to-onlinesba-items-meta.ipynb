{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# This notebook focuses on processing data from excel spreadsheet directly    #\n",
    "# into another format ready to load into OnlineSBA. It's focused on producing #\n",
    "# the items meta file                                                         #\n",
    "# This notebook should work on the same set of SOE assessment files as        #\n",
    "# the notebook soe-to-onlinesba for best results                              #\n",
    "#                                                                             #\n",
    "# It is also used to process raw SOE workbooks and flag data issues           #\n",
    "###############################################################################\n",
    "# Core stuff\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Data stuff\n",
    "import pandas as pd # Data analysis\n",
    "\n",
    "# Pretty printing stuff\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Configuration (initial setup)\n",
    "with open('config.json', 'r') as file:\n",
    "     config = json.load(file)\n",
    "test = config['test']\n",
    "country = config['country']\n",
    "cwd = os.getcwd()\n",
    "\n",
    "year_to_load = config['load_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_df(filename):\n",
    "    \"\"\"Loads an Excel filename to a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, required\n",
    "        The filename of the excel file to load\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    file_path = Path(filename)\n",
    "    file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "    if file_extension == 'xlsx':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0, engine='openpyxl')\n",
    "    elif file_extension == 'xls':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0)\n",
    "    elif file_extension == 'csv':\n",
    "        df_student_results = pd.read_csv(filename, index_col=None, header=0)\n",
    "    else:\n",
    "        raise Exception(\"File not supported\")\n",
    "\n",
    "    return df_student_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single SOE Assessment workbook (for testing,)\n",
    "# in particular the sheet with the raw data\n",
    "local_path = os.path.abspath('/mnt/h/Development/Pacific EMIS/repositories-data/pacific-emis-exams/')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2019/3GrEng2019/AllSchools_A03_2018-19_Results.xls')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2012/6grEng12/AllSchools_A06_2011-12_Results.xls')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2010/3GrMath/AllSchools_M03_2009-10_Results.xls')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2012/6GrEng2012/AllSchools_A06_2011-12_Results.xls')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2009/3GrKM2009/AllSchools_B03_2008-09_Results.xls')\n",
    "#filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2014/Gr6Eng2014/AllSchools_A06_2013-14_Results.xls')\n",
    "filename = os.path.join(local_path, 'RMI/MISAT/MISAT 2017/Gr3Eng2017/AllSchools_A03_2016-17_Results.xls')\n",
    "#filename = os.path.join(local_path, 'FSM/NMCT/NMCT 2021/AllSchools_R08_2020-21_Results.xls')\n",
    "\n",
    "df_student_results = load_excel_to_df(filename)\n",
    "print('df_student_results')\n",
    "display(df_student_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load all SOE Assessment workbook inside a directory\n",
    "# (~50 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "path = os.path.join(local_path, country+'/'+test+'/')\n",
    "\n",
    "if year_to_load != 'all':\n",
    "    path = os.path.join(path, year_to_load)\n",
    "    \n",
    "df_student_results_list = []\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        print('Loading into DataFrame:', filename)\n",
    "        try:\n",
    "            df_student_results_list.append(load_excel_to_df(filename))\n",
    "            #df_student_results_list[name] = load_excel_to_df(filename)\n",
    "        except:\n",
    "            print('Problem loading:', filename)\n",
    "            #print('Error was:', )            \n",
    "\n",
    "print('Completed loading excel files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 'Item_002_AS0302010102m_aaa'\n",
    "'_'.join(l.split('_', 2)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_consecutive(l):\n",
    "    \"\"\"Simply checks the items are all consecutive (e.g. Item_001, Item_002, etc)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l : List of items\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    True if the Items are numbered consecutively\n",
    "    \"\"\"    \n",
    "    l = [int(i.split('_')[1]) for i in l]\n",
    "    return l == list(range(min(l), max(l)+1))\n",
    "\n",
    "def has_duplicates(l):\n",
    "    \"\"\"Simply checks the items for any duplicates (e.g. Item_001_AS0302010102m_aaa and Item_002_AS0302010102m_aaa)\n",
    "    \n",
    "    Or is this a valid scenario?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l : List of items\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    True if the Items have duplicates metadata\n",
    "    \"\"\"    \n",
    "    l = ['_'.join(l.split('_', 2)[2:]) for i in l]\n",
    "    return len(l) == len(set(l))\n",
    "\n",
    "def create_series(df, accept_testid_alt: False, testing: False):\n",
    "    \"\"\"Create a pandas series containing meta data from a SOE Assessment responses raw DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame, required\n",
    "        The DataFrame to produce the Series\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.serries.Series\n",
    "    \"\"\"\n",
    "    # Create the Series for a particular exams\n",
    "    sy = df['SchoolYear'].iloc[0]\n",
    "    if not re.match('20\\d{2}-\\d{2}$', sy):\n",
    "        tqdm.write('Year format incorrect')\n",
    "    testid = df['TestID'].iloc[0]\n",
    "    testid_chars = list(testid)\n",
    "    testid_chars.insert(1,'S')\n",
    "    testid_alt = \"\".join(testid_chars)\n",
    "    testname = df['TestName'].iloc[0]\n",
    "    \n",
    "    if testid == 'A12' or testid == 'B12':\n",
    "        testid_alt = 'MS12'        \n",
    "    \n",
    "    # this also excludes items with _zzz\n",
    "    items = df.columns[df.columns.str.startswith('Item_') & ~df.columns.str.contains('_zzz')].tolist()\n",
    "    \n",
    "    if testing:\n",
    "        tqdm.write(\"testid: {}\".format(testid))\n",
    "        tqdm.write(\"testid_chars: {}\".format(testid_chars))\n",
    "        tqdm.write(\"testid_alt: {}\".format(testid_alt))\n",
    "        tqdm.write(\"testname: {}\".format(testname))\n",
    "        tqdm.write(\"items: {}\".format(items))\n",
    "        \n",
    "    # Check for inconsistencies in Test Items\n",
    "    # TestID must be the same as found in the Items (e.g. MS03 is in Item_055_MS0304010103h_ddd)\n",
    "    test_item_not_matching = False \n",
    "    test_missing_items = False\n",
    "    test_are_consecutive = False\n",
    "    test_has_duplicates = False\n",
    "    \n",
    "    # Test for items heads to match the expected Test ID\n",
    "    for i in items:\n",
    "        if accept_testid_alt:\n",
    "            if not testid in i and not testid_alt in i:\n",
    "                test_item_not_matching = True\n",
    "        else:\n",
    "            if not testid in i:\n",
    "                test_item_not_matching = True\n",
    "    \n",
    "    try:\n",
    "        if test_item_not_matching and testid != 'H08':\n",
    "            tqdm.write(\"Inconsistency detected in the test {} for year {}: Items test ID not matching test ID (i.e. The TestID says {} but items look like {})\".format(testname, sy, testid, items[0]))\n",
    "        if len(items) == 0:\n",
    "            test_missing_items = True\n",
    "            tqdm.write(\"Inconsistency detected in the test {} for year {}: There does not seem to be any items (e.g. Item_001_MS0301010101e_aaa, Item_002_MS0301010101e_aaa, Item_004_MS0301010101e_aaa missing Item_003)\".format(testname, sy))             \n",
    "        if not are_consecutive(items):\n",
    "            test_are_consecutive = True\n",
    "            tqdm.write(\"Inconsistency detected in the test {} for year {}: Items not correctly ordered (e.g. Item_001_MS0301010101e_aaa, Item_002_MS0301010101e_aaa, Item_004_MS0301010101e_aaa missing Item_003)\".format(testname, sy)) \n",
    "        if has_duplicates(items):\n",
    "            test_has_duplicates = True\n",
    "            tqdm.write(\"Inconsistency detected in the test {} for year {}: Items contain duplicated metadata(e.g. Item_001_MS0301010101e_aaa and Item_002_MS0301010101e_aaa have the same MS0301010101e_aaa)\".format(testname, sy))\n",
    "        #if test_inconsistencies:\n",
    "        #    tqdm.write(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    test_meta = [sy, test, testname, len(items), testid]\n",
    "    test_meta = test_meta + items\n",
    "    \n",
    "    s = pd.Series(test_meta)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single Series from SOE Assessment workbook (for testing,)\n",
    "#t = df_student_results\n",
    "#t.at[0,'SchoolYear'] = '2009-2010'\n",
    "s_exam_meta_data = create_series(df_student_results, accept_testid_alt=True, testing=True)\n",
    "print('s_exam_meta_data')\n",
    "display(s_exam_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a list of Series from all SOE Assessment workbooks (for testing,)\n",
    "# Working with all student exams files (~28 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "s_exam_meta_data_list = []\n",
    "\n",
    "for df in tqdm(df_student_results_list):\n",
    "    s_exam_meta_data_list.append(create_series(df, accept_testid_alt=True, testing=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assemble list of series into DataFrames based on the school year\n",
    "years = []\n",
    "df_exam_meta_data_list = []\n",
    "\n",
    "# First create a unique list of all the years for which we have exams data\n",
    "for s in s_exam_meta_data_list:\n",
    "    # Get the year\n",
    "    years.append(s[0])\n",
    "years = list(dict.fromkeys(years))\n",
    "print(years)\n",
    "\n",
    "# Create a dictionary of year to exams meta data DataFrame starting with empty DataFrames\n",
    "exam_meta_data_dict = {}\n",
    "for year in years:\n",
    "    exam_meta_data_dict[year] = pd.DataFrame()\n",
    "#exam_meta_data_dict\n",
    "#display(s_exam_meta_data_list)\n",
    "\n",
    "print('Processing exam meta data files')\n",
    "\n",
    "# Go through the list of series and populate their respective DataFrames\n",
    "for s in tqdm(s_exam_meta_data_list):\n",
    "    # e.g. exam_meta_data_dict['2019-20']\n",
    "    #exam_meta_data_dict[s[0]]\n",
    "    try:\n",
    "        #tqdm.write('Processing exam meta data for test id {} and year {}'.format(s[4], s[0]))\n",
    "        df1 = exam_meta_data_dict[s[0]]\n",
    "        df2 = pd.DataFrame()\n",
    "        df2[s[0]+'-'+s[4]] = s.reset_index(drop=True)   \n",
    "        df3 = df1.join(df2, how='outer')\n",
    "        exam_meta_data_dict[s[0]] = df3\n",
    "    except ValueError as e:\n",
    "        tqdm.write('File contains the wrong TestID. Fix file with TestID of {} to match Test Name of {} in year {}'.format(s[4], s[2], s[0]))        \n",
    "        tqdm.write('Error was {}'.format(e))\n",
    "    except Exception as e:\n",
    "        tqdm.write('Unknown error {}'.format(e))\n",
    "\n",
    "#exam_meta_data_dict['2011-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write processed data back into excel (or CSV directly)\n",
    "# Working with all student exams files\n",
    "\n",
    "for year, df in tqdm(exam_meta_data_dict.items()):\n",
    "    # Remove the year row? They don't seem to need it\n",
    "    df = df.drop([0])\n",
    "    try: \n",
    "        #exam_year_meta = 'data/'+country+''/onlinesba-load-files-xls/' + test + '-' + year + '.xlsx'        \n",
    "        exam_year_meta = os.path.join(local_path, country+'/onlinesba-load-files-csv/' + test + '-' + year + '.csv')\n",
    "        filename = os.path.join(cwd, exam_year_meta)        \n",
    "        df.to_csv(filename, index=False)\n",
    "        #with pd.ExcelWriter(filename) as writer:\n",
    "        #    # add DataFrames you want to write to Excel here\n",
    "        #    df.to_excel(writer, index=False, sheet_name='Sheet1', engine='openpyxl', header=False)\n",
    "        \n",
    "        #tqdm.write('Writing {}'.format(filename))\n",
    "    except TypeError as e:\n",
    "        tqdm.write('TypeError {}'.format(e))\n",
    "    except Exception as e:\n",
    "        tqdm.write('Unknown error {}'.format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-ocean",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
