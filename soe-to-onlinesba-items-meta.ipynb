{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# This notebook focuses on processing data from excel spreadsheet directly    #\n",
    "# into another format ready to load into OnlineSBA. It's focused on producing #\n",
    "# the items meta file                                                         #\n",
    "# This notebook should work on the same set of SOE assessment files as        #\n",
    "# the notebook soe-to-onlinesba for best results                              #\n",
    "###############################################################################\n",
    "# Core stuff\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Data stuff\n",
    "import pandas as pd # Data analysis\n",
    "\n",
    "# Initial setup\n",
    "country = 'RMI' # FSM\n",
    "test = 'MISAT' # NMCT\n",
    "\n",
    "# Configuration\n",
    "with open('config.json', 'r') as file:\n",
    "     config = json.load(file)\n",
    "\n",
    "year_to_load = config['load_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_df(filename):\n",
    "    \"\"\"Loads an Excel filename to a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, required\n",
    "        The filename of the excel file to load\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    file_path = Path(filename)\n",
    "    file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "    if file_extension == 'xlsx':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0, engine='openpyxl')\n",
    "    elif file_extension == 'xls':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0)\n",
    "    elif file_extension == 'csv':\n",
    "        df_student_results = pd.read_csv(filename, index_col=None, header=0)\n",
    "    else:\n",
    "        raise Exception(\"File not supported\")\n",
    "\n",
    "    return df_student_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single SOE Assessment workbook (for testing,)\n",
    "# in particular the sheet with the raw data\n",
    "cwd = os.getcwd()\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2019/3GrEng2019/AllSchools_A03_2018-19_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2012/6grEng12/AllSchools_A06_2011-12_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2010/3GrMath/AllSchools_M03_2009-10_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2012/6GrEng2012/AllSchools_A06_2011-12_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2009/3GrKM2009/AllSchools_B03_2008-09_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2014/Gr6Eng2014/AllSchools_A06_2013-14_Results.xls')\n",
    "filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2021/3GrEng2021/AllSchools_A03_2020-21_Results.xls')\n",
    "\n",
    "df_student_results = load_excel_to_df(filename)\n",
    "print('df_student_results')\n",
    "display(df_student_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load all SOE Assessment workbook inside a directory\n",
    "# (~50 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, 'data/'+country+'/'+test+'/')\n",
    "\n",
    "if year_to_load != 'all':\n",
    "    path = os.path.join(path, year_to_load)\n",
    "    \n",
    "df_student_results_list = []\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        print('Loading into DataFrame:', filename)\n",
    "        try:\n",
    "            df_student_results_list.append(load_excel_to_df(filename))\n",
    "            #df_student_results_list[name] = load_excel_to_df(filename)\n",
    "        except:\n",
    "            print('Problem loading:', filename)\n",
    "            #print('Error was:', )            \n",
    "\n",
    "print('Completed loading excel files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConsecutive(l):\n",
    "    \"\"\"Simply checks the items are all consecutive (e.g. Item_001, Item_002, etc)\n",
    "    Parameters\n",
    "    ----------\n",
    "    l : List of items\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    True if the Items are numbered consecutively\n",
    "    \"\"\"    \n",
    "    l = [int(i.split('_')[1]) for i in l]\n",
    "    return l == list(range(min(l), max(l)+1))\n",
    "\n",
    "def create_series(df, accept_testid_alt: False, testing: False):\n",
    "    \"\"\"Create a pandas series containing meta data from a SOE Assessment responses raw DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame, required\n",
    "        The DataFrame to produce the Series\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.serries.Series\n",
    "    \"\"\"\n",
    "    # Create the Series for a particular exams\n",
    "    sy = df['SchoolYear'].iloc[0]\n",
    "    if not re.match('20\\d{2}-\\d{2}$', sy):\n",
    "        print('Year format incorrect')\n",
    "    testid = df['TestID'].iloc[0]\n",
    "    testid_chars = list(testid)\n",
    "    testid_chars.insert(1,'S')\n",
    "    testid_alt = \"\".join(testid_chars)\n",
    "    testname = df['TestName'].iloc[0]\n",
    "    \n",
    "    # this also excludes items with _zzz\n",
    "    items = df.columns[df.columns.str.startswith('Item_') & ~df.columns.str.contains('_zzz')].tolist()\n",
    "    \n",
    "    # Check for inconsistencies in Test Items\n",
    "    # TestID must be the same as found in the Items (e.g. MS03 is in Item_055_MS0304010103h_ddd)\n",
    "    test_inconsistencies = False\n",
    "    test_item_not_matching = False \n",
    "    test_missing_items = False\n",
    "    \n",
    "    for i in items:\n",
    "        if accept_testid_alt:\n",
    "            if not testid in i and not testid_alt in i:\n",
    "                test_item_not_matching = True\n",
    "                test_inconsistencies = True\n",
    "        else:\n",
    "            if not testid in i:\n",
    "                test_item_not_matching = True\n",
    "                test_inconsistencies = True\n",
    "    \n",
    "    try:\n",
    "        if test_item_not_matching:\n",
    "            print(\"Inconsistency detected in the test {} for year {}: Items test ID not matching test ID (e.g. TestID M03 should have items like Item_055_M0304010103h_ddd)\".format(testname, sy))\n",
    "        if len(items) == 0:\n",
    "            test_missing_items = True\n",
    "            print(\"Inconsistency detected in the test {} for year {}: There does not seem to be any items (e.g. Item_001_MS0301010101e_aaa, Item_002_MS0301010101e_aaa, Item_004_MS0301010101e_aaa missing Item_003)\".format(testname, sy))             \n",
    "        if not checkConsecutive(items):\n",
    "            test_inconsistencies = True\n",
    "            print(\"Inconsistency detected in the test {} for year {}: Items not correctly ordered (e.g. Item_001_MS0301010101e_aaa, Item_002_MS0301010101e_aaa, Item_004_MS0301010101e_aaa missing Item_003)\".format(testname, sy)) \n",
    "        #if test_inconsistencies:\n",
    "        #    print(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    test_meta = [sy, test, testname, len(items), testid]\n",
    "    test_meta = test_meta + items\n",
    "    \n",
    "    s = pd.Series(test_meta)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'M10'\n",
    "l = list(s)\n",
    "l.insert(1,'S')\n",
    "\"\".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single Series from SOE Assessment workbook (for testing,)\n",
    "#t = df_student_results\n",
    "#t.at[0,'SchoolYear'] = '2009-2010'\n",
    "s_exam_meta_data = create_series(df_student_results, accept_testid_alt=True, testing=True)\n",
    "print('s_exam_meta_data')\n",
    "display(s_exam_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a list of Series from all SOE Assessment workbooks (for testing,)\n",
    "# Working with all student exams files (~28 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "s_exam_meta_data_list = []\n",
    "\n",
    "for df in df_student_results_list:\n",
    "    s_exam_meta_data_list.append(create_series(df, accept_testid_alt=True, testing=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assemble list of series into DataFrames based on the school year\n",
    "years = []\n",
    "df_exam_meta_data_list = []\n",
    "\n",
    "# First create a unique list of all the years for which we have exams data\n",
    "for s in s_exam_meta_data_list:\n",
    "    # Get the year\n",
    "    years.append(s[0])\n",
    "years = list(dict.fromkeys(years))\n",
    "print(years)\n",
    "\n",
    "# Create a dictionary of year to exams meta data DataFrame starting with empty DataFrames\n",
    "exam_meta_data_dict = {}\n",
    "for year in years:\n",
    "    exam_meta_data_dict[year] = pd.DataFrame()\n",
    "#exam_meta_data_dict\n",
    "#display(s_exam_meta_data_list)\n",
    "\n",
    "# Go through the list of series and populate their respective DataFrames\n",
    "for s in s_exam_meta_data_list:\n",
    "    # e.g. exam_meta_data_dict['2019-20']\n",
    "    #exam_meta_data_dict[s[0]]\n",
    "    try:\n",
    "        print('Processing exam meta data for test id {} and year {}'.format(s[4], s[0]))\n",
    "        df1 = exam_meta_data_dict[s[0]]\n",
    "        df2 = pd.DataFrame()\n",
    "        df2[s[0]+'-'+s[4]] = s.reset_index(drop=True)   \n",
    "        df3 = df1.join(df2, how='outer')\n",
    "        exam_meta_data_dict[s[0]] = df3\n",
    "    except ValueError as e:\n",
    "        print('File contains the wrong TestID. Fix file with TestID of {} to match Test Name of {} in year {}'.format(s[4], s[2], s[0]))        \n",
    "        print('Error was', e)\n",
    "    except:\n",
    "        print('Unknown error')\n",
    "\n",
    "#exam_meta_data_dict['2011-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write processed data back into excel (or CSV directly)\n",
    "# Working with all student exams files\n",
    "\n",
    "for year, df in exam_meta_data_dict.items():\n",
    "    # Remove the year row? They don't seem to need it\n",
    "    df = df.drop([0])\n",
    "    try: \n",
    "        #exam_year_meta = 'data/RMI/onlinesba-load-files-xls/' + test + '-' + year + '.xlsx'        \n",
    "        exam_year_meta = 'data/RMI/onlinesba-load-files-csv/' + test + '-' + year + '.csv'        \n",
    "        filename = os.path.join(cwd, exam_year_meta)\n",
    "        print('Writing', filename)\n",
    "        #with pd.ExcelWriter(filename) as writer:\n",
    "        #    # add DataFrames you want to write to Excel here\n",
    "        #    df.to_excel(writer, index=False, sheet_name='Sheet1', engine='openpyxl', header=False)\n",
    "        df.to_csv(filename, index=False)        \n",
    "    except TypeError as e:\n",
    "        print('Problem with a type, cannot generate filename')\n",
    "        print('Unknown error', e) \n",
    "    except:\n",
    "        print('Unknown error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-algeria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
