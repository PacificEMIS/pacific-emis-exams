{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# FSM data cleanup, processing notebook\n",
    "##########################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# To run this notebook or any cells of this notebook you would need both the exact same raw data spreadsheets\n",
    "# and to change the folder below and also the relative folders throughout the cells below\n",
    "fsmDir = '/Users/ghachey/Documents/JobsAndClients/Nuzusys/Clients/FederatedStatesOfMicronesiaPublicSchoolSystem/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Process population projections (2010 Census)\n",
    "##########################################################################################\n",
    "rawPopProjData = os.path.join(fsmDir,'background/PopulationProjection2010CensusProcessed.xlsx')\n",
    "outPopProjData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-population-10-year-projection-initial-data.xlsx')\n",
    "\n",
    "parse_cols = {\n",
    "    2010: \"A:C\",\n",
    "    2011: \"F:H\",\n",
    "    2012: \"K:M\",\n",
    "    2013: \"P:R\",\n",
    "    2014: \"U:W\",\n",
    "    2015: \"Z:AB\",\n",
    "    2016: \"AE:AG\",\n",
    "    2017: \"AJ:AL\",\n",
    "    2018: \"AO:AQ\"\n",
    "}\n",
    "\n",
    "sheets = {\n",
    "    \"Chuuk\": [1,\"CHK\"],\n",
    "    \"Pohnpei\": [3, \"PNI\"],\n",
    "    \"Yap\": [4, \"YAP\"],\n",
    "    \"Kosrae\": [2, \"KSA\"]\n",
    "}\n",
    "\n",
    "data = {}\n",
    "\n",
    "for key, value in parse_cols.items():\n",
    "    data[key] = pd.read_excel(rawPopProjData, sheetname=None, header=2, index_col=None,\n",
    "                              names=[\"popAge\",\"popM\",\"popF\"], parse_cols=value)\n",
    "\n",
    "popProjDF = pd.DataFrame()\n",
    "\n",
    "# for each year\n",
    "for year in data:\n",
    "    # for each state\n",
    "    for state in data[year]:\n",
    "        # I'm here got a DataFrame\n",
    "        #print(y,s)\n",
    "        df = data[year][state]\n",
    "        df['popmodCode'] = pd.Series([\"FSMNSO\"] * 76, index=df.index)\n",
    "        df['dID'] = pd.Series([sheets[state][0]] * 76, index=df.index)\n",
    "        df['elN'] = pd.Series([sheets[state][1]] * 76, index=df.index)\n",
    "        df['popYear'] = pd.Series([year] * 76, index=df.index)\n",
    "        popProjDF = popProjDF.append(df)\n",
    "\n",
    "popProjDF = popProjDF[[\"popmodCode\",\"popYear\",\"popAge\",\"popM\",\"popF\",\"dID\",\"elN\"]]\n",
    "popProjDF.loc[popProjDF.popAge == '        75+', 'popAge'] = 75\n",
    "popProjDF = popProjDF.round({'popM': 0, 'popF': 0})\n",
    "popProjDF\n",
    "\n",
    "# Experiment with population projection data for quick and dirty\n",
    "# quality test\n",
    "#data[2010][\"Pohnpei\"]\n",
    "#df2013 = popProjDF[popProjDF['popYear'] == 2013]\n",
    "#df2013.sum()\n",
    "\n",
    "# Write population data\n",
    "popProjDF.to_excel(outPopProjData, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     popmodCode  popYear  popAge        popM        popF  dID  elN\n",
      "0       FSMNSO2     2010       0  137.000000  130.000000  YAP  YAP\n",
      "1       FSMNSO2     2010       1  134.000000   99.000000  YAP  YAP\n",
      "2       FSMNSO2     2010       2  111.000000  110.000000  YAP  YAP\n",
      "3       FSMNSO2     2010       3   99.000000  123.000000  YAP  YAP\n",
      "4       FSMNSO2     2010       4  107.000000  110.000000  YAP  YAP\n",
      "5       FSMNSO2     2010       5  133.000000   98.000000  YAP  YAP\n",
      "6       FSMNSO2     2010       6  124.000000  117.000000  YAP  YAP\n",
      "7       FSMNSO2     2010       7  125.000000  127.000000  YAP  YAP\n",
      "8       FSMNSO2     2010       8  105.000000  117.000000  YAP  YAP\n",
      "9       FSMNSO2     2010       9  127.000000  119.000000  YAP  YAP\n",
      "10      FSMNSO2     2010      10  135.000000  126.000000  YAP  YAP\n",
      "11      FSMNSO2     2010      11  132.000000  124.000000  YAP  YAP\n",
      "12      FSMNSO2     2010      12  142.000000  129.000000  YAP  YAP\n",
      "13      FSMNSO2     2010      13  153.000000  131.000000  YAP  YAP\n",
      "14      FSMNSO2     2010      14  133.000000  124.000000  YAP  YAP\n",
      "15      FSMNSO2     2010      15  131.000000  105.000000  YAP  YAP\n",
      "16      FSMNSO2     2010      16  135.000000  114.000000  YAP  YAP\n",
      "17      FSMNSO2     2010      17  125.000000  135.000000  YAP  YAP\n",
      "18      FSMNSO2     2010      18  128.000000  111.000000  YAP  YAP\n",
      "19      FSMNSO2     2010      19   98.000000   99.000000  YAP  YAP\n",
      "20      FSMNSO2     2010      20   99.000000   91.000000  YAP  YAP\n",
      "21      FSMNSO2     2010      21   80.000000   74.000000  YAP  YAP\n",
      "22      FSMNSO2     2010      22   76.000000   82.000000  YAP  YAP\n",
      "23      FSMNSO2     2010      23   79.000000   80.000000  YAP  YAP\n",
      "24      FSMNSO2     2010      24   74.000000   88.000000  YAP  YAP\n",
      "25      FSMNSO2     2010      25   70.000000   80.000000  YAP  YAP\n",
      "26      FSMNSO2     2010      26   78.000000   83.000000  YAP  YAP\n",
      "27      FSMNSO2     2010      27   71.000000   79.000000  YAP  YAP\n",
      "28      FSMNSO2     2010      28   86.000000   98.000000  YAP  YAP\n",
      "29      FSMNSO2     2010      29   82.000000   78.000000  YAP  YAP\n",
      "...         ...      ...     ...         ...         ...  ...  ...\n",
      "4130    FSMNSO2     2025      35   35.926185   44.137885  KSA  KSA\n",
      "4131    FSMNSO2     2025      36   34.899723   33.873260  KSA  KSA\n",
      "4132    FSMNSO2     2025      37   30.793873   35.926185  KSA  KSA\n",
      "4133    FSMNSO2     2025      38   23.608636   24.635099  KSA  KSA\n",
      "4134    FSMNSO2     2025      39   34.899723   45.164347  KSA  KSA\n",
      "4135    FSMNSO2     2025      40   22.582174   34.899723  KSA  KSA\n",
      "4136    FSMNSO2     2025      41   37.979110   43.111422  KSA  KSA\n",
      "4137    FSMNSO2     2025      42   30.793873   35.926185  KSA  KSA\n",
      "4138    FSMNSO2     2025      43   33.873260   32.846798  KSA  KSA\n",
      "4139    FSMNSO2     2025      44   33.873260   40.032035  KSA  KSA\n",
      "4140    FSMNSO2     2025      45   48.243735   28.740948  KSA  KSA\n",
      "4141    FSMNSO2     2025      46   34.899723   31.820336  KSA  KSA\n",
      "4142    FSMNSO2     2025      47   45.164347   34.899723  KSA  KSA\n",
      "4143    FSMNSO2     2025      48   32.846798   33.873260  KSA  KSA\n",
      "4144    FSMNSO2     2025      49   45.164347   33.873260  KSA  KSA\n",
      "4145    FSMNSO2     2025      50   40.032035   26.688023  KSA  KSA\n",
      "4146    FSMNSO2     2025      51   42.084960   36.952648  KSA  KSA\n",
      "4147    FSMNSO2     2025      52   27.714486   42.084960  KSA  KSA\n",
      "4148    FSMNSO2     2025      53   32.846798   35.926185  KSA  KSA\n",
      "4149    FSMNSO2     2025      54   37.979110   43.111422  KSA  KSA\n",
      "4150    FSMNSO2     2025      55   37.979110   33.873260  KSA  KSA\n",
      "4151    FSMNSO2     2025      56   32.846798   21.555711  KSA  KSA\n",
      "4152    FSMNSO2     2025      57   22.582174   25.661561  KSA  KSA\n",
      "4153    FSMNSO2     2025      58   28.740948   25.661561  KSA  KSA\n",
      "4154    FSMNSO2     2025      59   29.767411   20.529249  KSA  KSA\n",
      "4155    FSMNSO2     2025      60   21.555711   22.582174  KSA  KSA\n",
      "4156    FSMNSO2     2025      61   25.661561   23.608636  KSA  KSA\n",
      "4157    FSMNSO2     2025      62   15.396937   18.476324  KSA  KSA\n",
      "4158    FSMNSO2     2025      63   19.502786   13.344012  KSA  KSA\n",
      "4159    FSMNSO2     2025      64   18.476324   12.317549  KSA  KSA\n",
      "\n",
      "[4160 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# Process population projections (2010 Census)\n",
    "##########################################################################################\n",
    "import numpy as np\n",
    "\n",
    "rawPopProjData3 = os.path.join(fsmDir,'background/Pop Projection (HIES 13-based)1.xlsx')\n",
    "outPopProjData3 = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-population-10-year-projection-initial-data3.xlsx')\n",
    "\n",
    "popProjDataDF3 = pd.read_excel(rawPopProjData3, sheet_name=None, header=[1,2], index_col=0)\n",
    "\n",
    "popProjDataDF3 = popProjDataDF3['HIES13 Pop Proj']\n",
    "\n",
    "# cleanup indices\n",
    "popProjDataDF3.rename(columns={\n",
    "    '2010A' : 2010,\n",
    "    '2013B': 2013,\n",
    "    '2014': 2014,\n",
    "    '2015': 2015,\n",
    "    '2016': 2016,\n",
    "    '2017': 2017,\n",
    "    '2018': 2018,\n",
    "    '2019': 2019,\n",
    "    '2020': 2020,\n",
    "    '2021': 2021,\n",
    "    '2022': 2022,\n",
    "    '2023': 2023,\n",
    "    '2024': 2024,\n",
    "    '2025': 2025\n",
    "}, inplace=True)\n",
    "popProjDataDF3.rename_axis(['Year', 'Gender'], axis=\"columns\", inplace=True)\n",
    "\n",
    "# group the DataFrame\n",
    "popProjDataDF3Total = popProjDataDF3[0:80]\n",
    "popProjDataDF3Yap = popProjDataDF3[80:160]\n",
    "popProjDataDF3Chuuk = popProjDataDF3[160:240]\n",
    "popProjDataDF3Pohnpei = popProjDataDF3[240:320]\n",
    "popProjDataDF3Kosrae = popProjDataDF3[320:400]\n",
    "\n",
    "# Add a region index\n",
    "popProjDataDF3Total = popProjDataDF3Total.assign(Region=pd.Series(np.nan))\n",
    "popProjDataDF3Total.set_index('Region', append=True, inplace=True)\n",
    "popProjDataDF3Yap = popProjDataDF3Yap.assign(Region='YAP')\n",
    "popProjDataDF3Yap.set_index('Region', append=True, inplace=True)\n",
    "popProjDataDF3Chuuk = popProjDataDF3Chuuk.assign(Region='CHK')\n",
    "popProjDataDF3Chuuk.set_index('Region', append=True, inplace=True)\n",
    "popProjDataDF3Pohnpei = popProjDataDF3Pohnpei.assign(Region='PNI')\n",
    "popProjDataDF3Pohnpei.set_index('Region', append=True, inplace=True)\n",
    "popProjDataDF3Kosrae = popProjDataDF3Kosrae.assign(Region='KSA')\n",
    "popProjDataDF3Kosrae.set_index('Region', append=True, inplace=True)\n",
    "\n",
    "# Put the DataFrames back together (don't really need the popProjDataDF3Total do we)\n",
    "popProjDataDF3 = pd.concat([popProjDataDF3Yap, popProjDataDF3Chuuk, popProjDataDF3Pohnpei, popProjDataDF3Kosrae])\n",
    "\n",
    "# Bit more indices cleanup and remove unnecessary rows\n",
    "popProjDataDF3.rename_axis(['Age', 'Region'], axis='index', inplace=True)\n",
    "popProjDataDF3 = popProjDataDF3.reorder_levels(['Region', 'Age'])\n",
    "#print(popProjDataDF3.index)\n",
    "\n",
    "popProjDataDF3 = popProjDataDF3.drop(index=[\n",
    "    'Yap','Chuuk','Pohnpei','Kosrae',\n",
    "    '0 to 4', '5 to 9', '10 to 14', '15 to 19', '20 to 24', '25 to 29', '30 to 34', '35 to 39', '40 to 44',\n",
    "    '45 to 49', '50 to 54', '55 to 59', '60 to 64', '65+'], level=1)\n",
    "\n",
    "popProjDataDF3 = popProjDataDF3.reset_index()\n",
    "popProjDataDF3['Age'] = popProjDataDF3['Age'].astype('int64')\n",
    "popProjDataDF3 = popProjDataDF3.set_index(['Region', 'Age'])\n",
    "popProjDataDF3.sort_index(axis=1, level=0, inplace=True)\n",
    "#print(popProjDataDF3.index)\n",
    "\n",
    "# Leave this rounding to excel\n",
    "#popProjDataDF3 = popProjDataDF3.apply(np.int64)\n",
    "#popProjDataDF3.info()\n",
    "\n",
    "# process and flatten index\n",
    "columns_mi = popProjDataDF3.columns\n",
    "ind = pd.Index([str(e[1]) + str(e[0]) for e in columns_mi.tolist()])\n",
    "ind\n",
    "popProjDataDF3.columns = ind\n",
    "# print(popProjDataDF3)\n",
    "# print(\"\\n\")\n",
    "\n",
    "# Set index as a column for use with wide_to_long\n",
    "popProjDataDF3[\"id\"] = popProjDataDF3.index\n",
    "# print(popProjDataDF3.head(2))\n",
    "# print(\"\\n\")\n",
    "\n",
    "popProjDataDF3 = pd.wide_to_long(popProjDataDF3, [\"Female\", \"Male\", \"Total\"], i=\"id\", j=\"popYear\")\n",
    "# cleanup indexes (move year to column, change back tuple Index into MultiIndex)\n",
    "popProjDataDF3.reset_index(level='popYear', inplace=True)\n",
    "popProjDataDF3.index = pd.MultiIndex.from_tuples(popProjDataDF3.index, names=['Region', 'Age'])\n",
    "popProjDataDF3.reset_index(inplace=True)\n",
    "\n",
    "# Final rename and missing columns\n",
    "popProjDataDF3.rename(columns={'Female': 'popF', 'Male': 'popM', 'Region': 'dID', 'Age': 'popAge'}, inplace=True)\n",
    "popProjDataDF3['elN'] = popProjDataDF3['dID']\n",
    "popProjDataDF3 = popProjDataDF3.drop(['Total'], 1)\n",
    "popProjDataDF3['popmodCode']  = 'FSMNSO2'\n",
    "order_cols = ['popmodCode','popYear','popAge','popM','popF','dID','elN']\n",
    "popProjDataDF3 = popProjDataDF3[order_cols]\n",
    "\n",
    "print(popProjDataDF3)\n",
    "\n",
    "# Write population data\n",
    "popProjDataDF3.to_excel(outPopProjData3, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Used in previous code, no longer needed as it was done already and saved in spreadsheet,\n",
    "# skip to next cell for short\n",
    "##########################################################################################\n",
    "\n",
    "# rawSchoolsExtraData = os.path.join(fsmDir,'background/All_FSM_Schools.xlsx')\n",
    "# rawInitialSchoolsData= os.path.join(fsmDir,'background/fsm-schools-with-raw-from-andrew-and-weison.xlsx')\n",
    "# outInitialSchoolsTyposManualData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-initial-lookups-anomalies-manual.xlsx')\n",
    "# outInitialSchoolsTyposData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-initial-lookups-anomalies.xlsx')\n",
    "# outSchoolsLookup = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-lookups.xlsx')\n",
    "\n",
    "\n",
    "# # Prepare schools helpers lookups. This is meant to assign the correct schools from badly entered data in various spreadsheets, etc.\n",
    "# #schoolsLookupDF = pd.read_excel(outEnrolmentTransitData, sheetname=\"cleanMergedSchoolsLeftJoinDF\", header=0, parse_cols=\"A,B\")\n",
    "# schoolsLookupDF = pd.read_excel(rawInitialSchoolsData, sheetname=\"Schools\", header=0, parse_cols=\"A,B\")\n",
    "# schoolsLookupTyposFromEnrolmentsDF = pd.read_excel(outInitialSchoolsTyposManualData, sheetname=\"FromEnrolments\", header=0, parse_cols=\"A,B\")\n",
    "# schoolsLookupTyposFromTeachersDF = pd.read_excel(outInitialSchoolsTyposManualData, sheetname=\"FromTeachers\", header=0, parse_cols=\"A,B\")\n",
    "# schoolsLookupTyposFromTeachersDF = schoolsLookupTyposFromTeachersDF.rename(columns = {'RawSchools': 'schName','SchNoMappingCompleteMe': 'schNo'})\n",
    "# schoolsLookupTyposFromAccreditationsDF = pd.read_excel(outInitialSchoolsTyposManualData, sheetname=\"FromAccreditations\", header=0, parse_cols=\"A,B\")\n",
    "# schoolsLookupTyposFromAccreditationsDF = schoolsLookupTyposFromAccreditationsDF.rename(columns = {'RawSchools': 'schName','SchNoMappingCompleteMe': 'schNo'})\n",
    "# # remove duplicates\n",
    "# schoolsLookupTyposFromTeachersDF.drop_duplicates(['schName','schNo'], inplace=True)\n",
    "# schoolsLookupTyposFromAccreditationsDF.drop_duplicates(['schName','schNo'], inplace=True)\n",
    "\n",
    "# # Add the typos constructed lookups containing to new manually fixed schools lookup\n",
    "# schoolsLookupDF = schoolsLookupDF.append(schoolsLookupTyposFromEnrolmentsDF)\n",
    "# schoolsLookupDF = schoolsLookupDF.append(schoolsLookupTyposFromTeachersDF)\n",
    "# schoolsLookupDF = schoolsLookupDF.append(schoolsLookupTyposFromAccreditationsDF)\n",
    "# schoolsLookupDF.drop_duplicates(['schName'], inplace=True)\n",
    "# # remove the ones without an key (NaN means they have a typo of some sort)\n",
    "# schoolsLookupDF = schoolsLookupDF.dropna()\n",
    "# print('schoolsLookupDF:')\n",
    "# print(schoolsLookupDF)\n",
    "\n",
    "# # Final dataset containing a correct school ID for each school names in various\n",
    "# # spreadsheets including all the ones with typos and differently spelled\n",
    "# schoolsLookup = schoolsLookupDF.set_index('schName').to_dict()['schNo']\n",
    "# schoolsLookupByName = {y:x for x,y in schoolsLookup.items()}\n",
    "# print('schoolsLookup:')\n",
    "# print(schoolsLookup)\n",
    "\n",
    "# # Writing data to sheets\n",
    "# writer = pd.ExcelWriter(outSchoolsLookup)\n",
    "# schoolsLookupDF.to_excel(writer, sheet_name='SchoolsLookups', index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Create a comprehensive school lookup map with both old and new school ID\n",
    "##########################################################################################\n",
    "\n",
    "# Starting point of the old lookup containing inconsistencies from\n",
    "# teacher, accreditation and enrollment raw data\n",
    "oldSchoolLookupData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-lookups-old.xlsx')\n",
    "oldSchoolLookupDataDF = pd.read_excel(oldSchoolLookupData, header=0)\n",
    "oldSchoolLookupDataDF.insert(1,'newSchNo',None)\n",
    "print(oldSchoolLookupDataDF[:3])\n",
    "\n",
    "# Now new mappings from Weison/Eugene\n",
    "newSchoolIDLookupRawData = os.path.join(fsmDir,'background/2017 UpdateSchool_Code with old Codes.xlsx')\n",
    "\n",
    "newSchoolIDLookupDict = {}\n",
    "parse_cols = {\n",
    "    'chuuk': \"A:C\",\n",
    "    'yap': \"F:H\",\n",
    "    'pohnpei': \"K:M\",\n",
    "    'kosrae': \"P:R\",\n",
    "}\n",
    "\n",
    "for key, value in parse_cols.items():\n",
    "    newSchoolIDLookupDict[key] = pd.read_excel(newSchoolIDLookupRawData, header=1, index_col=None,\n",
    "                              names=[\"schName\",\"newSchNo\",\"schNo\"], parse_cols=value)\n",
    "\n",
    "newSchoolIDLookupDataDF = pd.concat(newSchoolIDLookupDict)\n",
    "newSchoolIDLookupDataDF = newSchoolIDLookupDataDF.dropna(axis='index', how='any')\n",
    "newSchoolIDLookupDataDF = newSchoolIDLookupDataDF.reset_index(drop=True)\n",
    "newSchoolIDLookupDataDF\n",
    "\n",
    "# Fill old mapping with new school ID\n",
    "oldToNewDict = pd.Series(newSchoolIDLookupDataDF.newSchNo.values,index=newSchoolIDLookupDataDF.schNo).to_dict()\n",
    "oldSchoolLookupDataDF.newSchNo = oldSchoolLookupDataDF.newSchNo.fillna(oldSchoolLookupDataDF.schNo.map(oldToNewDict))\n",
    "print(oldSchoolLookupDataDF[:3])\n",
    "\n",
    "\n",
    "# Combined all mapping together\n",
    "schoolLookupMappingDF = oldSchoolLookupDataDF.append(newSchoolIDLookupDataDF,ignore_index=True)\n",
    "schoolLookupMappingDF\n",
    "\n",
    "schoolsLookup = schoolLookupMappingDF.set_index('schName').to_dict()['newSchNo']\n",
    "schoolsLookupByName = {y:x for x,y in schoolsLookup.items()}\n",
    "print('schoolsLookup:')\n",
    "print(schoolsLookup)\n",
    "\n",
    "# Write school lookup mapping for later use (i.e. processing enrollments, teachers, accredication raw data)\n",
    "newSchoolLookupData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-lookups.xlsx')\n",
    "schoolLookupMappingDF.to_excel(newSchoolLookupData, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Get some offical lookups for use in various data processing throughout cells\n",
    "##########################################################################################\n",
    "\n",
    "rawFSMLookups = os.path.join(fsmDir,'project-life-cycle/design-phase/PineapplesLookups-FSM.xlsx')\n",
    "\n",
    "authoritiesLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"Authorities\", skiprows=38, parse_cols=\"A,B\")\n",
    "authoritiesLookups = authoritiesLookupsDF.set_index('authName').to_dict()['authCode']\n",
    "authoritiesByNameLookups = authoritiesLookupsDF.set_index('authCode').to_dict()['authName']\n",
    "print('authoritiesLookupsDF:')\n",
    "print(authoritiesLookupsDF.head(15))\n",
    "\n",
    "gradeLevelsLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"lkpLevels\", skiprows=44, parse_cols=\"A,B\")\n",
    "print('gradeLevelsLookupsDF:')\n",
    "print(gradeLevelsLookupsDF.head(5))\n",
    "\n",
    "electLLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"lkpElectorateL\", skiprows=85, parse_cols=\"A,B\")\n",
    "print('electLLookupsDF:')\n",
    "print(electLLookupsDF.head(5))\n",
    "\n",
    "electNLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"lkpElectorateN\", skiprows=36, parse_cols=\"A,B\")\n",
    "print('electNLookupsDF:')\n",
    "print(electNLookupsDF.head(5))\n",
    "\n",
    "# islands and municipalities\n",
    "islandsLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"Islands\", skiprows=94, parse_cols=\"A,B\")\n",
    "print('islandsLookupsDF:')\n",
    "print(islandsLookupsDF.head(5))\n",
    "islandsLookup = islandsLookupsDF.set_index('iName').to_dict()['iCode']\n",
    "islandsLookupByName = {y:x for x,y in islandsLookup.items()}\n",
    "print('islandsLookup:')\n",
    "print(islandsLookup)\n",
    "\n",
    "\n",
    "teacherRoleLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"lkpTeacherRole\", skiprows=116, parse_cols=\"A,B\")\n",
    "teacherRoleLookups = teacherRoleLookupsDF.set_index('codeDescription').to_dict()['codeCode']\n",
    "teacherRoleByNameLookups = teacherRoleLookupsDF.set_index('codeCode').to_dict()['codeDescription']\n",
    "print('teacherRoleLookupsDF:')\n",
    "print(teacherRoleLookupsDF.head(5))\n",
    "\n",
    "teacherQualLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"lkpTeacherQual\", skiprows=55, parse_cols=\"A,B\")\n",
    "print('teacherQualLookupsDF:')\n",
    "print(teacherQualLookupsDF.head(5))\n",
    "\n",
    "roleGradesLookupsDF = pd.read_excel(rawFSMLookups, sheetname=\"RoleGrades\", skiprows=82, parse_cols=\"A,C\")\n",
    "roleGradesLookups = roleGradesLookupsDF.set_index('roleCode').to_dict()['rgCode']\n",
    "print('roleGradesLookupsDF:')\n",
    "print(roleGradesLookupsDF.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process schools data\n",
    "################################################################################\n",
    "\n",
    "rawSchoolsData = os.path.join(fsmDir,'background/schools-cleaned-from-raw-data.xlsx')\n",
    "schoolsOrderedDictDF = pd.read_excel(rawSchoolsData, sheetname=['Chuuk','Yap','Pohnpei','Kosrae'], header=0)\n",
    "schoolsDF = pd.concat([schoolsOrderedDictDF['Chuuk'],schoolsOrderedDictDF['Yap'],schoolsOrderedDictDF['Pohnpei'],schoolsOrderedDictDF['Kosrae']])\n",
    "schoolsDF = schoolsDF.reset_index(drop=True)\n",
    "\n",
    "# Drop columns with lesser quality data, bad data or uneeded data\n",
    "schoolsDF = schoolsDF.drop(['schAuth','schElectL','Location','Region/Zone/Municipality','School Type','School Level','Enrollment'], 1)\n",
    "\n",
    "# Map authorities to their codes\n",
    "schoolsDF = schoolsDF.replace(to_replace={'Authority':authoritiesLookups})\n",
    "schoolsDF = schoolsDF.rename(columns = {'Authority': 'schAuth'})\n",
    "\n",
    "# Map Islands/Municipality (i.e. iCode) to their codes\n",
    "schoolsDF = schoolsDF.replace(to_replace={'iCode':islandsLookup})\n",
    "\n",
    "# Use 'IslandsOrElectorate' to infer Local electorate (i.e. schElectL)\n",
    "def assignElectLOrNull(x):\n",
    "    # will get iCode another way\n",
    "    # if x in islandsLookupsDF['iName'].values:        \n",
    "    #     # return the iCode\n",
    "    #     return islandsLookupsDF[islandsLookupsDF['iName'] == x]['iCode'].values[0]\n",
    "    if x in electLLookupsDF['codeDescription'].values:\n",
    "        # return the codeCode\n",
    "        return electLLookupsDF[electLLookupsDF['codeDescription'] == x]['codeCode'].values[0]\n",
    "    else:\n",
    "        return 'NULL'\n",
    "\n",
    "schoolsDF = schoolsDF.assign(schElectL = schoolsDF['IslandsOrElectorate'])\n",
    "schoolsDF['schElectL'] = schoolsDF['schElectL'].apply(assignElectLOrNull)\n",
    "schoolsDF = schoolsDF.drop(['IslandsOrElectorate'], 1)\n",
    "\n",
    "# Put NULL for all missing values\n",
    "schoolsDF = schoolsDF.fillna('NULL')\n",
    "\n",
    "# Set registration date for all schools to 1 Jan 1970 for now\n",
    "from datetime import date\n",
    "schoolsDF = schoolsDF.assign(schRegStatusDate=date(1970,1,1))\n",
    "\n",
    "# Replace all NULL with 0 in schClosed and replace 1 with 2016 (assumed year school closed)\n",
    "schoolsDF.loc[schoolsDF.schClosed == 'NULL', 'schClosed'] = 0\n",
    "schoolsDF.loc[schoolsDF.schClosed == 1, 'schClosed'] = 2016\n",
    "\n",
    "# Handle any school name with ' in it.\n",
    "schoolsDF['schName'] = schoolsDF['schName'].str.replace(\"'\",\"''\")\n",
    "\n",
    "print('schoolsDF:')\n",
    "print(schoolsDF.head(5))\n",
    "\n",
    "# Writing data to sheets\n",
    "outSchoolsInitialData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-initial-data.xlsx')\n",
    "writer = pd.ExcelWriter(outSchoolsInitialData)\n",
    "schoolsDF.to_excel(writer, sheet_name='Schools', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Prepare student enrolments auxiliary raw data\n",
    "# Also get all schools to identify typos and associate with correct school (in other cell)\n",
    "# And some grade level data processing too\n",
    "################################################################################\n",
    "\n",
    "rawCombinedData = os.path.join(fsmDir,'background/CombinedData.xlsx')\n",
    "\n",
    "# Read the whole Student Roster in\n",
    "rawRosterDF = pd.read_excel(rawCombinedData, sheetname=\"CombinedStudents\", header=0, index_col=None, parse_cols=\"A,C,I,J,M,N,P,S,T,U,X\")\n",
    "print(\"rawRosterDF: \")\n",
    "print(rawRosterDF.head(1))\n",
    "\n",
    "# Prepare grade levels helper lookup (from student roster)\n",
    "uniqueLevelsInStudentRoster = rawRosterDF['Grade Level'].unique()\n",
    "uniqueLevelsInStudentRosterDF = pd.DataFrame(uniqueLevelsInStudentRoster)\n",
    "uniqueLevelsInStudentRosterDF = uniqueLevelsInStudentRosterDF.rename(columns = {0: 'codeDescription'})\n",
    "uniqueLevelsInStudentRosterDF = uniqueLevelsInStudentRosterDF.assign(codeCode=pd.Series(['GK','G1','G2','G3','G4','G5','G6',\n",
    "                                                                                         'G7','G8','G9','G10','G11','G12',\n",
    "                                                                                         'G4','GK']).values)\n",
    "print('uniqueLevelsInStudentRosterDF: ')\n",
    "print(uniqueLevelsInStudentRosterDF)\n",
    "\n",
    "levelsLookup = uniqueLevelsInStudentRosterDF.set_index('codeDescription').to_dict()['codeCode']\n",
    "print('levelsLookup:')\n",
    "print(levelsLookup)\n",
    "\n",
    "# Get unique survey years and gender for observation\n",
    "uniqueSurveyYears = rawRosterDF['SchoolYear'].unique()\n",
    "print(\"uniqueSurveyYears: \",)\n",
    "print(uniqueSurveyYears)\n",
    "\n",
    "uniqueGender = rawRosterDF['Gender'].unique()\n",
    "print(\"uniqueGender: \")\n",
    "print(uniqueGender)\n",
    "\n",
    "uniqueRepeat = rawRosterDF['Repeat Previous Year Grade'].unique()\n",
    "print(\"uniqueRepeat: \")\n",
    "print(uniqueRepeat)\n",
    "\n",
    "uniqueTrin = rawRosterDF['Transferred From which school'].unique()\n",
    "print(\"uniqueTrin: \")\n",
    "print(uniqueTrin)\n",
    "\n",
    "uniqueTrout = rawRosterDF['Transferred TO which school'].unique()\n",
    "print(\"uniqueTrout: \")\n",
    "print(uniqueTrout)\n",
    "\n",
    "uniqueDropout = rawRosterDF['Drop-Out'].unique()\n",
    "print(\"uniqueDropout: \")\n",
    "print(uniqueDropout)\n",
    "\n",
    "\n",
    "uniqueSchoolsInStudentRoster = rawRosterDF['School Name'].unique()\n",
    "uniqueSchoolsInStudentRosterDF = pd.DataFrame(uniqueSchoolsInStudentRoster)\n",
    "uniqueSchoolsInStudentRosterDF = uniqueSchoolsInStudentRosterDF.rename(columns = {0: 'schName'})\n",
    "uniqueSchoolsInStudentRosterDF\n",
    "\n",
    "cleanMergedSchoolsRightJoinDF = pd.merge(schoolsDF, uniqueSchoolsInStudentRosterDF, on='schName', how='right')\n",
    "cleanMergedSchoolsLeftJoinDF = pd.merge(schoolsDF, uniqueSchoolsInStudentRosterDF, on='schName', how='left')\n",
    "cleanMergedSchoolsRightJoinDF\n",
    "\n",
    "\n",
    "# Writing data to sheets\n",
    "# writer = pd.ExcelWriter(outEnrolmentTransitData)\n",
    "# writer.save()\n",
    "# schoolsDF.to_excel(writer, sheet_name='Schools Lookups', index=False)\n",
    "# cleanMergedSchoolsRightJoinDF.to_excel(writer, sheet_name='cleanMergedSchoolsLeftJoinDF', index=False)\n",
    "# #cleanMergedSchoolsLeftJoinDF.to_excel(writer, sheet_name='cleanMergedSchoolsRightJoinDF', index=False)\n",
    "# writer.save()\n",
    "\n",
    "# Some pre-processing data cleanup\n",
    "\n",
    "# Clean repeater, transfers in/out, dropouts\n",
    "repeatLookup = {\n",
    "    'No': 'No',\n",
    "    'Yes': 'Yes',\n",
    "    'NO': 'No',\n",
    "    'YES': 'Yes',\n",
    "    'yes': 'Yes',\n",
    "    'Missing': 'No',\n",
    "    ' ': 'No'\n",
    "}\n",
    "\n",
    "repeat = rawRosterDF['Repeat Previous Year Grade'].map(repeatLookup)\n",
    "#trin = rawRosterDF['Transferred From which school'].map(trinLookup)\n",
    "#trout = rawRosterDF['Transferred TO which school'].map(troutLookup)\n",
    "#dropout = rawRosterDF['Drop-Out'].map(dropoutLookup)\n",
    "rawRosterDF = rawRosterDF.assign(repeat=repeat)\n",
    "\n",
    "# Clean grade levels and age\n",
    "rawRosterDF = rawRosterDF.replace(to_replace={'Grade Level':levelsLookup})\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'Grade Level': 'enLevel'})\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'Age as of September 30 of that School Year': 'enAge'})\n",
    "\n",
    "# Clean schools\n",
    "rawRosterDF = rawRosterDF.replace(to_replace={'School Name':schoolsLookup})\n",
    "closedSchools = ['Kanifay ECE Center', 'Colonia ECE Center', 'Mizpah Christian High School', 'Mizpah High', 'Rumung Elementary School',\n",
    "                 'Nukaf Elem/Sapota Paata Elem']\n",
    "rawRosterDF = rawRosterDF[~rawRosterDF['School Name'].isin(closedSchools)]\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'School Name': 'schNo'})\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'Full Name': 'Name'})\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'Date of Birth': 'DoB'})\n",
    "\n",
    "# Remove student with unknown DoB and Age\n",
    "rawRosterDF = rawRosterDF[~(rawRosterDF['DoB'] == 'Unknown')]\n",
    "\n",
    "# Clean survey years and genders\n",
    "surveyYearsLookup = {\n",
    "    'SY2016-2017': 2016,\n",
    "    'SY2015-2016': 2015,\n",
    "    'SY2014-2015': 2014,\n",
    "    'SY2013-2014': 2013,\n",
    "    'SY2012-2013': 2012\n",
    "}\n",
    "gendersLookup = {\n",
    "    'male': 'M',\n",
    "    'female': 'F',\n",
    "    'MAle': 'M',\n",
    "    'MALE': 'M',\n",
    "    'Female': 'F',\n",
    "    'Male': 'M',\n",
    "}\n",
    "rawRosterDF = rawRosterDF.replace(to_replace={'SchoolYear':surveyYearsLookup, 'Gender':gendersLookup})\n",
    "rawRosterDF = rawRosterDF.rename(columns = {'SchoolYear': 'svyYear'})\n",
    "print('rawRosterDF:')\n",
    "print(rawRosterDF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process repeaters\n",
    "################################################################################\n",
    "\n",
    "outPupilTableData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-enrollment-pupil-table-initial-data.xlsx')\n",
    "\n",
    "# Get all raw repeat data\n",
    "rawRepeatDF = rawRosterDF[rawRosterDF['repeat'] == 'Yes']\n",
    "rawRepeatDF = rawRepeatDF.drop(['Name','DoB','Repeat Previous Year Grade','Transferred From which school','Transferred TO which school','Drop-Out'],1)\n",
    "# Add ssID using schoolSurveyLookup\n",
    "rawRepeatDF['ssIDTemp'] = rawRepeatDF['svyYear'].map(str) + rawRepeatDF['schNo']\n",
    "rawRepeatDF['ssID'] = rawRepeatDF['ssIDTemp'].map(schoolSurveyLookup)\n",
    "print(\"rawRepeatDF: \")\n",
    "print(rawRepeatDF.head(3))\n",
    "\n",
    "# Prepare a pupiltable dataframe prefilled with all known values\n",
    "# 'ssID','ptCode','ptAge','ptLevel','ptPage','ptRow','ptCol','ptM','ptF','ptSum','ptTableDef','ptTable'\n",
    "# Note: only the necessary columns are included\n",
    "pupilTableColumns = ['ssID','ptCode','ptAge','ptLevel','ptM','ptF']\n",
    "pupilTableDF = pd.DataFrame(columns=pupilTableColumns)\n",
    "pupilTableDF = rawRepeatDF.drop_duplicates(subset=['svyYear','schNo','enAge','enLevel'])\n",
    "pupilTableDF = pupilTableDF.assign(ptM=0,ptF=0,ptCode='REP')\n",
    "pupilTableDF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"pupilTableDF Empty: \")\n",
    "print(pupilTableDF.head(3))\n",
    "\n",
    "# # Test grabbing one of the repeater record\n",
    "# df = rawRosterDF[(rawRosterDF['svyYear'] == 2016) &\n",
    "#                  (rawRosterDF['schNo'] == 'CHK002') &\n",
    "#                  (rawRosterDF['enAge'] == 7) &\n",
    "#                  (rawRosterDF['enLevel'] == 'G1')]\n",
    "# print(\"df: \")\n",
    "# print(df)\n",
    "\n",
    "# Fill up the dataframe with pupiltable data\n",
    "for repeater in rawRepeatDF.itertuples(): # .iterrows():\n",
    "    #print(repeater)\n",
    "\n",
    "    # What pupiltable record is this repeater to update\n",
    "    pupilTableRecord = pupilTableDF[(pupilTableDF['svyYear'] == repeater.svyYear) &\n",
    "                                    (pupilTableDF['schNo'] == repeater.schNo) &\n",
    "                                    (pupilTableDF['enAge'] == repeater.enAge) &\n",
    "                                    (pupilTableDF['enLevel'] == repeater.enLevel)]\n",
    "\n",
    "    try: \n",
    "        if repeater.Gender == 'M':\n",
    "            pupilTableDF.iloc[pupilTableRecord.index, pupilTableDF.columns.get_loc('ptM')] = pupilTableDF.iloc[pupilTableRecord.index, pupilTableDF.columns.get_loc('ptM')] + 1\n",
    "        elif repeater.Gender == 'F':\n",
    "            pupilTableDF.iloc[pupilTableRecord.index, pupilTableDF.columns.get_loc('ptF')] = pupilTableDF.iloc[pupilTableRecord.index, pupilTableDF.columns.get_loc('ptF')] + 1\n",
    "    except IndexError:\n",
    "        print(pupilTableDF)\n",
    "        print(\"Index at fault: \", pupilTableRecord.index)\n",
    "\n",
    "# Make more consistent with pupiltable\n",
    "pupilTableDF = pupilTableDF.drop(['svyYear','schNo','Gender','repeat','ssIDTemp'], 1)\n",
    "pupilTableDF = pupilTableDF.rename(columns = {'enAge': 'ptAge', 'enLevel': 'ptLevel'})\n",
    "        \n",
    "print(\"pupilTableDF: \")\n",
    "print(pupilTableDF.head(3))\n",
    "\n",
    "# # Writing data to sheets\n",
    "writer = pd.ExcelWriter(outPupilTableData)\n",
    "pupilTableDF.to_excel(writer, sheet_name='PupilTableRepeaters', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process enrollment data\n",
    "# NOTE: Long to process: executed in 13m 48s on MacBook Pro, 2.9 GHz Intel Core i7, 16 GB 2133 MHz LPDDR3)\n",
    "################################################################################\n",
    "\n",
    "outEnrolmentTransitData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-enrollment-initial-transit-data.xlsx')\n",
    "\n",
    "# svyYear, schNo, Name, Gender, DoB, enAge, enLevel  \n",
    "enrolmentColumns = ['svyYear','schNo','enAge','enLevel','enM','enF']\n",
    "rawEnrolmentDF = pd.DataFrame(columns=enrolmentColumns)\n",
    "rawEnrolmentDF\n",
    "\n",
    "# df = rawRosterDF[(rawRosterDF['svyYear'] == 2016) &\n",
    "#                         (rawRosterDF['schNo'] == 'CHK175') &\n",
    "#                         (rawRosterDF['enAge'] == 6) &\n",
    "#                         (rawRosterDF['enLevel'] == 'GK')]\n",
    "\n",
    "# Work on small sample to get this working first\n",
    "rawRosterCleanedSampleDF = rawRosterDF #[:1000]\n",
    "\n",
    "rawEnrolmentDF = rawRosterCleanedSampleDF.drop_duplicates(subset=['svyYear','schNo','enAge','enLevel'])\n",
    "rawEnrolmentDF = rawEnrolmentDF.drop(['Name','Gender','DoB'], 1)\n",
    "rawEnrolmentDF = rawEnrolmentDF.assign(enM=0,enF=0)\n",
    "rawEnrolmentDF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"rawEnrolmentDF Empty: \")\n",
    "print(rawEnrolmentDF)\n",
    "print(\"rawRosterCleanedSampleDF: \")\n",
    "print(rawRosterCleanedSampleDF)\n",
    "\n",
    "# # Check if record exist and if not create it.\n",
    "for student in rawRosterCleanedSampleDF.itertuples(): # .iterrows():\n",
    "    #print(student)\n",
    "\n",
    "    # What enrolment record is this student to update\n",
    "    enrolRecord = rawEnrolmentDF[(rawEnrolmentDF['svyYear'] == student.svyYear) &\n",
    "                              (rawEnrolmentDF['schNo'] == student.schNo) &\n",
    "                              (rawEnrolmentDF['enAge'] == student.enAge) &\n",
    "                              (rawEnrolmentDF['enLevel'] == student.enLevel)]\n",
    "\n",
    "    try: \n",
    "        if student.Gender == 'M':\n",
    "            rawEnrolmentDF.iloc[enrolRecord.index, rawEnrolmentDF.columns.get_loc('enM')] = rawEnrolmentDF.iloc[enrolRecord.index, rawEnrolmentDF.columns.get_loc('enM')] + 1\n",
    "        elif student.Gender == 'F':\n",
    "            rawEnrolmentDF.iloc[enrolRecord.index, rawEnrolmentDF.columns.get_loc('enF')] = rawEnrolmentDF.iloc[enrolRecord.index, rawEnrolmentDF.columns.get_loc('enF')] + 1\n",
    "    except IndexError:\n",
    "        print(rawEnrolmentDF)\n",
    "        print(\"Index at fault: \", enrolRecord.index)\n",
    "\n",
    "#rawEnrolmentDF = pd.read_excel(outEnrolmentTransitData, sheetname=\"EnrolmentsRaw\", header=0, parse_cols=\"A:F\")\n",
    "rawEnrolmentDF = rawEnrolmentDF[(rawEnrolmentDF['enAge'] != -195) &\n",
    "                                (rawEnrolmentDF['enAge'] != -1) &\n",
    "                                (rawEnrolmentDF['enAge'] != 0) &\n",
    "                                (~rawEnrolmentDF['enAge'].isnull())]\n",
    "print(\"Uniques age values: \", rawEnrolmentDF['enAge'].unique())\n",
    "\n",
    "# Drop some data which I may need to come back to later\n",
    "rawEnrolmentDF = rawEnrolmentDF.drop(['Repeat Previous Year Grade','Transferred From which school','Transferred TO which school','Drop-Out','repeat'], 1)\n",
    "\n",
    "# Writing enrolment data to sheets\n",
    "writer = pd.ExcelWriter(outEnrolmentTransitData)\n",
    "rawEnrolmentDF.to_excel(writer, sheet_name='EnrolmentsRaw', index=False)\n",
    "writer.save()\n",
    "\n",
    "print(\"rawEnrolmentDF: \")\n",
    "print(rawEnrolmentDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process School Surveys\n",
    "################################################################################\n",
    "\n",
    "outInitialSchoolSurveysData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schoolsurveys-initial-data.xlsx')\n",
    "\n",
    "schoolTypesLookup = schoolsDF.set_index('schNo').to_dict()['schType']\n",
    "\n",
    "rawEnrolmentDF = pd.read_excel(outEnrolmentTransitData, sheetname=\"EnrolmentsRaw\", header=0, parse_cols=\"A:F\")\n",
    "schoolSurveyDF = rawEnrolmentDF.drop(['enAge','enLevel'], 1)\n",
    "schoolSurveyDF = schoolSurveyDF.groupby(['svyYear','schNo'], as_index=False).sum()\n",
    "schoolSurveyDF = schoolSurveyDF.rename(columns = {'enF': 'ssEnrolF', 'enM': 'ssEnrolM'})\n",
    "schoolSurveyDF = schoolSurveyDF.assign(ssEnrol = lambda x: x.ssEnrolF + x.ssEnrolM)\n",
    "schoolSurveyDF.insert(0,'ssID',range(1,len(schoolSurveyDF.index)+1))\n",
    "\n",
    "schoolSurveyDF['ssSchType'] = schoolSurveyDF['schNo'].map(schoolTypesLookup)\n",
    "print(\"schoolSurveyDF: \")\n",
    "print(schoolSurveyDF.head(3))\n",
    "\n",
    "# Writing SchoolSurveys data to sheets\n",
    "writer = pd.ExcelWriter(outInitialSchoolSurveysData)\n",
    "schoolSurveyDF.to_excel(writer, sheet_name='SchoolSurveys', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process final Enrolments ['ssID', 'enAge', 'enLevel', 'enM', 'enF']\n",
    "################################################################################\n",
    "\n",
    "outEnrolmentData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-enrollment-initial-data.xlsx')\n",
    "\n",
    "schoolSurveyDF['ssIDTemp'] = schoolSurveyDF['svyYear'].map(str) + schoolSurveyDF['schNo']\n",
    "schoolSurveyLookup = schoolSurveyDF.set_index(['ssIDTemp']).to_dict()['ssID']\n",
    "print(\"schoolSurveyLookup: \")\n",
    "print(rschoolSurveyLookup.head(3))\n",
    "\n",
    "\n",
    "enrolmentsDF = rawEnrolmentDF\n",
    "enrolmentsDF['ssIDTemp'] = enrolmentsDF['svyYear'].map(str) + enrolmentsDF['schNo']\n",
    "enrolmentsDF['ssID'] = enrolmentsDF['ssIDTemp'].map(schoolSurveyLookup)\n",
    "enrolmentsDF = enrolmentsDF.drop(['svyYear','schNo','ssIDTemp'], 1)\n",
    "\n",
    "order_cols = ['ssID', 'enAge', 'enLevel', 'enM', 'enF']\n",
    "enrolmentsDF = enrolmentsDF[order_cols]\n",
    "\n",
    "print(\"rawEnrolment: \")\n",
    "print(rawEnrolmentDF.head(3))\n",
    "print(\"schoolSurveyDF: \")\n",
    "print(schoolSurveyDF.head(3))\n",
    "print(\"enrolments: \")\n",
    "print(enrolmentsDF)\n",
    "\n",
    "# Writing Enrolments data to sheets\n",
    "writer = pd.ExcelWriter(outEnrolmentData)\n",
    "enrolmentsDF.to_excel(writer, sheet_name='Enrolments', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process accreditation data\n",
    "################################################################################\n",
    "\n",
    "rawAccreditationData = os.path.join(fsmDir,'background/AccreditationData_2017.xlsx')\n",
    "outAccreditationData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-schools-accreditation-initial-data.xlsx')\n",
    "\n",
    "rawAccreditationDataDF = pd.read_excel(rawAccreditationData, sheetname=\"UpdatedSheet\", header=1)\n",
    "\n",
    "# Remove all records where no school inspection exists for now\n",
    "rawAccreditationDataDF = rawAccreditationDataDF[~rawAccreditationDataDF['L1'].isnull()]\n",
    "\n",
    "rawAccreditationDataDF['Year'].fillna(value=2016,inplace=True)\n",
    "\n",
    "schoolWithExistingLookup = list(schoolsLookup.keys())\n",
    "schoolWithExistingLookup.sort()\n",
    "rawUniqueSchoolNamesFromAccreditation = list(rawAccreditationDataDF['School Name'].unique())\n",
    "rawUniqueSchoolNamesFromAccreditation.pop()\n",
    "rawUniqueSchoolNamesFromAccreditation.sort()\n",
    "print('schoolWithExistingLookup: ', schoolWithExistingLookup[:3])\n",
    "print('rawUniqueSchoolNamesFromAccreditation: ', rawUniqueSchoolNamesFromAccreditation[:3])\n",
    "# set(rawUniqueSchoolNames).difference(schoolWithExistingLookup)\n",
    "\n",
    "# No longer needed, I have a comprehensive mapping of school names with anomalies\n",
    "# # First cleanup schools from raw accreditation data (to be fixed manually and re-entered into the schoolsLookup in other cell)\n",
    "# uniqueSchoolsFromRawAccreditationDF = pd.DataFrame({'RawSchools': rawUniqueSchoolNamesFromAccreditation})\n",
    "# #create a mapping for those schools that actually match a school from other records\n",
    "# SchNoMapping = uniqueSchoolsFromRawAccreditationDF['RawSchools'].map(schoolsLookup)\n",
    "# uniqueSchoolsFromRawAccreditationDF = uniqueSchoolsFromRawAccreditationDF.assign(SchNoMappingCompleteMe = SchNoMapping)\n",
    "# SchNameMapping = uniqueSchoolsFromRawAccreditationDF['SchNoMappingCompleteMe'].map(schoolsLookupByName)\n",
    "# uniqueSchoolsFromRawAccreditationDF = uniqueSchoolsFromRawAccreditationDF.assign(SchoolName = SchNameMapping)\n",
    "# print('uniqueSchoolsFromRawAccreditationDF: ')\n",
    "# print(uniqueSchoolsFromRawAccreditationDF.head(5))\n",
    "# # Writing all schools anomalies for hand fixing\n",
    "# # uniqueSchoolsFromRawAccreditationDF.to_excel(schoolTypoWriter, sheet_name='SchoolsFromAccreditation', index=False)\n",
    "# # schoolTypoWriter.save()\n",
    "\n",
    "# Prepare data for InspectionSet (inspsetID,inspsetName,inspsetType,inspsetYear)\n",
    "InspectionSets = {\n",
    "    'inspsetID': [1,2],\n",
    "    'inspsetName': ['2016','2017'],\n",
    "    'inspsetType': ['SCHACCR','SCHACCR'],\n",
    "    'inspsetYear': [2016,2017]\n",
    "}\n",
    "\n",
    "inspectionSetsLookup = {\n",
    "    2016: 1,\n",
    "    2017: 2\n",
    "}\n",
    "\n",
    "inspectionSetDF = pd.DataFrame(data=InspectionSets)\n",
    "print('inspectionSetDF:')\n",
    "print(inspectionSetDF.head(5))\n",
    "      \n",
    "# Process SchoolAccreditation starting from the raw data\n",
    "schNo = rawAccreditationDataDF['School Name'].map(schoolsLookup)\n",
    "inspsetID = rawAccreditationDataDF['Year'].map(inspectionSetsLookup)\n",
    "rawAccreditationDataDF = rawAccreditationDataDF.assign(schNo = schNo, inspsetID = inspsetID)\n",
    "rawAccreditationDataDF = rawAccreditationDataDF.drop(['State','School Name','Column22','Column3','Column1','Year'], 1)\n",
    "rawAccreditationDataDF = rawAccreditationDataDF.rename(columns = {'Date Visited': 'inspStart',\n",
    "                                                                  'L1':'saL1', 'L2':'saL2', 'L3':'saL3', 'L4':'saL4',\n",
    "                                                                  'T1':'saT1', 'T2':'saT2', 'T3':'saT3', 'T4':'saT4',\n",
    "                                                                  'D1':'saD1', 'D2':'saD2', 'D3':'saD3', 'D4':'saD4',\n",
    "                                                                  'N1':'saN1', 'N2':'saN2', 'N3':'saN3', 'N4':'saN4',\n",
    "                                                                  'F1':'saF1', 'F2':'saF2', 'F3':'saF3', 'F4':'saF4',\n",
    "                                                                  'S1':'saS1', 'S2':'saS2', 'S3':'saS3', 'S4':'saS4',\n",
    "                                                                  'CO1':'saCO1', 'CO2':'saCO2',\n",
    "                                                                  'Tally 1':'saLT1','Tally 2':'saLT2','Tally 3':'saLT3','Tally 4':'saLT4',\n",
    "                                                                  'Total':'saT','Level':'saSchLevel'})\n",
    "rawAccreditationDataDF.insert(0,'inspID',range(1,len(rawAccreditationDataDF.index)+1))\n",
    "rawAccreditationDataDF.insert(0,'saID',rawAccreditationDataDF['inspID'])\n",
    "# TODO remove records with no school ID for now until the schools are all sorted out\n",
    "rawAccreditationDataDF = rawAccreditationDataDF[~rawAccreditationDataDF['schNo'].isnull()]\n",
    "\n",
    "schoolAccreditationDF = rawAccreditationDataDF.drop(['inspID','inspStart','inspsetID','schNo'],1)\n",
    "schoolAccreditationDF.fillna('NULL', inplace=True)\n",
    "print('schoolAccreditationDF:')\n",
    "print(schoolAccreditationDF.head(5))\n",
    "      \n",
    "# Process SchoolInspection data (inspID,schNo,inspPlanned,inspStart,inspEnd,inspNote,inspBy,inspsetID)\n",
    "schoolInspectionDF = rawAccreditationDataDF.drop(list(schoolAccreditationDF.columns.values),1)\n",
    "schoolInspectionDF.fillna('NULL', inplace=True)\n",
    "print('schoolInspectionDF:')\n",
    "print(schoolInspectionDF.head(5))\n",
    "      \n",
    "# Writing all school accreditation and related data to sheets\n",
    "writer = pd.ExcelWriter(outAccreditationData)\n",
    "inspectionSetDF.to_excel(writer, sheet_name='InspectionSet', index=False)\n",
    "schoolAccreditationDF.to_excel(writer, sheet_name='SchoolAccreditation', index=False)\n",
    "schoolInspectionDF.to_excel(writer, sheet_name='SchoolInspection', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Process teachers data\n",
    "################################################################################\n",
    "\n",
    "#rawTeachersData = os.path.join(fsmDir,'background/SY2015-2016CombinedTeachersending.xlsx')\n",
    "rawTeachersData = os.path.join(fsmDir,'background/CombinedDataStaff.xlsx')\n",
    "outTeachersData = os.path.join(fsmDir,'project-life-cycle/development-phase/fsm-teachers-initial-data.xlsx')\n",
    "\n",
    "# Prepare writer for all teacher related data\n",
    "writer = pd.ExcelWriter(outTeachersData)\n",
    "\n",
    "# All raw fields 'State','Municipality/Zone/Region','Island Name','First Name','Last Name','Job Title','Ethnicity','Citizenship','Staff Type','Teacher-Type','Organization','Gender','Highest Degree Achieved','Copy of Degree/Certificate Available','Field of Study','Certified','Expiration','Date of Hire ','Date of Birth','Annual Salary','Funding Source','School Name','School Type','School Level','Grade Taught','Employment Status','Reason','Date of Exit','Total # of days absent'\n",
    "rawTeachersAppointmentsDF = pd.read_excel(rawTeachersData, sheetname=\"CombinedSchoolStaff\", header=0)\n",
    "# Change all the string missing to actual pandas NULL since this is what we'll be inserting in DB\n",
    "rawTeachersAppointmentsDF.replace('Missing', 'NULL', inplace=True)\n",
    "# Handle as many dates as possible setting the bad ones to NaN \t \n",
    "tDatePSAppointed = pd.to_datetime(rawTeachersAppointmentsDF['Date of Hire '], errors=\"coerce\").dt.date #, format=\"%m/%d/%Y\"\n",
    "tDOB = pd.to_datetime(rawTeachersAppointmentsDF['Date of Birth'], errors=\"coerce\").dt.date #, format=\"%m/%d/%Y\"\n",
    "tDatePSClosed = pd.to_datetime(rawTeachersAppointmentsDF['Date of Exit'], errors=\"coerce\").dt.date #, format=\"%m/%d/%Y\"\n",
    "\n",
    "# Only work on the first 500 rows until this is cleaned\n",
    "#rawTeachersAppointmentsDF = rawTeachersAppointmentsDF #[0:499]\n",
    "# Cleanup\n",
    "# Drop what we will not need at all here onwards, rename, clean dates...\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.assign(tDatePSAppointed = tDatePSAppointed, tDOB = tDOB, tDatePSClosed = tDatePSClosed)\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.drop(['State','Municipality/Zone/Region','Island Name','School Type','School Level',\n",
    "                                                            'Date of Hire ','Date of Birth','Date of Exit'], 1)\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.rename(columns = {\n",
    "    'First Name': 'tGiven', 'Last Name': 'tSurname', 'Gender': 'tSex', 'Reason': 'tCloseReason'\n",
    "})\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.fillna('NULL')\n",
    "\n",
    "# Get a whole bunch of unique repeating values in lookup like columns\n",
    "# as first step in cleaning them\n",
    "uniqueStaffTypeFromRawTeacher = rawTeachersAppointmentsDF['Staff Type'].unique()\n",
    "print('uniqueStaffTypeFromRawTeacher:')\n",
    "print(uniqueStaffTypeFromRawTeacher)\n",
    "\n",
    "uniqueTeacherTypeFromRawTeacher = rawTeachersAppointmentsDF['Teacher-Type'].unique()\n",
    "print('uniqueTeacherTypeFromRawTeacher:')\n",
    "print(uniqueTeacherTypeFromRawTeacher)\n",
    "\n",
    "uniqueOrganizationFromRawTeacher = rawTeachersAppointmentsDF['Organization'].unique()\n",
    "print('uniqueOrganizationFromRawTeacher:')\n",
    "print(uniqueOrganizationFromRawTeacher)\n",
    "\n",
    "uniqueCertifiedFromRawTeacher = rawTeachersAppointmentsDF['Certified'].unique()\n",
    "print('uniqueCertifiedFromRawTeacher:')\n",
    "print(uniqueCertifiedFromRawTeacher)\n",
    "\n",
    "uniqueEthnicitiesFromRawTeacher = rawTeachersAppointmentsDF['Ethnicity'].unique()\n",
    "print('uniqueEthnicitiesFromRawTeacher:')\n",
    "print(uniqueEthnicitiesFromRawTeacher)\n",
    "\n",
    "uniqueJobTitlesFromRawTeacher = rawTeachersAppointmentsDF['Job Title'].unique() # role in Pineapple\n",
    "print('uniqueJobTitlesFromRawTeacher:')\n",
    "print(uniqueJobTitlesFromRawTeacher)\n",
    "\n",
    "uniqueHighestDegreesFromRawTeacher = rawTeachersAppointmentsDF['Highest Degree Achieved'].unique()\n",
    "print('uniqueHighestDegreesFromRawTeacher:')\n",
    "print(uniqueHighestDegreesFromRawTeacher) \n",
    "\n",
    "uniqueSchoolsFromRawTeacher = rawTeachersAppointmentsDF['School Name'].unique()\n",
    "print('uniqueSchoolsFromRawTeacher:')\n",
    "print(uniqueSchoolsFromRawTeacher)\n",
    "\n",
    "uniqueTeacherAppointmentSchoolYearFromRawTeacher = rawTeachersAppointmentsDF['SchoolYear'].unique()\n",
    "print('uniqueTeacherAppointmentSchoolYearFromRawTeacher:')\n",
    "print(uniqueTeacherAppointmentSchoolYearFromRawTeacher)\n",
    "\n",
    "uniqueGenderFromRawTeacher = rawTeachersAppointmentsDF['tSex'].unique()\n",
    "print('uniqueGenderFromRawTeacher:')\n",
    "print(uniqueGenderFromRawTeacher)\n",
    "\n",
    "# Manually constructed lookups from above unique values\n",
    "# these must be rebuilt when/if new data would come in as input\n",
    "rawNationalitiesLookup = {\n",
    "    'Chuukese': 'CHU',\n",
    "    'American': 'USA',\n",
    "    'Australian': 'AUS',\n",
    "    'Romanian': 'ROU',\n",
    "    'Finnish': 'FIN',\n",
    "    'Belgian': 'BEL',\n",
    "    'Yapese ': 'YAP',\n",
    "    'Filipino': 'PHL',\n",
    "    'Brazilian': 'BRA',\n",
    "    'Russian': 'RUS',\n",
    "    'Other': 'O',\n",
    "    'Pohnpeian': 'PNI',\n",
    "    'Indonesian': 'IDN',\n",
    "    'Japanese': 'JPN',\n",
    "    'Yap': 'YAP',\n",
    "    'Chuuk': 'CHU',\n",
    "    'Yapese': 'YAP',\n",
    "    'Palauan': 'PLW',\n",
    "    'Caucasian': 'USA',\n",
    "    'N. American': 'USA',\n",
    "    'Pakistani': 'PAK',\n",
    "    'Vietnamese': 'VNM',\n",
    "    'Norwegian': 'NOR' \n",
    "}\n",
    "\n",
    "rawRolesLookup = {\n",
    "    'Classroom Teacher I': 'CTI',\n",
    "    'Classroom Teacher II': 'CTII',\n",
    "    'Classroom Teacher IV': 'CTIV',\n",
    "    'Classroom Teacher III': 'CTIII',\n",
    "    'Classroom Teacher V': 'CTV',\n",
    "    'Classroom Mentor': 'CM',\n",
    "    'Vocational Coordinator': 'VC',\n",
    "    'Classroom Teacher': 'CT',\n",
    "    'School Principal II': 'SPII',\n",
    "    'Vocational Teacher II': 'VTII',\n",
    "    'Assistant Principal III': 'ASPIII',\n",
    "    'School Principal I': 'SPI',\n",
    "    'Teacher Assistant': 'TA',\n",
    "    'Houseparent I': 'HI',\n",
    "    'Cook III': 'CIII',\n",
    "    'Head Teacher': 'HT',\n",
    "    'School Principal III': 'CPIII',\n",
    "    'Peace Corp Volunteer': 'PCV',\n",
    "    'Acting Principal I': 'API',\n",
    "    'School Principal (Middle School)': 'SP',\n",
    "    'School Principal(Primary Grade)': 'SP',\n",
    "    'School Principal': 'SP',\n",
    "    'Classroom Teacher_Regular': 'CT',\n",
    "    'Classroom Teacher_ECE': 'CT',\n",
    "    'Classroom Teacher_Special Ed.': 'CT',\n",
    "    'Teacher Aide_WD&ST': 'TA',\n",
    "    'Principal/Classroom Teacher_Regular': 'SP',\n",
    "    'Teacher Aide_Special Ed': 'TA',\n",
    "    'Teacher Aide_Special Ed.': 'TA',\n",
    "    'Classroom Teacher_VocEd': 'VTI',\n",
    "    'Teacher Aide_ECE': 'TA',\n",
    "    'Related Services Assistant': 'TA',\n",
    "    'Clasroom Teacher_Regular': 'CT',\n",
    "    'Principal': 'SP',\n",
    "    'Teacger Aide_WD&ST': 'TA',\n",
    "    'Principal III': 'SPIII',\n",
    "    'Classroom Teacher': 'CT',    \n",
    "    'Vice Principal I': 'SVPI',\n",
    "    'Classroom Teacher I (SpEd)': 'CTI',\n",
    "    'Classroom Teacher II (SpEd)': 'CTII',\n",
    "    'Classroom Teacher (Contract)': 'CT',\n",
    "    'School Principal II': 'SPII',\n",
    "    'Assistant Principal ': 'AP',\n",
    "    'Vocational Teacher': 'VT',\n",
    "    'Vocational Teacher I': 'VTI',\n",
    "    'Classroom Teacher III (SpEd)': 'CTIII',\n",
    "    'Classroom Teacher  II': 'CTII',\n",
    "    'Classroom Teacher  I': 'CTI',\n",
    "    'Classroom Teache II': 'CTII',\n",
    "    'Vocational Teacher III': 'VTIII',\n",
    "    'Classroom Teacher IV (SpEd)': 'CTIV',    \n",
    "    'Classroom Teacher (SpEd)': 'CT',\n",
    "    'Principal I': 'SPI',\n",
    "    'Calssroom Teacher II': 'CTII',\n",
    "    'Acting School Principal': 'AP',\n",
    "    'Calssroom Teacher I': 'CTI',\n",
    "    'Classroom Teacher Ii': 'CTII',\n",
    "    'Classroom Teacher  (SpEd)': 'CT',\n",
    "    'Classroom Teacher II ': 'CTII',\n",
    "    'Classroom Teacher (Contract)1yr': 'CT',\n",
    "    'Classroom Teacher (Contract 1YR)': 'CT',\n",
    "    'School Principal III': 'SPIII',\n",
    "    'Classroom Teacher I (Contract-NTE 1YR)': 'CTI',\n",
    "    'Acting Principal I': 'API', #test dup\n",
    "    'Vocational Instructor': 'VTI',\n",
    "    'Classroom Teacher i': 'CTI',\n",
    "    'School Principal II (Contract)': 'SPII',\n",
    "    'Acting Head Teacher': 'AHT',\n",
    "    'Classroom Teacher l': 'CTI',\n",
    "    'School Prncipal': 'SP',\n",
    "    'School Princiapl II': 'SPII',\n",
    "    'School Principal (Middle School)': 'SP',\n",
    "    'School Principal (Primary Grade)': 'SP',\n",
    "    'Teacher Aide': 'TA',\n",
    "    'Vice Principal': 'SVP',\n",
    "    'Classroom Teacher (PCV)': 'CT',\n",
    "    'Classroom Teacher (Bible)': 'CT',\n",
    "    'Culture Teacher': 'CT',\n",
    "    'Vocational Education Teacher': 'VT',\n",
    "    'Culture Resource Teacher': 'CT',\n",
    "    'Teacher ': 'CT',    \n",
    "    'Teacher': 'CT',\n",
    "    'Librarian': 'L',\n",
    "    'Cook': 'C',\n",
    "    'Bus Driver': 'BD',\n",
    "    'Clerk': 'CL',\n",
    "    'Couselor': 'SC',\n",
    "    'Assistant Marine Instructor': 'VT',\n",
    "    'Principla': 'SP',\n",
    "    'Counselor': 'SC',\n",
    "    'Kitchen Helper': 'KH',\n",
    "    'Classroom Teacher-Regular': 'CT',\n",
    "    'Prinipal': 'SP',\n",
    "    'Boat Operator': 'BO',\n",
    "    'ClassroomTeacher_Regular': 'CT',\n",
    "    'Houseparent': 'H',\n",
    "    'Driver': 'D',\n",
    "    'Supply Technician': 'ST',\n",
    "    'Print Disability Specialist': 'PDS',\n",
    "    'Secretary': 'SE',\n",
    "    'House Parent': 'HP',    \n",
    "    'Education Specialis': 'ES',\n",
    "    'Pricipal': 'SP',\n",
    "    'School PrincipalIII': 'SPIII',\n",
    "    'Classroom Mentor': 'CM',    \n",
    "    'Vocational Coordinator': 'VC',\n",
    "    'Consultant (Reform Plan)': 'CO',\n",
    "    'Counselor IV': 'SCIV',\n",
    "    'Secretary I': 'SEI',\n",
    "    'Maintenance': 'MA',\n",
    "    'Security Guard I': 'SGI',\n",
    "    'Security Guard Supervisor': 'SGS',\n",
    "    'Campus Maintenance': 'MA',\n",
    "    'Registrar': 'RE',\n",
    "    'School PrincipalII': 'SPIII',\n",
    "    'Registrar I': 'REI',    \n",
    "    'Security Guard': 'SG',\n",
    "    'Trademan': 'TR',\n",
    "    'Clerk Typist III': 'CLIII',\n",
    "    'Custodian': 'CU',\n",
    "    'Clerk Typist': 'CL',\n",
    "    'Building Maitenance I': 'MAI',\n",
    "    'Security Guard II': 'SGII',\n",
    "    'Cook III': 'CIII',\n",
    "    'Houseparent I': 'HI',\n",
    "    'Cook I': 'CI',\n",
    "    'School PrincipalI': 'SPI',\n",
    "    'Assistant School PrincipalIII': 'ASPIII',\n",
    "    'Data Clerk I': 'CI',\n",
    "    'Peace Corp Volunteer': 'PCV',\n",
    "    'School Principal(Middle School)': 'SP',\n",
    "    'School Principal(Primary Grade)': 'SP',\n",
    "    'Primary Consulting Resource Teacher': 'C',\n",
    "    'Substitute Teacher': 'SUB',\n",
    "    'School Counselor': 'SC',\n",
    "    'Secondary Consulting Resource Teacher': 'C',\n",
    "    'Administrative Officer': 'AO',\n",
    "    'Maintenance Specialist': 'MA',\n",
    "    'Secondary Transition Specialist': 'ES',\n",
    "    'Secondary Transition Supervisor': 'TS',\n",
    "    'PE Instuctor': 'VT',\n",
    "    'School Accountant/Administrative Assistant': 'AO',\n",
    "    'Supervisor': 'SU',\n",
    "    'Moonitor': 'MO',\n",
    "    'Principal/Administrator': 'SP',\n",
    "    'Monitor': 'MO',\n",
    "    'Canteen supervisor': 'CS',\n",
    "    'Admin. Assistant': 'AA',\n",
    "    'Voc Ed. Coordinator': 'VC',\n",
    "    'Vice Princiapl': 'SVP',\n",
    "    'School Counselor V': 'SCV',\n",
    "    'Maintenance Worker III': 'MAIII',\n",
    "    'Security Guard III': 'SGIII',\n",
    "    'Bus Driver II': 'BDII',\n",
    "    'Bus Driver I': 'BDI',\n",
    "    'Data Clerk IV': 'CLIV',\n",
    "    'Custodial Worker II'\n",
    "    'Registrar II': 'REII',\n",
    "    'Teacher Assistant': 'TA',\n",
    "    'Maintenance Worker I': 'MAI',    \n",
    "    'House Parent II': 'HII',\n",
    "    'Librarian I': 'LI',\n",
    "    'School Counselor I': 'SCI',\n",
    "    'Cook II': 'CII',\n",
    "    'Assistant Principal': 'ASP',\n",
    "    'Resource Teacher': 'CT',\n",
    "    'Teacher Aide (WD&ST)': 'TA',\n",
    "    'Cook ': 'C',    \n",
    "    'Teaching Principal': 'SP',\n",
    "    'Bus Driver ': 'BD',\n",
    "    'Contract Instructor': 'VT',\n",
    "    'Home Arts Instructor': 'VT',\n",
    "    'cook': 'C',\n",
    "    'Ground Keeper': 'GK',\n",
    "    'Assistant Librarian': 'AL',\n",
    "    'Job Career Counselor': 'SC',\n",
    "    'Related Services Assstant': 'RSA',\n",
    "    'ECE Supervisor': 'SU',\n",
    "    'Resource Teacher ': 'CT',\n",
    "    'Teacher-WDNST': 'CT',\n",
    "    'Teacher/PE Instuctor': 'CT',\n",
    "    'Asst Director': 'ADI',\n",
    "    'Director': 'DI',\n",
    "    'Accountant': 'ACC',\n",
    "    'Consultant  (R/Plan)': 'C',\n",
    "    'Classroom Teacer IV': 'CTIV',\n",
    "    'Acting Principal': 'AP',\n",
    "    'Classroom Teache I': 'CTI',\n",
    "    'Acting School Principal I': 'API',\n",
    "    'World Teach': 'U'\n",
    "}\n",
    "\n",
    "# staff, teacher type, organisation for the \n",
    "rawDegreesLookup = {\n",
    "    'AS': 'AS',\n",
    "    'BA': 'BA',\n",
    "    'AA': 'AA',\n",
    "    'MA': 'MA',\n",
    "    'none': 'NULL',\n",
    "    'BS': 'BS',\n",
    "    'As': 'AS',\n",
    "    'None': 'NULL',\n",
    "    'AS ': 'AS',\n",
    "    'NULL': 'NULL',\n",
    "    'AAS': 'AAS',\n",
    "    'MS': 'MS',\n",
    "    'BA ': 'BA',\n",
    "    'HS Graduate': 'HS',\n",
    "    'AA/AS': 'AS',\n",
    "    'No Degree': 'NULL',\n",
    "    'BA/BS': 'BS',\n",
    "    'MA/MS': 'MS',\n",
    "    'Certificate of Achievement': 'NULL',\n",
    "    'AS Degree': 'AS',\n",
    "    'Other': 'NULL',\n",
    "    'AAA': 'AAA',\n",
    "    'High School Diploma': 'HS',\n",
    "    'AA Degree': 'AA',\n",
    "    'BS ': 'BS',\n",
    "    'BS, Diploma': 'BS',\n",
    "    'CA': 'C',\n",
    "    'PHD': 'PHD',\n",
    "    'BS/MA': 'MA',\n",
    "    'Finished 8th Gr': 'NULL',\n",
    "    'High School': 'HS',\n",
    "    'Some High Schoo': 'NULL',\n",
    "    'AA\\\\': 'AA',\n",
    "    'Some Elementary': 'NULL',\n",
    "    'Some High School': 'NULL',\n",
    "    'BS/B.Sc.': 'BS',\n",
    "    'M.Ed.': 'MED',\n",
    "    '3RD YR.': 'NULL',\n",
    "    'Certificate': 'C',\n",
    "    'BBA': 'BA',\n",
    "    'Elementary Graduate': 'NULL',\n",
    "    'Third Year': 'NULL',\n",
    "    'Certificate of Completion': 'NULL'\n",
    "}\n",
    "\n",
    "# In the EMIS, there is no specific place to stored the equivalent of the columns \"Staff Type\", \"Teacher-Type\", \"Organization\"\n",
    "      \n",
    "# Built based on Staff Type, Teacher-Type, Organization\n",
    "#       Local Regular Teaching Staff\n",
    "#       Local Special Education Teaching Staff\n",
    "#       Local Early Childhood Teaching Staff\n",
    "#       Local Volunteer Teaching Staff\n",
    "#       DOE Regular Teaching Staff\n",
    "#       DOE Special Education Teaching Staff\n",
    "#       DOE Early Childhood Teaching Staff\n",
    "#       DOE Volunteer Teaching Staff\n",
    "#       World Teacher Regular Teaching Staff\n",
    "#       World Teacher Special Education Teaching Staff\n",
    "#       World Teacher Early Childhood Teaching Staff\n",
    "#       World Teacher Volunteer Teaching Staff\n",
    "#       Peace Corp Regular Teaching Staff\n",
    "#       Peace Corp Special Education Teaching Staff\n",
    "#       Peace Corp Early Childhood Teaching Staff\n",
    "#       Peace Corp Volunteer Teaching Staff\n",
    "      \n",
    "staffTypeFromRawTeacherLookup = {\n",
    "    'Teaching Staff': 'TS',\n",
    "    'Teaching Staff-TS': 'TS',\n",
    "    'None Teaching Staff': 'NTS',\n",
    "    'TS': 'TS',\n",
    "    'NTS': 'NTS',\n",
    "    'Principal': 'TS',\n",
    "    'Vice Principal': 'TS',\n",
    "    'Counselor': 'NTS',\n",
    "    'Admin. Assistant': 'NTS',\n",
    "    'Clerk': 'NTS',\n",
    "    'Voc Ed. Coordinator': 'TS',\n",
    "    'Maintenance': 'NTS',\n",
    "    'Librarian': 'NTS',\n",
    "    'Clerk ': 'NTS',\n",
    "    'Librarian Staff': 'NTS',\n",
    "    'Clerk Staff': 'NTS',\n",
    "    'Supervisor': 'NTS',\n",
    "    'T': 'TS',\n",
    "    'NT': 'NTS',\n",
    "    'Volunteer': 'TS',\n",
    "    'NST': 'NTS',\n",
    "    'Library': 'NTS'\n",
    "}\n",
    "\n",
    "certifiedFromRawTeacherLookup = {\n",
    "    'NULL': 'NULL',\n",
    "    'Certified': 'NSTT',\n",
    "    'Yes': 'NSTT',\n",
    "    'No': 'NULL',\n",
    "    'yes': 'NSTT',\n",
    "    ' Yes': 'NSTT',\n",
    "    'Processing': 'NULL'\n",
    "}\n",
    "\n",
    "genderFromRawTeacherLookup = {\n",
    "    'NULL': 'NULL',\n",
    "    'Male': 'M',\n",
    "    'Female': 'F'\n",
    "}\n",
    "\n",
    "# Add helper column to identify teachers\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.assign(theTeacher = lambda x: x.tGiven + '-' + x.tSurname)\n",
    "# clean staff type into another column staffTypeTemp\n",
    "staffTypeTemp = rawTeachersAppointmentsDF['Staff Type'].map(staffTypeFromRawTeacherLookup)\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.assign(staffTypeTemp = staffTypeTemp)\n",
    "# clean certifications into another column certifiedTemp    \n",
    "certifiedTemp = rawTeachersAppointmentsDF['Certified'].map(certifiedFromRawTeacherLookup)\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF.assign(staffTypeTemp = staffTypeTemp, certifiedTemp = certifiedTemp)\n",
    "rawTeachersAppointmentsDF.to_excel(writer, sheet_name='RawTeacherAppointments', index=False)\n",
    "# remove all non-teachers for now as raw data contains all staff\n",
    "rawTeachersAppointmentsDF = rawTeachersAppointmentsDF[rawTeachersAppointmentsDF['staffTypeTemp'] == 'TS']\n",
    "# print('rawTeachersAppointmentsDF:')\n",
    "# print(rawTeachersAppointmentsDF.head(3))\n",
    "      \n",
    "# Teacher DB (tID,tDOB,tSex,tGiven,tSurname)\n",
    "teachersDF = rawTeachersAppointmentsDF[['theTeacher','tDOB','tSex','tGiven','tSurname',\n",
    "                                        'Highest Degree Achieved','Field of Study','certifiedTemp',\n",
    "                                        'tDatePSAppointed','tDatePSClosed','tCloseReason']]\n",
    "teachersDF = teachersDF.replace({'tSex': {'Male': 'M', 'Female': 'F'}})\n",
    "# Small possibility of loosing some data here (some teacher duplicate might contain the certification while others not)\n",
    "# the drop_dup only keeps the first occurance\n",
    "teachersDF = teachersDF.drop_duplicates(['theTeacher'])\n",
    "teachersDF.insert(0,'tID',range(1,len(teachersDF.index)+1))\n",
    "# TODO Fix single quote (') in teacher names\n",
    "# create teachers lookup\n",
    "teachersLookup = teachersDF.set_index('theTeacher').to_dict()['tID']\n",
    "print('teachersDF:')\n",
    "print(teachersDF.head(1))\n",
    "\n",
    "# teacherTypeFromRawTeacherLookup = {\n",
    "#     'Missing': Nan,\n",
    "#     'Regular-R': 'R',\n",
    "#     'Special Ed.': 'SE',\n",
    "#     'ECE': 'ECE',\n",
    "#     'R': 'R',\n",
    "#     'SE': 'SE',\n",
    "#     'Volunteer': 'V',\n",
    "#     'RSA': ?,\n",
    "#     'Regular': 'R',\n",
    "#     'SPED': 'SE',\n",
    "#     'Early Childhood Education': 'ECE',\n",
    "#     'SDA': ?,\n",
    "#     'World Teacher': ?,\n",
    "#     'AVS II', ?,\n",
    "#     'SM': ?,\n",
    "#     'RT': 'R',\n",
    "#     'SET': 'SE',\n",
    "#     'Resident': ?,\n",
    "#     'Local': ?,\n",
    "#     'WT': ?\n",
    "# }\n",
    "      \n",
    "# organizationFromRawTeacherLookup = {\n",
    "#     'Missing': NaN,\n",
    "#     'Local': '',\n",
    "#     'CDOE': 'DOE',\n",
    "#     'Special Education': 'DOE',\n",
    "#     'World Teacher': 'WT',\n",
    "#     'Peace Corp': 'PC',\n",
    "#     'Private School': ?,\n",
    "#     'JIV': ?,\n",
    "#     'DOE': 'DOE',\n",
    "#     'DOE ': 'DOE',\n",
    "#     'KDOE': ?,\n",
    "#     'World Teach': 'WT',\n",
    "#     'KMG': ?,\n",
    "#     'YCHS': ?\n",
    "#     'Private': ?\n",
    "# }\n",
    "\n",
    "# No longer needed, I have a comprehensive mapping of school names with anomalies\n",
    "# # First cleanup schools (to be written to file for manual association to correct school)\n",
    "# uniqueSchoolsFromRawTeacherDF = pd.DataFrame({'RawSchools': uniqueSchoolsFromRawTeacher})\n",
    "# #create a mapping for those schools that actually match a school from other records\n",
    "# SchNoMapping = uniqueSchoolsFromRawTeacherDF['RawSchools'].map(schoolsLookup)\n",
    "# uniqueSchoolsFromRawTeacherDF = uniqueSchoolsFromRawTeacherDF.assign(SchNoMappingCompleteMe = SchNoMapping)\n",
    "# SchNameMapping = uniqueSchoolsFromRawTeacherDF['SchNoMappingCompleteMe'].map(schoolsLookupByName)\n",
    "# uniqueSchoolsFromRawTeacherDF = uniqueSchoolsFromRawTeacherDF.assign(SchoolName = SchNameMapping)\n",
    "# # Writing all schools anomalies for hand fixing\n",
    "# schoolTypoWriter = pd.ExcelWriter(outInitialSchoolsTyposData)\n",
    "# uniqueSchoolsFromRawTeacherDF.to_excel(schoolTypoWriter, sheet_name='SchoolsFromTeachers', index=False)\n",
    "# schoolTypoWriter.save()\n",
    "      \n",
    "# Process teacher training (tID,trInstitution,trQual,trMajor) or (tID,trQual,trMajor)\n",
    "# this is the academic degrees\n",
    "teachersTrainingDF = teachersDF[['tID','Highest Degree Achieved','Field of Study']]\n",
    "trQual= teachersTrainingDF['Highest Degree Achieved'].map(rawDegreesLookup) #teachersTrainingDF.loc['trQual']\n",
    "teachersTrainingDF = teachersTrainingDF.rename(columns = {'Field of Study': 'trMajor'})\n",
    "teachersTrainingDF = teachersTrainingDF.assign(trQual = trQual)\n",
    "teachersTrainingDF = teachersTrainingDF.drop(['Highest Degree Achieved'], 1)\n",
    "# and now the NSTT certification\n",
    "teachersCertifiedDF = teachersDF[['tID','certifiedTemp']]\n",
    "teachersCertifiedDF = teachersCertifiedDF[teachersCertifiedDF['certifiedTemp'] == 'NSTT']\n",
    "teachersCertifiedDF = teachersCertifiedDF.rename(columns = {'certifiedTemp': 'trQual'})\n",
    "#teachersCertifiedDF.insert(0,'trInstitution','FSM National Standard Teacher Certification') # range(1,len(teachersCertifiedDF.index)+1)\n",
    "teachersTrainingDF = teachersTrainingDF.append(teachersCertifiedDF)\n",
    "teachersTrainingDF = teachersTrainingDF.fillna('NULL')\n",
    "teachersTrainingDF = teachersTrainingDF[~(teachersTrainingDF['trQual'] == 'NULL')]\n",
    "print(teachersTrainingDF.head(1))\n",
    "\n",
    "# Process teacher appointments. (tID,taDate,SchNo,taRole,estpNo,taEndDate)\n",
    "teachersAppointmentsDF = rawTeachersAppointmentsDF[['theTeacher','SchoolYear','School Name','Job Title']]\n",
    "# Set taDate and taEndDate based on SchoolYear ??\n",
    "teachersAppointmentStartDatesLookup = {\n",
    "    'SY2013-2014': '2013-08-01 00:00:00.000',\n",
    "    'SY2014-2015': '2014-08-01 00:00:00.000',\n",
    "    'SY2015-2016': '2015-08-01 00:00:00.000',\n",
    "    'SY2016-2017': '2016-08-01 00:00:00.000',\n",
    "}\n",
    "teachersAppointmentEndDatesLookup = {\n",
    "    'SY2013-2014': '2014-07-31 00:00:00.000',\n",
    "    'SY2014-2015': '2015-07-31 00:00:00.000',\n",
    "    'SY2015-2016': '2016-07-31 00:00:00.000',\n",
    "    'SY2016-2017': '2017-07-31 00:00:00.000',\n",
    "}\n",
    "taDate = teachersAppointmentsDF['SchoolYear'].map(teachersAppointmentStartDatesLookup)\n",
    "taEndDate = teachersAppointmentsDF['SchoolYear'].map(teachersAppointmentEndDatesLookup)\n",
    "teachersAppointmentsDF = teachersAppointmentsDF.assign(taDate = taDate, taEndDate = taEndDate)\n",
    "# # Need to link to correct teacher\n",
    "tID = teachersAppointmentsDF['theTeacher'].map(teachersLookup)\n",
    "# Need to link to correct schools\n",
    "SchNo = teachersAppointmentsDF['School Name'].map(schoolsLookup)\n",
    "taRole = teachersAppointmentsDF['Job Title'].map(rawRolesLookup)\n",
    "teachersAppointmentsDF = teachersAppointmentsDF.assign(tID = tID, SchNo = SchNo, taRole = taRole)\n",
    "# remove all appointments where we don't know the school and role since this is invalid data\n",
    "# by nature (how can this be an appointment without knowing the school/role)\n",
    "teachersAppointmentsDF = teachersAppointmentsDF[(pd.notnull(teachersAppointmentsDF['SchNo'])) & (pd.notnull(teachersAppointmentsDF['taRole']))]\n",
    "print('teachersAppointmentsDF:')\n",
    "print(teachersAppointmentsDF.head(1))\n",
    "\n",
    "# Process establishments (estpNo,schNo,estpRoleGrade,estpActiveDate,estpTitle)\n",
    "estpPositions = {}\n",
    "\n",
    "def getEstpNo(row):\n",
    "    estpKey = str(row.schNo) + '-' + str(row.taRole)\n",
    "    if (estpKey in estpPositions):\n",
    "        # Next position to assign to the school\n",
    "        schoolPositions = estpPositions[estpKey]\n",
    "        lastPositionIndex = schoolPositions.pop()\n",
    "        newPositionIndex = lastPositionIndex+1\n",
    "        estpPositions[estpKey] = schoolPositions + [lastPositionIndex,newPositionIndex]\n",
    "        schoolRole = estpKey + '-' + str(newPositionIndex)\n",
    "        return schoolRole\n",
    "    else:\n",
    "        # First position assigned to the school\n",
    "        estpPositions[estpKey] = [1]\n",
    "        schoolRole = str(estpKey) + '-1'        \n",
    "        return schoolRole\n",
    "    \n",
    "# To simplify things we'll create a new establishment school position for each teacher appointment\n",
    "# This is a simpler way to get off the ground faster, I think (hope)\n",
    "#teachersAppointmentsWithEstpSetDF = teachersAppointmentsDF[teachersAppointmentsDF['taDate'] == '2016-08-01 00:00:00.000']\n",
    "#establishmentsDF = teachersAppointmentsDF[teachersAppointmentsDF['taDate'] == '2016-08-01 00:00:00.000']\n",
    "establishmentsDF = teachersAppointmentsDF\n",
    "establishmentsDF = establishmentsDF.rename(columns = {'taDate': 'estpActiveDate', 'SchNo': 'schNo'})\n",
    "estpTitle = establishmentsDF['taRole'].map(teacherRoleByNameLookups)\n",
    "estpRoleGrade = establishmentsDF['taRole'].map(roleGradesLookups)\n",
    "establishmentsDF = establishmentsDF.assign(estpTitle = estpTitle, estpRoleGrade = estpRoleGrade)\n",
    "estpNo = establishmentsDF.apply(lambda row: getEstpNo(row),axis=1)\n",
    "establishmentsDF.insert(0, 'estpNo', estpNo)\n",
    "teachersAppointmentsDF = teachersAppointmentsDF.assign(estpNo = estpNo)\n",
    "print('establishmentsDF:')\n",
    "print(establishmentsDF.head(1))\n",
    "\n",
    "# final cleanups of unecessary columns\n",
    "teachersDF = teachersDF.drop(['theTeacher','Highest Degree Achieved','Field of Study','certifiedTemp'], 1)\n",
    "teachersAppointmentsDF = teachersAppointmentsDF.drop(['SchoolYear','School Name','Job Title','theTeacher'], 1)\n",
    "establishmentsDF = establishmentsDF.drop(['tID','taRole','taEndDate','theTeacher','SchoolYear','School Name','Job Title'], 1)\n",
    "\n",
    "# Write sheets\n",
    "teachersDF.to_excel(writer, sheet_name='Teacher', index=False)\n",
    "teachersTrainingDF.to_excel(writer, sheet_name='TeacherTraining', index=False)\n",
    "teachersAppointmentsDF.to_excel(writer, sheet_name='TeacherAppointment', index=False)\n",
    "establishmentsDF.to_excel(writer, sheet_name='Establishment', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "fsmDir = '/Users/ghachey/Documents/JobsAndClients/Nuzusys/Clients/FederatedStatesOfMicronesiaPublicSchoolSystem/'\n",
    "vermpaf = os.path.join(fsmDir,'project-life-cycle/development-phase/indicators/VERMPAF-FEDEMIS-TEST-11mar2018.xml')\n",
    "\n",
    "tree = ET.parse(vermpaf)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Create unique list of  in exams sample\n",
    "#survivals = set([]) # to insert tuples of schema (School_ID, School_Name)\n",
    "\n",
    "# Process nation flows (i.e. transition rate, survival rate)\n",
    "      # <TRM>\n",
    "      # <TRF>\n",
    "      # <TR>\n",
    "      # <SRM>\n",
    "      # <SRF>\n",
    "      # <SR>\n",
    "      # year=\"2017\" yearOfEd=\"11\"\n",
    "data = []      \n",
    "for s in root.iter('Survival'):\n",
    "    if s.find('TRM') is not None:\n",
    "       TRM = s.find('TRM').text\n",
    "    else:\n",
    "       TRM = None\n",
    "    if s.find('TRF') is not None:\n",
    "       TRF = s.find('TRF').text\n",
    "    else:\n",
    "       TRF = None\n",
    "    if s.find('TR') is not None:\n",
    "       TR = s.find('TR').text\n",
    "    else:\n",
    "       TR = None\n",
    "    if s.find('SRM') is not None:\n",
    "       SRM = s.find('SRM').text\n",
    "    else:\n",
    "       SRM = None\n",
    "    if s.find('SRF') is not None:\n",
    "       SRF = s.find('SRF').text\n",
    "    else:\n",
    "       SRF = None\n",
    "    if s.find('SR') is not None:\n",
    "       SR = s.find('SR').text\n",
    "    else:\n",
    "       SR = None       \n",
    "    data.append({'TRM': TRM, 'TRF': TRF, 'TR': TR, 'SRM': SRM, 'SRF': SRF, 'SR': SR,\n",
    "                 'year': s.get('year'), 'yearOfEd': s.get('yearOfEd')})\n",
    "\n",
    "data2 = []      \n",
    "for t in root.iter('TeacherQC'):\n",
    "\n",
    "    if t.find('Enrol') is not None:\n",
    "       Enrol = t.find('Enrol').text\n",
    "    else:\n",
    "       Enrol = None\n",
    "    if t.find('TeachersM') is not None:\n",
    "       TeachersM = t.find('TeachersM').text\n",
    "    else:\n",
    "       TeachersM = None\n",
    "    if t.find('TeachersF') is not None:\n",
    "       TeachersF = t.find('TeachersF').text\n",
    "    else:\n",
    "       TeachersF = None\n",
    "    if t.find('Teachers') is not None:\n",
    "       Teachers = t.find('Teachers').text\n",
    "    else:\n",
    "       Teachers = None\n",
    "    if t.find('QualM') is not None:\n",
    "       QualM = t.find('QualM').text\n",
    "    else:\n",
    "       QualM = None\n",
    "    if t.find('QualF') is not None:\n",
    "       QualF = t.find('QualF').text\n",
    "    else:\n",
    "       QualF = None\n",
    "    if t.find('Qual') is not None:\n",
    "       Qual = t.find('Qual').text\n",
    "    else:\n",
    "       Qual = None\n",
    "    if t.find('CertM') is not None:\n",
    "       CertM = t.find('CertM').text\n",
    "    else:\n",
    "       CertM = None\n",
    "    if t.find('CertF') is not None:\n",
    "       CertF = t.find('CertF').text\n",
    "    else:\n",
    "       CertF = None\n",
    "    if t.find('Cert') is not None:\n",
    "       Cert = t.find('Cert').text\n",
    "    else:\n",
    "       Cert = None\n",
    "    if t.find('CertPercM') is not None:\n",
    "       CertPercM = t.find('CertPercM').text\n",
    "    else:\n",
    "       CertPercM = None\n",
    "    if t.find('CertPercF') is not None:\n",
    "       CertPercF = t.find('CertPercF').text\n",
    "    else:\n",
    "       CertPercF = None\n",
    "    if t.find('CertPerc') is not None:\n",
    "       CertPerc = t.find('CertPerc').text\n",
    "    else:\n",
    "       CertPerc = None\n",
    "    if t.find('QualPercM') is not None:\n",
    "       QualPercM = t.find('QualPercM').text\n",
    "    else:\n",
    "       QualPercM = None\n",
    "    if t.find('QualPercF') is not None:\n",
    "       QualPercF = t.find('QualPercF').text\n",
    "    else:\n",
    "       QualPercF = None\n",
    "    if t.find('QualPerc') is not None:\n",
    "       QualPerc = t.find('QualPerc').text\n",
    "    else:\n",
    "       QualPerc = None\n",
    "    if t.find('PTR') is not None:\n",
    "       PTR = t.find('PTR').text\n",
    "    else:\n",
    "       PTR = None\n",
    "    if t.find('CertPTR') is not None:\n",
    "       CertPTR = t.find('CertPTR').text\n",
    "    else:\n",
    "       CertPTR = None\n",
    "    if t.find('QualPTR') is not None:\n",
    "       QualPTR = t.find('QualPTR').text\n",
    "    else:\n",
    "       QualPTR = None\n",
    "\n",
    "    data2.append({'Enrol': Enrol, 'TeachersM': TeachersM, 'TeachersF': TeachersF, 'Teachers': Teachers,\n",
    "                  'QualM': QualM, 'QualF': QualF, 'Qual': Qual, 'CertM': CertM, 'CertF': CertF, 'Cert': Cert, \n",
    "                  'CertPercM': CertPercM, 'CertPercF': CertPercF, 'CertPerc': CertPerc,\n",
    "                  'QualPercM': QualPercM, 'QualPercF': QualPercF, 'QualPerc': QualPerc, \n",
    "                  'PTR': PTR, 'CertPTR': CertPTR, 'QualPTR': QualPTR, \n",
    "                  'year': t.get('year'), 'sectorCode': t.get('sectorCode')})\n",
    "\n",
    "flowDF = pd.DataFrame(data)\n",
    "teacherQualDF = pd.DataFrame(data2)\n",
    "teacherQualDF = teacherQualDF.sort_values(by=['year', 'sectorCode'])\n",
    "\n",
    "flowDF\n",
    "teacherQualDF\n",
    "\n",
    "# Writing data to sheets\n",
    "outData = os.path.join(fsmDir,'project-life-cycle/development-phase/indicators/fsm-flow-and-teacher-qual-data.xlsx')\n",
    "writer = pd.ExcelWriter(outData)\n",
    "flowDF.to_excel(writer, sheet_name='FlowData', index=False)\n",
    "teacherQualDF.to_excel(writer, sheet_name='TeacherQualData', index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "name": "fedemis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
