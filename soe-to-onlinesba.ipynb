{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "###############################################################################\n",
    "# This notebook focuses on processing data from excel spreadsheet directly    #\n",
    "# into another format ready to load into OnlineSBA                            #\n",
    "#                                                                             #\n",
    "# It is also used to process raw SOE workbooks and flag data issues           #\n",
    "###############################################################################\n",
    "\n",
    "# import everything we need throughout the notebook\n",
    "# core stuff\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Data stuff\n",
    "import pandas as pd # Data analysis\n",
    "import xlrd # excel \n",
    "import pyodbc # SQL DB\n",
    "import numpy as np\n",
    "\n",
    "# Fuzzy searching stuff\n",
    "from fuzzywuzzy import fuzz\n",
    "# process is used to compare a string to MULTIPLE other strings\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Pretty printing stuff\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from IPython.display import display, HTML\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Generate unique identifiers stuff\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "rd = random.Random()\n",
    "rd.seed(0)\n",
    "\n",
    "# Configuration (initial setup)\n",
    "with open('config.json', 'r') as file:\n",
    "     config = json.load(file)\n",
    "\n",
    "test = config['test']\n",
    "country = config['country']\n",
    "cwd = os.getcwd()\n",
    "\n",
    "year_to_load = config['load_year']\n",
    "skip_incorrect_answers = config['skip_incorrect_answers']\n",
    "remove_items_metadata = config['remove_items_metadata']\n",
    "export = config['export']\n",
    "fix_schoolid_in_source_data = config['fix_schoolid_in_source_data']\n",
    "accept_teachers_with_three_chars_only = config['accept_teachers_with_three_chars_only']\n",
    "accept_unknown_gender = config['accept_unknown_gender']\n",
    "accept_unknown_student = config['accept_unknown_student']\n",
    "accept_unknown_teacher = config['accept_unknown_teacher']\n",
    "\n",
    "# Establish a database server connection\n",
    "conn = \"\"\"\n",
    "    Driver={{ODBC Driver 17 for SQL Server}};\n",
    "    Server={},{};\n",
    "    Database={};\n",
    "    authentication=SqlPassword;UID={};PWD={};\n",
    "    TrustServerCertificate=yes;\n",
    "    autocommit=True\n",
    "    \"\"\".format(config['server_ip'], config['server_port'], config['database'], config['uid'], config['pwd'])\n",
    "\n",
    "sql_conn = pyodbc.connect(conn)\n",
    "\n",
    "# It is important to keep the order of the cells since there are inplace \n",
    "# operations on DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the schools, student enrollments and teachers from the database\n",
    "# For students and teachers currenly only those of that year of loaded and used to compare with exams data\n",
    "# e.g. student enrolled in 2018-19 and teachers teaching in 2018-19 and compared with exams data\n",
    "# for 2018-19\n",
    "\n",
    "query_student_enrol = \"\"\"\n",
    "SELECT\n",
    "\tstuCardID\n",
    "\t, CONCAT(stuGiven,' ',stuFamilyName) AS Student -- stuMiddleNames,' ',\n",
    "\t, stuGender\n",
    "\t, stuDoB\n",
    "\t, schNo\n",
    "\t, stueYear\n",
    "\tFROM Student_ S\n",
    "\tINNER JOIN StudentEnrolment_ SE ON S.stuID = SE.stuID\n",
    "\"\"\"\n",
    "\n",
    "query_schools = \"\"\"\n",
    "SELECT\n",
    "\tschNo\n",
    "\t, schName\n",
    "\tFROM Schools\n",
    "\"\"\"\n",
    "\n",
    "# Not used yet\n",
    "#query_teachers = \"\"\"\n",
    "#\"\"\"\n",
    "\n",
    "df_student_enrol = pd.read_sql(query_student_enrol, sql_conn)\n",
    "print('df_student_enrol')\n",
    "display(df_student_enrol.head(3))\n",
    "\n",
    "df_schools = pd.read_sql(query_schools, sql_conn)\n",
    "print('df_schools')\n",
    "display(df_schools.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_df(filename):\n",
    "    \"\"\"Loads an Excel filename to a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, required\n",
    "        The filename of the excel file to load\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    file_path = Path(filename)\n",
    "    file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "    if file_extension == 'xlsx':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0, engine='openpyxl')\n",
    "    elif file_extension == 'xls':\n",
    "        df_student_results = pd.read_excel(filename, index_col=None, header=0)\n",
    "    elif file_extension == 'csv':\n",
    "        df_student_results = pd.read_csv(filename, index_col=None, header=0)\n",
    "    else:\n",
    "        raise Exception(\"File not supported\")\n",
    "\n",
    "    return df_student_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single SOE Assessment workbook (for testing,)\n",
    "# in particular the sheet with the raw data\n",
    "cwd = os.getcwd()\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2019/3GrEng2019/AllSchools_A03_2018-19_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2012/6grEng12/AllSchools_A06_2011-12_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2019/Gr6Math2019/AllSchools_M06_2018-19_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2009/6GrMath2009/AllSchools_M06_2008-09_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2009/Gr6KM2009/AllSchools_B06_2008-09_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2009/3GrMath2009/AllSchools_M03_2008-09_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2011/3GrEng2011/AllSchools_A03_2010-11_Results1.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2018/Gr3KM2018/AllSchools_B03_2017-18_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2016/Gr8HSET2016/AllSchools_H08_2015-16_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2017/Gr8HSET2017/AllSchools_H08_2016-17_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2009/8GrHSET2009/AllSchools_H08_2008-09_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2017/Gr3Math2017/AllSchools_M03_2016-17_Results.xls')\n",
    "filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2017/Gr10Math2017/AllSchools_M10_2016-17_Results1.xls')\n",
    "#filename = os.path.join(cwd, 'data/RMI/MISAT/MISAT 2021/Gr3Eng2021/AllSchools_A03_2020-21_Results.xls')\n",
    "#filename = os.path.join(cwd, 'data/FSM/NMCT/NMCT 2021/AllSchools_R08_2020-21_Results.xls')\n",
    "\n",
    "testname = filename.split('/')[-1]\n",
    "df_student_results = {}\n",
    "df_student_results[testname] = load_excel_to_df(filename)\n",
    "print('df_student_results')\n",
    "display(df_student_results[testname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load all SOE Assessment workbook inside a directory\n",
    "# (~32 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "cwd = os.getcwd()\n",
    "data_dir = 'data/'+country+'/'+test\n",
    "path = os.path.join(cwd, data_dir)\n",
    "\n",
    "if year_to_load != 'all':\n",
    "    path = os.path.join(path, year_to_load)\n",
    "\n",
    "df_student_results_list = {}\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        print('Loading into DataFrame file:', filename)\n",
    "        try:\n",
    "            df_student_results_list[name] = load_excel_to_df(filename)\n",
    "        except:\n",
    "            print('Problem loading file:', filename)\n",
    "            #print('Error was:', )            \n",
    "\n",
    "print('Completed loading excel files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_exams_data_with_student_enrol_df(df_student_results, df_student_enrol, testing=False):\n",
    "    \"\"\" Merge both the dirty exams data with the clean student enrollments dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_student_results : DataFrame, required\n",
    "        The student results DataFrame (from SOE Assessment response sheet)\n",
    "    df_student_enrol : DataFrame, required\n",
    "        The student enrolment DataFrame (from EMIS)\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # lower case to make join case insensitive (like SQL Server, the default collation of Pacific EMIS anyway)\n",
    "    try:\n",
    "        df_student_results['StudentName2'] = df_student_results['StudentName'].str.lower()\n",
    "        df_student_enrol['Student2'] = df_student_enrol['Student'].str.lower()\n",
    "    except KeyError:        \n",
    "        print('StudentName column is not present or misspelled (hint from data): ', df_student_results[:1].iloc[:, : 5].to_csv(index=False, header=False))\n",
    "        return\n",
    "    except:\n",
    "        print('Unknown error')\n",
    "        return\n",
    "\n",
    "    # Also need to trim spaces to make it exactly like the SQL Server join\n",
    "    df_student_results['StudentName2'] = df_student_results['StudentName2'].str.strip()\n",
    "    df_student_enrol['Student2'] = df_student_enrol['Student2'].str.strip()\n",
    "\n",
    "    # Before we attempt to merge\n",
    "    # Only keep one of the duplicates from the EMIS\n",
    "    df_student_enrol.drop_duplicates(keep='last', inplace=True)\n",
    "    if testing: print('Total student enrol: ', len(df_student_enrol.index))\n",
    "\n",
    "    # isolate into a seperate DataFrame students with\n",
    "    # same name but different DoB, school, etc. (i.e. different students of same name)\n",
    "    df_student_enrol.duplicated(subset=['Student2'])\n",
    "    df_student_enrol_nonambiguous = df_student_enrol[~df_student_enrol.duplicated(subset=['Student2'], keep=False)]\n",
    "    df_student_enrol_ambiguous = df_student_enrol[df_student_enrol.duplicated(subset=['Student2'], keep=False)]\n",
    "    if testing: print('Total student enrol that are not ambiguous: ', len(df_student_enrol_nonambiguous.index))\n",
    "    if testing: print('Total student enrol that are ambiguous: ', len(df_student_enrol_ambiguous.index))\n",
    "    if testing: print('Check ambiguous + not ambiguous equals all enrolled (minus duplicates): ', len(df_student_enrol_nonambiguous.index) + len(df_student_enrol_ambiguous.index))\n",
    "    if testing: \n",
    "        print('df_student_enrol_nonambiguous') \n",
    "        display(df_student_enrol_nonambiguous.head(2))\n",
    "    df_student_enrol_ambiguous.sort_values(by=['Student2'])\n",
    "\n",
    "    # For now, process using only non-ambiguous student enrolment records\n",
    "    # It would only be possible to use non-ambiguous student enrolment records\n",
    "    # if the exams data would contain the correct school, DoB or other data\n",
    "    # that could disambiguate students with same name\n",
    "\n",
    "    # Merge student exams data with student enrolments\n",
    "    df_students_results_and_enrol = df_student_results.set_index('StudentName2').join(df_student_enrol_nonambiguous.set_index('Student2'), lsuffix='_caller', rsuffix='_other')\n",
    "    df_students_results_and_enrol = df_student_results.merge(df_student_enrol_nonambiguous, how='left', left_on='StudentName2', right_on='Student2', suffixes=('_from_exams', '_from_db'), indicator=False)\n",
    "    if testing: \n",
    "        print('df_students_results_and_enrol') \n",
    "        display(df_students_results_and_enrol.head(2))\n",
    "    \n",
    "    return df_students_results_and_enrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge student exams data with student enrollments\n",
    "# Working with the single student exams file (for testing)\n",
    "df_students_results_and_enrol = {}\n",
    "df_students_results_and_enrol[testname] = merge_exams_data_with_student_enrol_df(df_student_results[testname], df_student_enrol, True)\n",
    "print('df_students_results_and_enrol')\n",
    "df_students_results_and_enrol[testname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge student exams data with student enrollments\n",
    "# Working with all student exams files (~22 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "df_students_results_and_enrol_list = {}\n",
    "\n",
    "for file,df in tqdm(df_student_results_list.items()):\n",
    "    df_students_results_and_enrol_list[file] = merge_exams_data_with_student_enrol_df(df, df_student_enrol, False)\n",
    "\n",
    "df_students_results_and_enrol_list\n",
    "# Remove any None item from list (those DataFrames could not be merged)\n",
    "#df_students_results_and_enrol_list = list(filter(lambda x: x is not None, df_students_results_and_enrol_list))\n",
    "for k in tqdm(df_students_results_and_enrol_list):\n",
    "    if df_students_results_and_enrol_list[k] is None:\n",
    "        del df_students_results_and_enrol_list[k]\n",
    "        tqdm.write(\"None DataFrame, could not be merged, investigate file {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_results_and_enrol_list[list(df_students_results_and_enrol_list.keys()).pop()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list is to be confirmed and updated as necessary\n",
    "# If a school name is in an exam file but not in here we need to generate an error message\n",
    "# and update this list with the correct mapping to the canonical school ID\n",
    "schools_lookup_from_exams_byname = {\n",
    "    ' Ebeye Christian -Private': 'KWA105',\n",
    "    ' Ebeye SDA-Private Primary': 'KWA109',\n",
    "    ' Ine-Arno': 'ARN103',\n",
    "    'Aerok A-Aelonlaplap': 'AIL100',       \n",
    "    'Aerok A-Ailinglaplap': 'AIL100',\n",
    "    'Aerok A-Maloelap': 'MAL101',\n",
    "    'Aerok A-Maloeplap': 'MAL101',\n",
    "    'Aerok A-Medium': 'AIL100',\n",
    "    'Aerok A-Public ': 'AIL100',\n",
    "    'Aerok A-Public': 'AIL100',\n",
    "    'Aerok M-Maleolap': 'MAL101',\n",
    "    'Aerok M-Maloelap': 'MAL101',\n",
    "    'Aerok M-Northern': 'MAL101',\n",
    "    'Aerok M-Public': 'MAL101',\n",
    "    'Aerok Protestant-Private': 'AIL109', \n",
    "    'Aerok, A-Ailinglaplap': 'AIL100',\n",
    "    'Ailuk -Ailuk ': 'ALU101',\n",
    "    'Ailuk -Ailuk': 'ALU101',\n",
    "    'Ailuk Protestant-Private': 'ALU103',\n",
    "    'Ailuk -Public ': 'ALU101',\n",
    "    'Ailuk -Public': 'ALU101',\n",
    "    'Ailuk-Ailuk': 'ALU101',\n",
    "    'Ailuk-Ailuk': 'ALU101',\n",
    "    'Ailuk-Enejelaar': 'ALU102',\n",
    "    'Ailuk-Medium': 'ALU101',\n",
    "    'Ailuk-Northern': 'ALU101',\n",
    "    'Ailuk-Public ': 'ALU101',\n",
    "    'Ailuk-Public': 'ALU101',\n",
    "    'Airok A-Aelonlaplap': 'AIL100',\n",
    "    'Airok A-Ailinglaplap': 'AIL100',\n",
    "    'Airok A-Central': 'AIL100',\n",
    "    'Airok A-Public ': 'AIL100',\n",
    "    'Airok A-Public': 'AIL100',\n",
    "    'Airok M-Maloelap': 'MAL101',\n",
    "    'Airok M-Maloeplap': 'MAL101',\n",
    "    'Airok M-Mejit': 'MAL101',\n",
    "    'Airok M-Public': 'MAL101',\n",
    "    'Airok M-Small': 'MAL101',\n",
    "    'Airok Protestant-Private': 'AIL109',\n",
    "    'Airok  M-Maloelap': 'MAL101',\n",
    "    'Airok  M-Public': 'MAL101',\n",
    "    'Airok, M-Maloelap': 'MAL101',\n",
    "    'Ajeltake Chistian Academy-Majuro': 'MAJ102',\n",
    "    'Ajeltake Chistian Academy-Private Primary': 'MAJ102',\n",
    "    'Ajeltake Christian Academy-Majuro': 'MAJ102',\n",
    "    'Ajeltake Christian Academy-Private ': 'MAJ102',\n",
    "    'Ajeltake Christian Academy-Private Primary': 'MAJ102',\n",
    "    'Ajeltake Christian Academy-Private': 'MAJ102',\n",
    "    'Ajeltake Christian Academy-Public ': 'MAJ102',\n",
    "    'Ajeltake Christian Acedemy-Majuro': 'MAJ102',\n",
    "    'Ajeltake Christian Acedemy-Private': 'MAJ102',\n",
    "    'Ajeltake -Majuro': 'MAJ101',\n",
    "    'Ajeltake-Large': 'MAJ101',\n",
    "    'Ajeltake-Majuro': 'MAJ101',\n",
    "    'Ajeltake-Majuro': 'MAJ101',\n",
    "    'Ajeltake-Public ': 'MAJ101',\n",
    "    'Ajeltake-Public': 'MAJ101',\n",
    "    'Arno -Arno ': 'ARN101',\n",
    "    'Arno -Arno': 'ARN101',\n",
    "    'Arno -Public ': 'ARN101',\n",
    "    'Arno -Public': 'ARN101',\n",
    "    'Arno-Arno': 'ARN101',\n",
    "    'Arno-Arno': 'ARN101',\n",
    "    'Arno-Eastern': 'ARN101',\n",
    "    'Arno-Medium': 'ARN101',\n",
    "    'Arno-Public ': 'ARN101',\n",
    "    'Arno-Public': 'ARN101',\n",
    "    'Assumption High -Private Secondary': 'MAJ104',\n",
    "    'Assumption High School-Public Secondary': 'MAJ104',\n",
    "    'Assumption HS-Ailinglaplap': 'MAJ104',\n",
    "    'Assumption -Private': 'MAJ103',\n",
    "    'Assumption-Majuro': 'MAJ103',\n",
    "    'Assumption-Private ': 'MAJ103',\n",
    "    'Assumption-Private Primary': 'MAJ103',\n",
    "    'Assumption-Private Secondary': 'MAJ104',\n",
    "    'Assumption-Private': 'MAJ103',\n",
    "    'Assumption-Private': 'MAJ103',\n",
    "    'Assumption-Public ': 'MAJ103',\n",
    "    'Aur -Aur ': 'AUR101',\n",
    "    'Aur -Aur': 'AUR101',\n",
    "    'Aur -Public ': 'AUR101',\n",
    "    'Aur -Public': 'AUR101',\n",
    "    'Aur-Aur': 'AUR101',\n",
    "    'Aur-Aur': 'AUR101',\n",
    "    'Aur-Medium': 'AUR101',\n",
    "    'Aur-Northern': 'AUR101',\n",
    "    'Aur-Public ': 'AUR101',\n",
    "    'Aur-Public': 'AUR101',\n",
    "    'Bikarej -Arno': 'ARN102',\n",
    "    'Bikarej -Public ': 'ARN102',\n",
    "    'Bikarej-Arno ': 'ARN102',\n",
    "    'Bikarej-Arno': 'ARN102',\n",
    "    'Bikarej-Arno': 'ARN102',\n",
    "    'Bikarej-Eastern': 'ARN102',\n",
    "    'Bikarej-Medium': 'ARN102',\n",
    "    'Bikarej-Public ': 'ARN102',\n",
    "    'Bikarej-Public': 'ARN102',\n",
    "    'Bouj -Aelonlaplap': 'AIL101',\n",
    "    'Bouj -Ailinglaplap': 'AIL101',\n",
    "    'Bouj -Public': 'AIL101',\n",
    "    'Bouj-Aelonlaplap': 'AIL101',\n",
    "    'Bouj-Ailinglaplap': 'AIL101',\n",
    "    'Bouj-Public': 'AIL101',\n",
    "    'Buoj -Ailinglaplap': 'AIL101',\n",
    "    'Buoj-Aelonlaplap': 'AIL101',\n",
    "    'Buoj-Ailinglaplap': 'AIL101',\n",
    "    'Buoj-Central': 'AIL101',\n",
    "    'Buoj-Medium': 'AIL101',\n",
    "    'Buoj-Public ': 'AIL101',\n",
    "    'Buoj-Public': 'AIL101',\n",
    "    'Carlos -Kwajalein': 'KWA101',\n",
    "    'Carlos -Public ': 'KWA101',\n",
    "    'Carlos-Kwajalein': 'KWA101',\n",
    "    'Carlos-Kwajalein': 'KWA101',\n",
    "    'Carlos-Kwajlein': 'KWA101',\n",
    "    'Carlos-Public ': 'KWA101',\n",
    "    'Carlos-Public': 'KWA101',\n",
    "    'Carlos-Small': 'KWA101',\n",
    "    'Deaf Center-Majuro': 'MAJ131',\n",
    "    'Delap Calvary-Private': 'KSA103',\n",
    "    'Delap -Majuro': 'MAJ105',\n",
    "    'Delap SDA High -Private Secondary': 'MAJ108',\n",
    "    'Delap SDA High School-Public Secondary': 'MAJ108',\n",
    "    'Delap SDA HS-Ailinglaplap': 'MAJ108',\n",
    "    'Delap SDA -Majuro': 'MAJ107',\n",
    "    'Delap SDA -Private': 'MAJ107',\n",
    "    'Delap SDA-Majuro': 'MAJ107',\n",
    "    'Delap SDA-Private ': 'MAJ107',\n",
    "    'Delap SDA-Private Primary': 'MAJ107',\n",
    "    'Delap SDA-Private Secondary': 'MAJ108',\n",
    "    'Delap SDA-Private': 'MAJ107',\n",
    "    'Delap SDA-Private': 'MAJ107',\n",
    "    'Delap SDA-Public ': 'MAJ107',\n",
    "    'Delap  -Majuro': 'MAJ105',\n",
    "    'Delap  -Public': 'MAJ105',\n",
    "    'Delap-Majuro': 'MAJ105',\n",
    "    'Delap-Public': 'MAJ105',\n",
    "    'DES-Large': 'MAJ105',\n",
    "    'DES-Majuro': 'MAJ105',\n",
    "    'DES-Majuro': 'MAJ105',\n",
    "    'DES-Public ': 'MAJ105',\n",
    "    'DES-Public': 'MAJ105',\n",
    "    'Ebadon -Kwajalein': 'KWA102',\n",
    "    'Ebadon -Public ': 'KWA102',\n",
    "    'Ebadon -Public': 'KWA102',\n",
    "    'Ebadon-Kwajalein': 'KWA102',\n",
    "    'Ebadon-Kwajalein': 'KWA102',\n",
    "    'Ebadon-Kwajlein': 'KWA102',\n",
    "    'Ebadon-Public ': 'KWA102',\n",
    "    'Ebadon-Public': 'KWA102',\n",
    "    'Ebadon-Small': 'KWA102',\n",
    "    'Ebeye Calvary High -Private Secondary': 'KWA104',\n",
    "    'Ebeye Calvary High School-Private Secondary': 'KWA104',\n",
    "    'Ebeye Calvary HS-Ailinglaplap': 'KWA104',\n",
    "    'Ebeye Calvary -Kwajalein': 'KWA103',\n",
    "    'Ebeye Calvary -Private': 'KWA103',\n",
    "    'Ebeye Calvary-Private Primary': 'KWA103',\n",
    "    'Ebeye Calvary-Private Secondary': 'KWA104',\n",
    "    'Ebeye Calvary-Private': 'KWA103',\n",
    "    'Ebeye Calvary-Private': 'KWA103',\n",
    "    'Ebeye Calvary-Private': 'KWA103',\n",
    "    'Ebeye Calvary-Public ': 'KWA103',\n",
    "    'Ebeye Calvary-Public': 'KWA103',\n",
    "    'Ebeye Cavalry-Private Primary': 'KWA103',\n",
    "    'Ebeye Christian-Kwajalein': 'KWA105',\n",
    "    'Ebeye Christian-Private ': 'KWA105',\n",
    "    'Ebeye Christian-Private Primary': 'KWA105',\n",
    "    'Ebeye Christian-Private': 'KWA105',\n",
    "    'Ebeye Christian-Private': 'KWA105',\n",
    "    'Ebeye Christian-Private': 'KWA105',\n",
    "    'Ebeye Christian-Public ': 'KWA105',\n",
    "    'Ebeye Deaf Center -Kwajalein': 'KWA121',\n",
    "    'Ebeye Deaf Center -Kwajelein': 'KWA121',\n",
    "    'Ebeye Deaf Center -Private Secondary': 'KWA120',\n",
    "    'Ebeye Deaf Edu. -Private Secondary': 'KWA120',\n",
    "    'Ebeye Elementary-Kwajelein': 'KWA108',\n",
    "    'Ebeye Middle Public-Kwajalein': 'KWA107',\n",
    "    'Ebeye Middle School-Kwajalein': 'KWA107',\n",
    "    'Ebeye Middle School-Public': 'KWA107',\n",
    "    'Ebeye Public -Public ': 'KWA108',\n",
    "    'Ebeye Public-Kwajalein': 'KWA108',\n",
    "    'Ebeye Public-Kwajelein': 'KWA108',\n",
    "    'Ebeye Public-Kwajlein': 'KWA108',\n",
    "    'Ebeye Public-Large': 'KWA108',\n",
    "    'Ebeye Public-Public ': 'KWA108',\n",
    "    'Ebeye Public-Public': 'KWA108',\n",
    "    'Ebeye SDA High -Private Secondary': 'KWA110',\n",
    "    'Ebeye SDA High School-Private Secondary': 'KWA110',\n",
    "    'Ebeye SDA HS-Ailinglaplap': 'KWA110',\n",
    "    'Ebeye SDA -Kwajalein': 'KWA109',\n",
    "    'Ebeye SDA -Private': 'KWA109',\n",
    "    'Ebeye SDA-Private ': 'KWA109',\n",
    "    'Ebeye SDA-Private Primary': 'KWA109',\n",
    "    'Ebeye SDA-Private Secondary': 'KWA110',\n",
    "    'Ebeye SDA-Private': 'KWA109',\n",
    "    'Ebeye SDA-Private': 'KWA109',\n",
    "    'Ebeye SDA-Public ': 'KWA109',\n",
    "    'Ebon -Ebon ': 'EBO101',\n",
    "    'Ebon -Ebon': 'EBO101',\n",
    "    'Ebon -Public ': 'EBO101',\n",
    "    'Ebon -Public': 'EBO101',\n",
    "    'Ebon-Ebon': 'EBO101',\n",
    "    'Ebon-Ebon': 'EBO101',\n",
    "    'Ebon-Medium': 'EBO101',\n",
    "    'Ebon-Public ': 'EBO101',\n",
    "    'Ebon-Public': 'EBO101',\n",
    "    'Ebon-Southern': 'EBO101',\n",
    "    'EES/ Ejit??-Kili': 'KIL101',\n",
    "    'Ejit-Kili ': 'KIL101',\n",
    "    'Ejit-Kili/Bikini': 'KIL101',\n",
    "    'Ejit-Kili': 'KIL101',\n",
    "    'Ejit-Majuro': 'KIL101',\n",
    "    'Ejit-Medium': 'KIL101',\n",
    "    'Ejit-Public ': 'KIL101',\n",
    "    'Ejit-Public': 'KIL101',\n",
    "    'Ejit-Southern': 'KIL101',\n",
    "    'Enburr-Kwajalein': 'KWA111',\n",
    "    'Enejelaar -Ailuk ': 'ALU102',\n",
    "    'Enejelaar -Ailuk': 'ALU102',\n",
    "    'Enejelaar-Ailuk': 'ALU102',\n",
    "    'Enejelaar-Alluk': 'ALU102',\n",
    "    'Enejelaar-Northern': 'ALU102',\n",
    "    'Enejelaar-Public ': 'ALU102',\n",
    "    'Enejelaar-Public': 'ALU102',\n",
    "    'Enejelaar-Small': 'ALU102',\n",
    "    'Enejet -Mili': 'MIL101',\n",
    "    'Enejet -Public ': 'MIL101',\n",
    "    'Enejet -Public': 'MIL101',\n",
    "    'Enejet-Eastern': 'MIL101',\n",
    "    'Enejet-Enejet': 'MIL101',\n",
    "    'Enejet-Medium': 'MIL101',\n",
    "    'Enejet-Mili': 'MIL101',\n",
    "    'Enejet-Public ': 'MIL101',\n",
    "    'Enejet-Public': 'MIL101',\n",
    "    'Enekoion -Ebon': 'EBO102',\n",
    "    'Enekoion -Public': 'EBO102',\n",
    "    'Enekoion-Ebon': 'EBO102',\n",
    "    'Enekoion-Ebon': 'EBO102',\n",
    "    'Enekoion-Public ': 'EBO102',\n",
    "    'Enekoion-Public': 'EBO102',\n",
    "    'Enekoion-Small': 'EBO102',\n",
    "    'Enekoion-Southern': 'EBO102',\n",
    "    'Enewa -Aelonlaplap': 'AIL102',\n",
    "    'Enewa -Ailinglaplap': 'AIL102',\n",
    "    'Enewa -Public ': 'AIL102',\n",
    "    'Enewa -Public': 'AIL102',\n",
    "    'Enewa-Aelonlaplap': 'AIL102',\n",
    "    'Enewa-Ailinglaplap': 'AIL102',\n",
    "    'Enewa-Central': 'AIL102',\n",
    "    'Enewa-Public ': 'AIL102',\n",
    "    'Enewa-Public': 'AIL102',\n",
    "    'Enewa-Small': 'AIL102',\n",
    "    'Enewetak -Enewetak ': 'ENE101',\n",
    "    'Enewetak -Public ': 'ENE101',\n",
    "    'Enewetak-Eastern': 'ENE101',\n",
    "    'Enewetak-Enewetak': 'ENE101',\n",
    "    'Enewetak-Enewetak': 'ENE101',\n",
    "    'Enewetak-Public ': 'ENE101',\n",
    "    'Enewetak-Public': 'ENE101',\n",
    "    'Enniburr High School-Public Secondary': 'KWA119',\n",
    "    'Enniburr -Kwajalein': 'KWA111',\n",
    "    'Enniburr -Public ': 'KWA111',\n",
    "    'Enniburr -Public': 'KWA111',\n",
    "    'Enniburr-Kwajalein': 'KWA111',\n",
    "    'Enniburr-Kwajalein': 'KWA111',\n",
    "    'Enniburr-Kwajlein': 'KWA111',\n",
    "    'Enniburr-Medium': 'KWA111',\n",
    "    'Enniburr-Public ': 'KWA111',\n",
    "    'Enniburr-Public Secondary': 'KWA119',\n",
    "    'Enniburr-Public': 'KWA111',\n",
    "    'Father Hacker High School-Private Secondary': 'KWA118',\n",
    "    'Father Hacker HS-Ailinglaplap': 'KWA118',\n",
    "    'Father Hacker-Private Secondary': 'KWA118',\n",
    "    'Gem Chirstian School-Private Primary': 'KWA112',\n",
    "    'Gem Christian High School-Private Secondary': 'KWA113',\n",
    "    'Gem Christian -Private ': 'KWA112',\n",
    "    'Gem Christian School-Kwajalein': 'KWA113',\n",
    "    'Gem Christian School-Private ': 'KWA112',\n",
    "    'Gem Christian School-Private Primary': 'KWA112',\n",
    "    'Gem Christian School-Private': 'KWA112',\n",
    "    'Gem Christian School-Private': 'KWA112',\n",
    "    'Gem Christian School-Private': 'KWA112',\n",
    "    'Gem Christian School-Public ': 'KWA112',\n",
    "    'Gem High School-Private Secondary': 'KWA113',\n",
    "    'Gem HS-Ailinglaplap': 'KWA113',\n",
    "    'Gem -Private': 'KWA112',\n",
    "    'Gem-Private Secondary': 'KWA113',\n",
    "    'Imiej -Jaluit ': 'JAL101',\n",
    "    'Imiej -Jaluit': 'JAL101',\n",
    "    'Imiej -Public ': 'JAL101',\n",
    "    'Imiej -Public': 'JAL101',\n",
    "    'Imiej-Jaluit': 'JAL101',\n",
    "    'Imiej-Jaluit': 'JAL101',\n",
    "    'Imiej-Medium': 'JAL101',\n",
    "    'Imiej-Public ': 'JAL101',\n",
    "    'Imiej-Public': 'JAL101',\n",
    "    'Imiej-Southern': 'JAL101',\n",
    "    'Imroj -Jaluit': 'JAL102',\n",
    "    'Imroj Protestant-Private': 'JAL110',\n",
    "    'Imroj -Public ': 'JAL102',\n",
    "    'Imroj -Public': 'JAL102',\n",
    "    'Imroj -Southern': 'JAL102',\n",
    "    'Imroj-Jaluit': 'JAL102',\n",
    "    'Imroj-Jaluit': 'JAL102',\n",
    "    'Imroj-Medium': 'JAL102',\n",
    "    'Imroj-Public ': 'JAL102',\n",
    "    'Imroj-Public': 'JAL102',\n",
    "    'Imroj-Southern': 'JAL102',\n",
    "    'Ine -Arno': 'ARN103',\n",
    "    'Ine -Public ': 'ARN103',\n",
    "    'Ine -Public': 'ARN103',\n",
    "    'Ine-Arno ': 'ARN103',\n",
    "    'Ine-Arno': 'ARN103',\n",
    "    'Ine-Arno': 'ARN103',\n",
    "    'Ine-Eastern': 'ARN103',\n",
    "    'Ine-Medium': 'ARN103',\n",
    "    'Ine-Public ': 'ARN103',\n",
    "    'Ine-Public': 'ARN103',\n",
    "    'Jabat -Jabat': 'JAB101',\n",
    "    'Jabat-Central': 'JAB101',\n",
    "    'Jabat-Jabat': 'JAB101',\n",
    "    'Jabat-Public ': 'JAB101',\n",
    "    'Jabat-Public': 'JAB101',\n",
    "    'Jabnoden -Jaluit ': 'JAL103',\n",
    "    'Jabnoden -Jaluit': 'JAL103',\n",
    "    'Jabnoden -Public ': 'JAL103',\n",
    "    'Jabnoden -Public': 'JAL103',\n",
    "    'Jabnoden-Jaluit': 'JAL103',\n",
    "    'Jabnoden-Jaluit': 'JAL103',\n",
    "    'Jabnoden-Public ': 'JAL103',\n",
    "    'Jabnoden-Public': 'JAL103',\n",
    "    'Jabnodren-Jaluit': 'JAL103',\n",
    "    'Jabnodren-Public ': 'JAL103',\n",
    "    'Jabnodren-Southern': 'JAL103',\n",
    "    'Jabonden-Jaluit': 'JAL103',\n",
    "    'Jabor -Jaluit ': 'JAL104',\n",
    "    'Jabor -Jaluit': 'JAL104',\n",
    "    'Jabor -Public ': 'JAL104',\n",
    "    'Jabor -Public': 'JAL104',\n",
    "    'Jabor-Jaluit': 'JAL104',\n",
    "    'Jabor-Jaluit': 'JAL104',\n",
    "    'Jabor-Medium': 'JAL104',\n",
    "    'Jabor-Public ': 'JAL104',\n",
    "    'Jabor-Public': 'JAL104',\n",
    "    'Jabor-Southern': 'JAL104',\n",
    "    'Jabot -Public': 'JAB101',\n",
    "    'Jabro -Private': 'KWA115',\n",
    "    'Jabro-Private': 'KWA115',\n",
    "    'Jah -Ailinglaplap': 'AIL103',\n",
    "    'Jah -Public ': 'AIL103',\n",
    "    'Jah -Public': 'AIL103',\n",
    "    'Jah-Aelonlaplap': 'AIL103',\n",
    "    'Jah-Ailinglaplap': 'AIL103',\n",
    "    'Jah-Central': 'AIL103',\n",
    "    'Jah-Public ': 'AIL103',\n",
    "    'Jah-Public': 'AIL103',\n",
    "    'Jah-Small': 'AIL103',\n",
    "    'Jaluit -Jaluit ': 'JAL105',\n",
    "    'Jaluit -Jaluit': 'JAL105',\n",
    "    'Jaluit -Public ': 'JAL105',\n",
    "    'Jaluit -Public': 'JAL105',\n",
    "    'Jaluit-???': 'JAL105',\n",
    "    'Jaluit-Jaljuit': 'JAL105',\n",
    "    'Jaluit-Jaluit': 'JAL105',\n",
    "    'Jaluit-Jaluit': 'JAL105',\n",
    "    'Jaluit-Medium': 'JAL105',\n",
    "    'Jaluit-Public ': 'JAL105',\n",
    "    'Jaluit-Public': 'JAL105',\n",
    "    'Jaluit-Southern': 'JAL105',\n",
    "    'Jang -Public ': 'MAL102',\n",
    "    'Jang-Maloelap': 'MAL102',\n",
    "    'Jang-Maloelap': 'MAL102',\n",
    "    'Jang-Maloeplap': 'MAL102',\n",
    "    'Jang-Northern': 'MAL102',\n",
    "    'Jang-Public ': 'MAL102',\n",
    "    'Jang-Public': 'MAL102',\n",
    "    'Jang-Small': 'MAL102',\n",
    "    'Japo -Arno': 'ARN104',\n",
    "    'Japo -Public ': 'ARN104',\n",
    "    'Japo-Arno ': 'ARN104',\n",
    "    'Japo-Arno': 'ARN104',\n",
    "    'Japo-Arno': 'ARN104',\n",
    "    'Japo-Eastern': 'ARN104',\n",
    "    'Japo-Medium': 'ARN104',\n",
    "    'Japo-Public ': 'ARN104',\n",
    "    'Japo-Public': 'ARN104',\n",
    "    'Jebal -Likiep ': 'LIK101',\n",
    "    'Jebal -Likiep': 'LIK101',\n",
    "    'Jebat-Jebat': 'JAB101',\n",
    "    'Jebro High School-Private Secondary': 'KWA114',\n",
    "    'Jebro High School-Public Secondary': 'KWA114',\n",
    "    'Jebro HS-Ailinglaplap': 'KWA114',\n",
    "    'Jebro Kabua-Private': 'KWA115',\n",
    "    'Jebro-Kwajalein': 'KWA115',\n",
    "    'Jebro-Private ': 'KWA115',\n",
    "    'Jebro-Private Primary': 'KWA115',\n",
    "    'Jebro-Private Secondary': 'KWA114',\n",
    "    'Jebro-Private': 'KWA115',\n",
    "    'Jebro-Private': 'KWA115',\n",
    "    'Jebro-Private': 'KWA115',\n",
    "    'Jebro-Public ': 'KWA115',\n",
    "    'Jebwan -Ailinglaplap': 'AIL105',\n",
    "    'Jebwan-Aelonlaplap': 'AIL105',\n",
    "    'Jebwan-Ailinglaplap': 'AIL105',\n",
    "    'Jebwan-Central': 'AIL105',\n",
    "    'Jebwan-Public ': 'AIL105',\n",
    "    'Jebwan-Public': 'AIL105',\n",
    "    'Jebwan-Small': 'AIL105',\n",
    "    'Jeh -Ailinglaplap': 'AIL104',\n",
    "    'Jeh -Public ': 'AIL104',\n",
    "    'Jeh -Public': 'AIL104',\n",
    "    'Jeh SDA-Private': 'AIL110',\n",
    "    'Jeh-Aelonlaplap': 'AIL104',\n",
    "    'Jeh-Ailinglaplap': 'AIL104',\n",
    "    'Jeh-Central': 'AIL104',\n",
    "    'Jeh-Medium': 'AIL104',\n",
    "    'Jeh-Public ': 'AIL104',\n",
    "    'Jeh-Public': 'AIL104',\n",
    "    'Jepal -Public ': 'LIK101',\n",
    "    'Jepal-Likiep': 'LIK101',\n",
    "    'Jepal-Likiep': 'LIK101',\n",
    "    'Jepal-Northern': 'LIK101',\n",
    "    'Jepal-Public ': 'LIK101',\n",
    "    'Jepal-Public': 'LIK101',\n",
    "    'Jepal-Small': 'LIK101',\n",
    "    'JHS-Ailinglaplap': 'JAL106',\n",
    "    'JHS-Public Secondary': 'JAL106',\n",
    "    'Jobwon -Ailinglaplap': 'AIL105',\n",
    "    'KAHS-Ailinglaplap': 'KWA116',\n",
    "    'KAHS-Public Secondary': 'KWA116',\n",
    "    'Kattiej -Aelonlaplap': 'AIL106',\n",
    "    'Kattiej -Ailinglaplap': 'AIL106',\n",
    "    'Kattiej -Public ': 'AIL106',\n",
    "    'Kattiej-Aelonlaplap': 'AIL106',\n",
    "    'Kattiej-Ailinglaplap': 'AIL106',\n",
    "    'Kattiej-Central': 'AIL106',\n",
    "    'Kattiej-Public ': 'AIL106',\n",
    "    'Kattiej-Public': 'AIL106',\n",
    "    'Kattiej-Small': 'AIL106',\n",
    "    'Kaven -Maloelap': 'MAL103',\n",
    "    'Kaven -Public ': 'MAL103',\n",
    "    'Kaven-Maleolap': 'MAL103',\n",
    "    'Kaven-Maloelap': 'MAL103',\n",
    "    'Kaven-Maloeplap': 'MAL103',\n",
    "    'Kaven-Northern': 'MAL103',\n",
    "    'Kaven-Public ': 'MAL103',\n",
    "    'Kaven-Public': 'MAL103',\n",
    "    'Kaven-Small': 'MAL103',\n",
    "    'Kilange -Arno': 'ARN105',\n",
    "    'Kilange -Public ': 'ARN105',\n",
    "    'Kilange -Public': 'ARN105',\n",
    "    'Kilange-Arno ': 'ARN105',\n",
    "    'Kilange-Arno': 'ARN105',\n",
    "    'Kilange-Arno': 'ARN105',\n",
    "    'Kilange-Eastern': 'ARN105',\n",
    "    'Kilange-Medium': 'ARN105',\n",
    "    'Kilange-Public ': 'ARN105',\n",
    "    'Kilange-Public': 'ARN105',\n",
    "    'Kili -Kili ': 'KIL102',\n",
    "    'Kili -Kili': 'KIL102',\n",
    "    'Kili -Public ': 'KIL102',\n",
    "    'Kili -Southern': 'KIL102',\n",
    "    'Kili-Kili/Bikini': 'KIL102',\n",
    "    'Kili-Kili': 'KIL102',\n",
    "    'Kili-Medium': 'KIL102',\n",
    "    'Kili-Public ': 'KIL102',\n",
    "    'Kili-Public': 'KIL102',\n",
    "    'Kili-Southern': 'KIL102',\n",
    "    'Kinange-Arno': 'ARN105',\n",
    "    'Lae -Lae ': 'LAE101',\n",
    "    'Lae -Lae': 'LAE101',\n",
    "    'Lae -Public ': 'LAE101',\n",
    "    'Lae -Public': 'LAE101',\n",
    "    'Lae-Lae ': 'LAE101',\n",
    "    'Lae-Lae': 'LAE101',\n",
    "    'Lae-Medium': 'LAE101',\n",
    "    'Lae-Public ': 'LAE101',\n",
    "    'Lae-Public': 'LAE101',\n",
    "    'Lae-Western': 'LAE101',\n",
    "    'Laura Christian Academy-Majuro': 'MAJ129',\n",
    "    'Laura Christian Academy-Private': 'MAJ129',\n",
    "    'Laura High School-Majuro': 'MAJ111',\n",
    "    'Laura High School-Public': 'MAJ111',\n",
    "    'Laura -Majuro': 'MAJ109',\n",
    "    'Laura Protestant-Private': 'MAJ133',\n",
    "    'Laura Public -Public ': 'MAJ109',\n",
    "    'Laura Public-Large': 'MAJ109',\n",
    "    'Laura Public-Majuro': 'MAJ109',\n",
    "    'Laura Public-Majuro': 'MAJ109',\n",
    "    'Laura Public-Public ': 'MAJ109',\n",
    "    'Laura Public-Public': 'MAJ109',\n",
    "    'Laura SDA -Majuro': 'MAJ110',\n",
    "    'Laura SDA -Private': 'MAJ110',\n",
    "    'Laura SDA-Majuro': 'MAJ110',\n",
    "    'Laura SDA-Private ': 'MAJ110',\n",
    "    'Laura SDA-Private Primary': 'MAJ110',\n",
    "    'Laura SDA-Private': 'MAJ110',\n",
    "    'Laura SDA-Public ': 'MAJ110',\n",
    "    'Laura-Majuro': 'MAJ109',\n",
    "    'Laura-Public ': 'MAJ109',\n",
    "    'LHS -Ailinglaplap': 'MAJ111',\n",
    "    'LHS-Ailinglaplap': 'MAJ111',\n",
    "    'LHS-Majuro': 'MAJ111',\n",
    "    'LHS-Public Secondary': 'MAJ111',\n",
    "    'LHS-Public': 'MAJ111',\n",
    "    'Lib -Lib ': 'LIB101',\n",
    "    'Lib -Lib': 'LIB101',\n",
    "    'Lib-Lib': 'LIB101',\n",
    "    'LIB-LIB': 'LIB101',\n",
    "    'Lib-Medium': 'LIB101',\n",
    "    'Lib-Public ': 'LIB101',\n",
    "    'Lib-Public': 'LIB101',\n",
    "    'Lib-Western': 'LIB101',\n",
    "    'Life Skills Academy-Majuro': 'MAJ113',\n",
    "    'Life Skills Academy-Public': 'MAJ113',\n",
    "    'Likiep -Likiep ': 'LIK102',\n",
    "    'Likiep -Likiep': 'LIK102',\n",
    "    'Likiep -Public ': 'LIK102',\n",
    "    'Likiep -Public': 'LIK102',\n",
    "    'Likiep-Likiep': 'LIK102',\n",
    "    'Likiep-Likiep': 'LIK102',\n",
    "    'Likiep-Medium': 'LIK102',\n",
    "    'Likiep-Northern': 'LIK102',\n",
    "    'Likiep-Public ': 'LIK102',\n",
    "    'Likiep-Public': 'LIK102',\n",
    "    'Loen -Namu ': 'NAU101',\n",
    "    'Loen -Namu': 'NAU101',\n",
    "    'Loen -Public ': 'NAU101',\n",
    "    'Loen -Public': 'NAU101',\n",
    "    'Loen-Central': 'NAU101',\n",
    "    'Loen-Medium': 'NAU101',\n",
    "    'Loen-Namu': 'NAU101',\n",
    "    'Loen-Namu': 'NAU101',\n",
    "    'Loen-Public ': 'NAU101',\n",
    "    'Loen-Public': 'NAU101',\n",
    "    'Long Isand-Majuro': 'MAJ112',\n",
    "    'Long Island-Majuro': 'MAJ112',\n",
    "    'Long Island-Public ': 'MAJ112',\n",
    "    'Long Island-Public': 'MAJ112',\n",
    "    'Longar -Arno': 'ARN106',\n",
    "    'Longar -Public ': 'ARN106',\n",
    "    'Longar-Arno ': 'ARN106',\n",
    "    'Longar-Arno': 'ARN106',\n",
    "    'Longar-Arno': 'ARN106',\n",
    "    'Longar-Eastern': 'ARN106',\n",
    "    'Longar-Medium': 'ARN106',\n",
    "    'Longar-Public ': 'ARN106',\n",
    "    'Longar-Public': 'ARN106',\n",
    "    'Lukoj-Arno': 'ARN107',\n",
    "    'Lukoj-Eastern': 'ARN107',\n",
    "    'Lukoj-Public': 'ARN107',\n",
    "    'Lukoj-Small': 'ARN107',\n",
    "    'Lukonwod -Mili': 'MIL102',\n",
    "    'Lukonwod -Public': 'MIL102',\n",
    "    'Lukonwod-Eastern': 'MIL102',\n",
    "    'Lukonwod-Enewetak': 'ENE101',\n",
    "    'Lukonwod-Lukonwod': 'MIL102',\n",
    "    'Lukonwod-Mili': 'MIL102',\n",
    "    'Lukonwod-Mili': 'MIL102',\n",
    "    'Lukonwod-Public ': 'MIL102',\n",
    "    'Lukonwod-Public': 'MIL102',\n",
    "    'Lukonwod-Small': 'MIL102',\n",
    "    'Lukunwod-Mili': 'MIL102',\n",
    "    'Mae -Namu ': 'NAU102',\n",
    "    'Mae -Public ': 'NAU102',\n",
    "    'Mae-Central': 'NAU102',\n",
    "    'Mae-Namu': 'NAU102',\n",
    "    'Mae-Namu': 'NAU102',\n",
    "    'Mae-Public ': 'NAU102',\n",
    "    'Mae-Public': 'NAU102',\n",
    "    'Majken -Namu': 'NAU103',\n",
    "    'Majken-Central': 'NAU103',\n",
    "    'Majken-Medium': 'NAU103',\n",
    "    'Majken-Namu': 'NAU103',\n",
    "    'Majken-Public ': 'NAU103',\n",
    "    'Majken-Public': 'NAU103',\n",
    "    'Majkin -Namu': 'NAU103',\n",
    "    'Majkin -Public': 'NAU103',\n",
    "    'Majkin-Central': 'NAU103',\n",
    "    'Majkin-Namu': 'NAU103',\n",
    "    'Majkin-Public ': 'NAU103',\n",
    "    'Majkin-Public': 'NAU103',\n",
    "    'Majuro Baptist Academy-Private Primary': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Majuro': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Private ': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Private Primary': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Private Secondary': 'MAJ115',\n",
    "    'Majuro Baptist Christian Academy-Private': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Private': 'MAJ114',\n",
    "    'Majuro Baptist Christian Academy-Public ': 'MAJ114',\n",
    "    'Majuro Baptist Christian-Private': 'MAJ114',\n",
    "    'Majuro Baptist HS-Ailinglaplap': 'MAJ115',\n",
    "    'Majuro Baptist-Private': 'MAJ114',\n",
    "    'Majuro Coop High -Private Secondary': 'MAJ117',\n",
    "    'Majuro Coop HS-Ailinglaplap': 'MAJ117',\n",
    "    'Majuro Cooperative High School-Private Secondary': 'MAJ117',\n",
    "    'Majuro Coop-Majuro': 'MAJ116',\n",
    "    'Majuro Coop-Private ': 'MAJ116',\n",
    "    'Majuro Coop-Private Primary': 'MAJ116',\n",
    "    'Majuro Coop-Private Secondary': 'MAJ117',\n",
    "    'Majuro Coop-Private': 'MAJ116',\n",
    "    'Majuro Coop-Private': 'MAJ116',\n",
    "    'Majuro Coop-Public ': 'MAJ116',\n",
    "    'Majuro Deaf Center -Public ': 'MAJ131',\n",
    "    'Majuro Deaf Center-Majuro': 'MAJ131',\n",
    "    'Majuro Deaf Center-Private Secondary': 'MAJ132',\n",
    "    'Majuro Deaf School-Majuro': 'MAJ131',\n",
    "    'Majuro Middle School-Majuro': 'MAJ120',\n",
    "    'Majuro Middle School-Public': 'MAJ120',\n",
    "    'Marshall Christian High School-Private Secondary': 'MAJ118',\n",
    "    'Marshall Christian High-Private Secondary': 'MAJ118',\n",
    "    'Marshall Christian-Private Secondary': 'MAJ118',\n",
    "    'Marshall Islands High School-Majuro': 'MAJ118',\n",
    "    'Marshall Islands High School-Public': 'MAJ118',\n",
    "    'Marshalls Christian High School-Private': 'MAJ118',\n",
    "    'Matolen -Arno': 'ARN108',\n",
    "    'Matolen -Public': 'ARN108',\n",
    "    'Matolen-Arno ': 'ARN108',\n",
    "    'Matolen-Arno': 'ARN108',\n",
    "    'Matolen-Arno': 'ARN108',\n",
    "    'Matolen-Eastern': 'ARN108',\n",
    "    'Matolen-Medium': 'ARN108',\n",
    "    'Matolen-Public ': 'ARN108',\n",
    "    'Matolen-Public': 'ARN108',\n",
    "    'MCHS -Ailinglaplap': 'MAJ117',\n",
    "    'MCHS-Private Secondary': 'MAJ118',\n",
    "    'MCHS-Public Secondary': 'MAJ118',\n",
    "    'MDEC-Majuro': 'MAJ131',\n",
    "    'MDEC-Public': 'MAJ131',\n",
    "    'MDED-Majuro': 'MAJ131',\n",
    "    'Mejatto -Mejatto ': 'RON101',\n",
    "    'Mejatto -Public': 'RON101',\n",
    "    'Mejatto -Rongelap': 'RON101',\n",
    "    'Mejatto-Kwajalein': 'RON101',\n",
    "    'Mejatto-Maloeplap': 'RON101',\n",
    "    'Mejatto-Medium': 'RON101',\n",
    "    'Mejatto-Mejatto': 'RON101',\n",
    "    'Mejatto-Public': 'RON101',\n",
    "    'Mejatto-Western': 'RON101',\n",
    "    'Mejel -Ailinglaplap': 'AIL107',\n",
    "    'Mejel -Public': 'AIL107',\n",
    "    'Mejel  -Aelonlaplap': 'AIL107',\n",
    "    'Mejel-Aelonlaplap': 'AIL107',\n",
    "    'Mejel-Ailinglaplap': 'AIL107',\n",
    "    'Mejel-Central': 'AIL107',\n",
    "    'Mejel-Public ': 'AIL107',\n",
    "    'Mejel-Public': 'AIL107',\n",
    "    'Mejel-Small': 'AIL107',\n",
    "    'Mejirirok -Jaluit': 'JAL107',\n",
    "    'Mejit -Mejit ': 'MEJ101',\n",
    "    'Mejit -Mejit': 'MEJ101',\n",
    "    'Mejit -Public ': 'MEJ101',\n",
    "    'Mejit -Public': 'MEJ101',\n",
    "    'Mejit-Medium': 'MEJ101',\n",
    "    'Mejit-Mejit': 'MEJ101',\n",
    "    'Mejit-Mejit': 'MEJ101',\n",
    "    'Mejit-Northern': 'MEJ101',\n",
    "    'Mejit-Public ': 'MEJ101',\n",
    "    'Mejit-Public': 'MEJ101',\n",
    "    'Mejrirok -Jaluit ': 'JAL107',\n",
    "    'Mejrirok -Jaluit': 'JAL107',\n",
    "    'Mejrirok-Jaluit': 'JAL107',\n",
    "    'Mejrirok-Public': 'JAL107',\n",
    "    'Mejrirok-Southern': 'JAL107',\n",
    "    'Mejurirok-Jaluit': 'JAL107',\n",
    "    'Mejurirok-Medium': 'JAL107',\n",
    "    'Mejurirok-Public ': 'JAL107',\n",
    "    'Mejurirok-Public': 'JAL107',\n",
    "    'Mejurirok-Southern': 'JAL107',\n",
    "    'Melang -Likiep': 'LIK103',\n",
    "    'Melang -Public': 'LIK103',\n",
    "    'Melang-Likiep': 'LIK103',\n",
    "    'Melang-Northern': 'LIK103',\n",
    "    'Melang-Public ': 'LIK103',\n",
    "    'Melang-Public': 'LIK103',\n",
    "    'Melang-Small': 'LIK103',\n",
    "    'Melan-Likiep': 'LIK103',\n",
    "    'Melan-Public ': 'LIK103',\n",
    "    'Melan-Public': 'LIK103',\n",
    "    'Middle School-Public': 'MAJ120',\n",
    "    'MIHS -Ailinglaplap': 'MAJ119',\n",
    "    'MIHS-Public Secondary': 'MAJ119',\n",
    "    'Mili -Mili': 'MIL103',\n",
    "    'Mili -Public': 'MIL103',\n",
    "    'Mili-Eastern': 'MIL103',\n",
    "    'Mili-Mili': 'MIL103',\n",
    "    'Mili-Mili': 'MIL103',\n",
    "    'Mili-Public ': 'MIL103',\n",
    "    'Mili-Public': 'MIL103',\n",
    "    'MMS-Majuro': 'MAJ120',\n",
    "    'Nallo -Mili': 'MIL104',\n",
    "    'Nallo -Public ': 'MIL104',\n",
    "    'Nallo -Public': 'MIL104',\n",
    "    'Nallo-Eastern': 'MIL104',\n",
    "    'Nallo-Jaluit': 'MIL104',\n",
    "    'Nallo-Medium': 'MIL104',\n",
    "    'Nallo-Mili': 'MIL104',\n",
    "    'Nallo-Mili': 'MIL104',\n",
    "    'Nallo-Public ': 'MIL104',\n",
    "    'Nallo-Public': 'MIL104',\n",
    "    'Namdrik -Namdrik ': 'NAM101',\n",
    "    'Namdrik -Namdrik': 'NAM101',\n",
    "    'Namdrik -Public ': 'NAM101',\n",
    "    'Namdrik -Public': 'NAM101',\n",
    "    'Namdrik-Large': 'NAM101',\n",
    "    'Namdrik-Namdrik': 'NAM101',\n",
    "    'Namdrik-Namdrik': 'NAM101',\n",
    "    'Namdrik-Public ': 'NAM101',\n",
    "    'Namdrik-Public': 'NAM101',\n",
    "    'Namdrik-Southern': 'NAM101',\n",
    "    'Namu -Namu ': 'NAU104',\n",
    "    'Namu-Central': 'NAU104',\n",
    "    'Namu-Namu': 'NAU104',\n",
    "    'Namu-Public ': 'NAU104',\n",
    "    'Namu-Public': 'NAU104',\n",
    "    'Namu-Small': 'NAU104',\n",
    "    'Narmej -Jaluit': 'JAL108',\n",
    "    'Narmej -Public ': 'JAL108',\n",
    "    'Narmej-Jaluit': 'JAL108',\n",
    "    'Narmej-Jaluit': 'JAL108',\n",
    "    'Narmej-Medium': 'JAL108',\n",
    "    'Narmej-Public ': 'JAL108',\n",
    "    'Narmej-Public': 'JAL108',\n",
    "    'Narmej-Southern': 'JAL108',\n",
    "    'Narmij-Jaluit ': 'JAL108',\n",
    "    'Narmij-Southern': 'JAL108',\n",
    "    'NDES -Majuro': 'MAJ126',\n",
    "    'NDES-Majuro': 'MAJ126',\n",
    "    'NIHS -Ailinglaplap': 'WTH101',\n",
    "    'NIHS -Public Secondary': 'WTH101',\n",
    "    'NIHS-Private Secondary': 'WTH101',\n",
    "    'NIHS-Public Secondary': 'WTH101',\n",
    "    'NIHS-Wotje': 'WTH101',\n",
    "    'North Delap-Majuro': 'MAJ126',\n",
    "    'North Delap-Public ': 'MAJ126',\n",
    "    'North Delap-Public': 'MAJ126',\n",
    "    'NVTI-Majuro': 'MAJ128',\n",
    "    'Ollet -Maloelap': 'MAL104',\n",
    "    'Ollet -Maloeplap': 'MAL104',\n",
    "    'Ollet -Ollet ': 'MAL104',\n",
    "    'Ollet -Public ': 'MAL104',\n",
    "    'Ollet -Public': 'MAL104',\n",
    "    'Ollet-Maloelap': 'MAL104',\n",
    "    'Ollet-Maloelap': 'MAL104',\n",
    "    'Ollet-Maloeplap': 'MAL104',\n",
    "    'Ollet-Northern': 'MAL104',\n",
    "    'Ollet-Public ': 'MAL104',\n",
    "    'Ollet-Public': 'MAL104',\n",
    "    'Ollet-Small': 'MAL104',\n",
    "    'Queen of Peace-Kwajalein': 'KWA117',\n",
    "    'Queen of Peace-Private ': 'KWA117',\n",
    "    'Queen of Peace-Private Primary': 'KWA117',\n",
    "    'Queen of Peace-Private': 'KWA117',\n",
    "    'Queen of Peace-Private': 'KWA117',\n",
    "    'Queen of Peace-Private': 'KWA117',\n",
    "    'Queen of Peace-Public ': 'KWA117',\n",
    "    'Rairok -Majuro': 'MAJ121',\n",
    "    'Rairok -Public ': 'MAJ121',\n",
    "    'Rairok -Public': 'MAJ121',\n",
    "    'Rairok-Large': 'MAJ121',\n",
    "    'Rairok-Majuro ': 'MAJ121',\n",
    "    'Rairok-Majuro': 'MAJ121',\n",
    "    'Rairok-Majuro': 'MAJ121',\n",
    "    'Rairok-Public ': 'MAJ121',\n",
    "    'Rairok-Public': 'MAJ121',\n",
    "    'RES-Large': 'MAJ122',\n",
    "    'RES-Majuro': 'MAJ122',\n",
    "    'RES-Majuro': 'MAJ122',\n",
    "    'RES-Public ': 'MAJ122',\n",
    "    'RES-Public': 'MAJ122',\n",
    "    'Rita Chrisitan-Private': 'MAJ123',\n",
    "    'Rita Christian High School-Private Secondary': 'MAJ124',\n",
    "    'Rita Christian High-Private Secondary': 'MAJ124',\n",
    "    'Rita Christian HS-Ailinglaplap': 'MAJ124',\n",
    "    'Rita Christian -Private': 'MAJ123',\n",
    "    'Rita Christian-Majuro': 'MAJ123',\n",
    "    'Rita Christian-nan': 'MAJ124',\n",
    "    'Rita Christian-Private ': 'MAJ123',\n",
    "    'Rita Christian-Private Primary': 'MAJ123',\n",
    "    'Rita Christian-Private Secondary': 'MAJ124',\n",
    "    'Rita Christian-Private Seconday': 'MAJ124',\n",
    "    'Rita Christian-Private': 'MAJ123',\n",
    "    'Rita Christian-Private': 'MAJ123',\n",
    "    'Rita Christian-Public ': 'MAJ123',\n",
    "    'Rita -Majuro': 'MAJ122',  \n",
    "    'Rita-Majuro': 'MAJ122',\n",
    "    'Rita-Public': 'MAJ122',\n",
    "    'Rongrong Christian Academy-Private': 'MAJ125',\n",
    "    'Rongrong Christian Elementary-Private': 'MAJ125',\n",
    "    'Rongrong Christian High-Private Secondary': 'MAJ118',\n",
    "    'Rongrong Christian School-Private': 'MAJ118',\n",
    "    'RongRong Christian-Private Primary': 'MAJ125',\n",
    "    'Rongrong Christian-Private': 'MAJ125',\n",
    "    'Rongrong Elementary-Majuro': 'MAJ125',\n",
    "    'Rongrong Elementary-Private': 'MAJ125',\n",
    "    'RongROng -Majuro': 'MAJ125',\n",
    "    'Rongrong-Majuro': 'MAJ125',\n",
    "    'RongRong-Majuro': 'MAJ125',\n",
    "    'Rongrong-Private ': 'MAJ125',\n",
    "    'Rongrong-Private': 'MAJ125',\n",
    "    'RongRong-Private': 'MAJ125',\n",
    "    'Rongrong-Public ': 'MAJ125',\n",
    "    'Rongrong-RongRong': 'MAJ125',\n",
    "    'Rongrong-Rongrong': 'MAJ125',\n",
    "    'Ronrong-Ronrong': 'MAJ125',\n",
    "    'St. Joseph -Jaluit': 'JAL109',\n",
    "    'St. Joseph -Private': 'JAL109',\n",
    "    'St. Joseph-Jaluit': 'JAL109',\n",
    "    'St. Joseph-Private ': 'JAL109',\n",
    "    'St. Joseph-Private Primary': 'JAL109',\n",
    "    'St. Joseph-Private': 'JAL109',\n",
    "    'St. Joseph-Private': 'JAL109',\n",
    "    'St. Joseph-Private': 'JAL109',\n",
    "    'St. Paul-Arno': 'ARN109',\n",
    "    'St. Paul-Private': 'ARN109',\n",
    "    'St. Paul-Private': 'ARN109',\n",
    "    'St. Thomas-Private': 'WTH104', \n",
    "    'St. Thomas-Wotje': 'WTH104',\n",
    "    'St.Joseph-Jaluit': 'JAL109',\n",
    "    'St.Joseph-Private': 'JAL109',\n",
    "    'St.Joseph-Public ': 'JAL109',\n",
    "    'St.Paul-Arno': 'ARN109',\n",
    "    'Tarawa -Maloelap': 'MAL105',\n",
    "    'Tarawa -Public ': 'MAL105',\n",
    "    'Tarawa -Public': 'MAL105',\n",
    "    'Tarawa-Majuro': 'MAL105',\n",
    "    'Tarawa-Maloelap': 'MAL105',\n",
    "    'Tarawa-Maloelap': 'MAL105',\n",
    "    'Tarawa-Maloeplap': 'MAL105',\n",
    "    'Tarawa-Medium': 'MAJ105',\n",
    "    'Tarawa-Northern': 'MAL105',\n",
    "    'Tarawa-Public ': 'MAL105',\n",
    "    'Tarawa-Public': 'MAL105',\n",
    "    'Tinak -Arno': 'ARN109',\n",
    "    'Tinak -Public ': 'ARN109',\n",
    "    'Tinak -Public': 'ARN109',\n",
    "    'Tinak-Arno ': 'ARN109',\n",
    "    'Tinak-Arno': 'ARN109',\n",
    "    'Tinak-Eastern': 'ARN109',\n",
    "    'Tinak-Medium': 'ARN109',\n",
    "    'Tinak-Public ': 'ARN109',\n",
    "    'Tinak-Public': 'ARN109',\n",
    "    'Tobal -Aur': 'AUR102',\n",
    "    'Tobal -Public ': 'AUR102',\n",
    "    'Tobal-Aur': 'AUR102',\n",
    "    'Tobal-Aur': 'AUR102',\n",
    "    'Tobal-Medium': 'AUR102',\n",
    "    'Tobal-Northern': 'AUR102',\n",
    "    'Tobal-Public ': 'AUR102',\n",
    "    'Tobal-Public': 'AUR102',\n",
    "    'Toka -Ebon': 'EBO103',\n",
    "    'Toka -Public ': 'EBO103',\n",
    "    'Toka -Public': 'EBO103',\n",
    "    'Toka-Ebon': 'EBO103',\n",
    "    'Toka-Ebon': 'EBO103',\n",
    "    'Toka-Medium': 'EBO103',\n",
    "    'Toka-Public ': 'EBO103',\n",
    "    'Toka-Public': 'EBO103',\n",
    "    'Toka-Southern': 'EBO103',\n",
    "    'Tokewa -Mili': 'MIL105',\n",
    "    'Tokewa -Public ': 'MIL105',\n",
    "    'Tokewa -Public': 'MIL105',\n",
    "    'Tokewa-Eastern': 'MIL105',\n",
    "    'Tokewa-Mili': 'MIL105',\n",
    "    'Tokewa-Public ': 'MIL105',\n",
    "    'Tokewa-Public': 'MIL105',\n",
    "    'Tokewa-Small': 'MIL105',\n",
    "    'Tutu -Arno': 'ARN110',\n",
    "    'Tutu -Public ': 'ARN110',\n",
    "    'Tutu-Arno ': 'ARN110',\n",
    "    'Tutu-Arno': 'ARN110',\n",
    "    'Tutu-Eastern': 'ARN110',\n",
    "    'Tutu-Public ': 'ARN110',\n",
    "    'Tutu-Public': 'ARN110',\n",
    "    'Tutu-Small': 'ARN110',\n",
    "    'UES-Large': 'ARN111',\n",
    "    'UES-Majuro': 'ARN111',\n",
    "    'UES-Majuro': 'MAJ126',\n",
    "    'UES-Public ': 'ARN111',\n",
    "    'UES-Public': 'ARN111',\n",
    "    'Ujae -Public ': 'UJA101',\n",
    "    'Ujae -Public': 'UJA101',\n",
    "    'Ujae -Ujae ': 'UJA101',\n",
    "    'Ujae -Ujae': 'UJA101',\n",
    "    'Ujae-Medium': 'UJA101',\n",
    "    'Ujae-Public ': 'UJA101',\n",
    "    'Ujae-Public': 'UJA101',\n",
    "    'Ujae-Ujae ': 'UJA101',\n",
    "    'Ujae-Ujae': 'UJA101',\n",
    "    'Ujae-Western': 'UJA101',\n",
    "    'Ulien -Arno': 'ARN111',\n",
    "    'Ulien -Public ': 'ARN111',\n",
    "    'Ulien -Public': 'ARN111',\n",
    "    'Ulien-Arno ': 'ARN111',\n",
    "    'Ulien-Arno': 'ARN111',\n",
    "    'Ulien-Arno': 'ARN111',\n",
    "    'Ulien-Eastern': 'ARN111',\n",
    "    'Ulien-Medium': 'ARN111',\n",
    "    'Ulien-Public ': 'ARN111',\n",
    "    'Ulien-Public': 'ARN111',\n",
    "    'Uliga -Majuro': 'MAJ126',\n",
    "    'Uliga Protestant-Private': 'MAJ130',\n",
    "    'Uliga-Majuro': 'MAJ126',\n",
    "    'UPCS-Majuro': 'MAJ130',\n",
    "    'UPCS-Private': 'MAJ130',\n",
    "    'Utrik -Public ': 'UTR101',\n",
    "    'Utrik -Utrik ': 'UTR101',\n",
    "    'Utrik-Medium': 'UTR101',\n",
    "    'Utrik-Northern': 'UTR101',\n",
    "    'Utrik-Public ': 'UTR101',\n",
    "    'Utrik-Public': 'UTR101',\n",
    "    'Utrik-Utrik': 'UTR101',\n",
    "    'Utrik-Utrik': 'UTR101',\n",
    "    'Wodmeej -Wotje': 'WTH102',\n",
    "    'Wodmeej-Northern': 'WTH102',\n",
    "    'Wodmeej-Public ': 'WTH102',\n",
    "    'Wodmeej-Public': 'WTH102',\n",
    "    'Wodmeej-Small': 'WTH102',\n",
    "    'Wodmeej-Wotje ': 'WTH102',\n",
    "    'Wodmeej-Wotje': 'WTH102',\n",
    "    'Wodmeej-Wotje': 'WTH102',\n",
    "    'Wodmej -Public ': 'WTH102',\n",
    "    'Wodmej -Wotje': 'WTH102',\n",
    "    'Wodmej-Public': 'WTH102',\n",
    "    'Woja A -Aelonlaplap': 'AIL108',\n",
    "    'Woja A -Ailinglaplap': 'AIL108',\n",
    "    'Woja A -Public ': 'AIL108',\n",
    "    'Woja A-Aelonlaplap': 'AIL108',\n",
    "    'Woja A-Ailinglaplap': 'AIL108',\n",
    "    'Woja A-Central': 'AIL108',\n",
    "    'Woja A-Medium': 'AIL108',\n",
    "    'Woja A-Public ': 'AIL108',\n",
    "    'Woja A-Public': 'AIL108',\n",
    "    'Woja M -Majuro': 'MAJ127',\n",
    "    'Woja M -Public ': 'MAJ127',\n",
    "    'Woja M-Large': 'MAJ127',\n",
    "    'Woja M-Majuro': 'MAJ127',\n",
    "    'Woja M-Majuro': 'MAJ127',\n",
    "    'Woja M-Private': 'MAJ127',\n",
    "    'Woja M-Public ': 'MAJ127',\n",
    "    'Woja M-Public': 'MAJ127',\n",
    "    'Woja SDA-Private': 'AIL111',\n",
    "    'Woja, A-Ailinglaplap': 'AIL108',\n",
    "    'Wotho-Wotho': 'WOT101',\n",
    "    'Wotje -Wotje ': 'WTH103',\n",
    "    'Wotje -Wotje': 'WTH103',\n",
    "    'Wotje-Large': 'WTH103',\n",
    "    'Wotje-Northern': 'WTH103',\n",
    "    'Wotje-Public ': 'WTH103',\n",
    "    'Wotje-Public': 'WTH103',\n",
    "    'Wotje-Wotje': 'WTH103',\n",
    "    'Wotje-Wotje': 'WTH103',\n",
    "    'Wotto -Wotto ': 'WOT101',\n",
    "    'Wotto-Public ': 'WOT101',\n",
    "    'Wotto-Public': 'WOT101',\n",
    "    'Wotto-Small': 'WOT101',\n",
    "    'Wotto-Western': 'WOT101',\n",
    "    'Wotto-Wotto': 'WOT101'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_exams(df, name, testing=False):\n",
    "    \"\"\" Does any cleanup/validation needed with Exams ID/Name.\n",
    "\n",
    "    Parameters\n",
    "    ----------    \n",
    "    df: DataFrame, required\n",
    "        The student results and enrol DataFrame\n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame)    \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    expected_testid = name.split('_')[1]\n",
    "    \n",
    "    # Basic check of the TestID in the filename\n",
    "    p = re.compile('[A-Z]{1}[0-9]{2}')\n",
    "    if not p.match(expected_testid):\n",
    "        print(\"The TestID is not what was expected. Make sure the excel file {} follows the format AllSchools_TESTID_YYYY-YY_Results.xls\".format(name))\n",
    "    \n",
    "    # Check the TestID in the data is has expected (i.e. what is in the filename)\n",
    "    testid_fromdata = df['TestID'].iloc[0]\n",
    "    if testid_fromdata != expected_testid:\n",
    "        print(\"The TestID in the data is not the same as the expected test ID from the excel filename for {}\".format(name))\n",
    "        \n",
    "    # Check that all the TestID are the same in the data\n",
    "    if len(df['TestID'].unique()) != 1:\n",
    "        print(\"The TestID in the data is not unique and contains unexpected values (e.g. A03 mixed with B03) from the excel filename for {}\".format(name))\n",
    "        \n",
    "    # No actual cleanup at the moment, just flag data validation issues\n",
    "    if testing:\n",
    "        print('Cleaned exams for file {}'.format(name))\n",
    "        #display(df)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "def clean_schools(df, df_schools, name, testing=False):\n",
    "    \"\"\" Does any cleanup/validation needed with SchoolIDs.\n",
    "\n",
    "    Parameters\n",
    "    ----------    \n",
    "    df: DataFrame, required\n",
    "        The student results and enrol DataFrame\n",
    "    df_schools : DataFrame, required\n",
    "        The schools DataFrame (from EMIS)\n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame) \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"        \n",
    "\n",
    "    # From EMIS, get school ID to name official mapping\n",
    "    schools_lookup = df_schools.set_index('schNo').to_dict()['schName']\n",
    "    schools_lookup_byname = df_schools.set_index('schName').to_dict()['schNo']\n",
    "    \n",
    "    # If the Results or Data file contains correct SchoolID can ignore the name mapping\n",
    "    # and just use that to produce the correct SchoolName\n",
    "    # All valid school IDs in the EMIS\n",
    "    school_ids = list(df_schools['schNo'])\n",
    "    \n",
    "    if testing: \n",
    "        print('schools_lookup')\n",
    "        #pp.pprint(dict(schools_lookup))\n",
    "        pp.pprint(dict(itertools.islice(schools_lookup.items(), 3)))\n",
    "        \n",
    "        print('schools_lookup_byname')\n",
    "        #pp.pprint(dict(schools_lookup_byname))\n",
    "        pp.pprint(dict(itertools.islice(schools_lookup_byname.items(), 3)))\n",
    "    \n",
    "    schools_lookup_from_exams = {y:x for x,y in schools_lookup_from_exams_byname.items()}\n",
    "    \n",
    "    if testing:\n",
    "        print('schools_lookup_from_exams_byname')\n",
    "        #pp.pprint(dict(schools_lookup_from_exams_byname))\n",
    "        pp.pprint(dict(itertools.islice(schools_lookup_from_exams_byname.items(), 3)))\n",
    "\n",
    "    # ??? Check if this is primary or elementary, some have same school names so use\n",
    "    # grade of test to define the school\n",
    "\n",
    "    # Create a temporary SchoolName and SchoolIsland joined\n",
    "    df['SchoolNameTemp'] = df.agg('{0[SchoolName]}-{0[IslandName]}'.format, axis=1)\n",
    "    if testing:\n",
    "        print('Cleaning schools SchoolNameTemp')\n",
    "        display(df['SchoolNameTemp'])\n",
    "    \n",
    "    # Upper case all school ID\n",
    "    # Convert to string, Not needed perhaps?\n",
    "    df['SchoolID'] = df['SchoolID'].astype(str)\n",
    "    df['SchoolID'] = df['SchoolID'].str.upper()\n",
    "    # Strip spaces\n",
    "    df['SchoolID'] = df['SchoolID'].str.strip()\n",
    "    \n",
    "    # Check if the school ID in the exams data file exists in the EMIS\n",
    "    # and create temporary school name for those\n",
    "    #s_school_ids1 = df['SchoolID'].map(schools_lookup_byname)\n",
    "    #df = df.assign(SchoolIDTemp1 = s_school_ids1)\n",
    "    mask = df['SchoolID'].isin(df_schools['schNo'].values)\n",
    "    df['SchoolIDTemp1'] = df['SchoolID'].where(mask)\n",
    "    # Check if the school name in the exams data file has a mapping hard coded (old/incorrect schoolIDs)\n",
    "    # and create temporary school name for those\n",
    "    s_school_ids2 = df['SchoolNameTemp'].map(schools_lookup_from_exams_byname)\n",
    "    df = df.assign(SchoolIDTemp2 = s_school_ids2)\n",
    "\n",
    "    if testing:\n",
    "        print('Cleaning schools SchoolIDTemp1')\n",
    "        display(df['SchoolIDTemp1'])\n",
    "        print('Cleaning schools SchoolIDTemp2')\n",
    "        display(df['SchoolIDTemp2'])\n",
    "        \n",
    "    # Coalesce to get the school ID\n",
    "    # Use bfill if I end up using more then two columns to coalesce\n",
    "    # https://stackoverflow.com/questions/38152389/coalesce-values-from-2-columns-into-a-single-column-in-a-pandas-dataframe\n",
    "    df['SchoolIDFinal'] = df.SchoolIDTemp1.combine_first(df.SchoolIDTemp2)\n",
    "    \n",
    "    # An attempt to get all correct School names from EMIS to save trouble of further\n",
    "    # building the hard coded schools_lookup_from_exams_byname\n",
    "    df['SchoolNameFinal'] = df['SchoolIDFinal'].map(schools_lookup)\n",
    "\n",
    "    # If does not have NaNs \n",
    "    #if not df['SchoolNameEMIS'].hasnans:\n",
    "    #    # then we can use SchoolNameEMIS as the new final SchoolName\n",
    "    #    df['SchoolNameFinal'] = df['SchoolIDFinal'].map(schools_lookup)\n",
    "    #else:\n",
    "    #    # Unfortunately need to fix this by hand\n",
    "    #    df['SchoolNameFinal'] = df['SchoolIDFinal'].map(schools_lookup)\n",
    "\n",
    "    # Check if there is a school that does not have a known\n",
    "    # mapping either from the EMIS' df_schools or the manually\n",
    "    # maintained above mapping (old ID, incorrect ones, etc.)\n",
    "    # If True look at the source file\n",
    "    if df['SchoolNameFinal'].isnull().values.any():\n",
    "        print('SchoolID/SchoolName still unknown/check source excel file {}'.format(name)) #df[:1].iloc[:, : 10].to_csv(index=False, header=False)        \n",
    "        \n",
    "        # How to clean the data based on configuration (fix in source data or using hand mapping)\n",
    "        if fix_schoolid_in_source_data:\n",
    "            df_school_name_missing = df[df['SchoolNameFinal'].isna()]\n",
    "            print(\"You have a bad school ID ({}) in your file {}\".format(df_school_name_missing['SchoolID'].unique(), name))\n",
    "        else:\n",
    "            # Unfortunately need to fix this by hand (mostly in RMI)\n",
    "            print('All school name and island name combination not yet part of hard coded mapping (if none listed, they likely have a mapping but school is not yet in EMIS):')\n",
    "            #print('SchoolNameFinal DataFrame with missing values:')\n",
    "            #display(df[df['SchoolNameFinal'].isna()])\n",
    "            unique_combination = set(df['SchoolNameTemp'].unique())\n",
    "            unique_combination_mapped = set(schools_lookup_from_exams_byname.keys())\n",
    "            unique_combination_not_mapped = unique_combination.difference(unique_combination_mapped)\n",
    "            for i in unique_combination_not_mapped:\n",
    "                print(\"'\" + i + \"': '',\")\n",
    "    if testing:\n",
    "        print(\"DataFrame with records with schoolID still unknown in excel file {}.\".format(name))\n",
    "        display(df[df['SchoolNameFinal'].isnull()])\n",
    "    \n",
    "    df = df.drop(['SchoolID','SchoolName','SchoolNameTemp','SchoolIDTemp1','SchoolIDTemp2'], 1)\n",
    "    df = df.rename(columns = {'SchoolIDFinal': 'SchoolID','SchoolNameFinal': 'SchoolName'})\n",
    "\n",
    "    if testing:\n",
    "        print('Cleaned schools DataFrame from file {}.'.format(name))\n",
    "        display(df)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "def clean_items(df, name, testing=False):\n",
    "    \"\"\" Does any cleanup/validation needed with Items (test responses.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, required\n",
    "        The student results and enrol DataFrame with items to clean    \n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame) \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\" \n",
    "\n",
    "    # We need to know what test we are cleaning items for since \n",
    "    # is affects the validation\n",
    "    test = df['TestID'].iloc[1]\n",
    "    \n",
    "    def strip_spaces(i):\n",
    "        if isinstance(i,str):\n",
    "            return i.strip()\n",
    "        else:\n",
    "            return i\n",
    "    \n",
    "    def validate_answer(i):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        validate if the item answer is correct (i.e. It is either 'A', 'B', 'C', 'D' or 'BLANK')\n",
    "        For high school test the last item column can also be a numeric.\n",
    "\n",
    "        Args:\n",
    "            i (Object): item to be validated\n",
    "\n",
    "        Returns:\n",
    "            True if item is valid\n",
    "            False if false is not valid\n",
    "        \"\"\"\n",
    "        if i == 'A' or i == 'B' or i == 'C' or i == 'D' or i == 'BLANK' or i == 'MULT':        \n",
    "            return True\n",
    "        elif test == 'H08': #and isinstance(i, float):\n",
    "            # Numbers can come in as string, in particular when the\n",
    "            # Series contains some error (i.e. 1` instead of 1)\n",
    "            # So we test for numeric by attempting a cast\n",
    "            try:\n",
    "                float(i)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def simplify_items(x):\n",
    "        \"\"\" If column an item make it uppercase and strip the redundant string\n",
    "        \"\"\"\n",
    "        if x.startswith('Item_'):  \n",
    "            if remove_items_metadata:\n",
    "                item = '_'.join(x.split('_', 2)[:2])\n",
    "            else:\n",
    "                item = '_'.join(x.split('_', 2))\n",
    "            return str.upper(item)\n",
    "        return x \n",
    "          \n",
    "    # Re-arrange and rename item columns\n",
    "    df = df.rename(columns = simplify_items)\n",
    "    \n",
    "    # Get list of items columns\n",
    "    cols = df.columns[df.columns.str.startswith('ITEM_')].tolist()\n",
    "    if testing: \n",
    "        print('Cleaned items columns:', cols)\n",
    "        print('Cleaned items columns length:', len(cols))        \n",
    "        print('Cleaned items Item-only DataFrame.columns length:', len(df[cols].columns))\n",
    "        print('Cleaned items Item-only DataFrame.columns')\n",
    "        display(df[cols].columns)\n",
    "    \n",
    "    # Strip out any spaces from all ITEMS\n",
    "    try:\n",
    "        df[cols] = df[cols].applymap(strip_spaces)\n",
    "    except:\n",
    "        print('Detected a mismatch in item numbers (e.g. repeating Item_039, Item_039, etc.) in excel file {}'.format(name))\n",
    "    \n",
    "    try:\n",
    "        # Remove all multiple answers (all the time?). Answers like (A,C), A&B, etc.\n",
    "        df[cols] = df[cols].replace(to_replace='\\({0,1}[A-D](,|&).*\\){0,1}', value='MULT', regex=True)\n",
    "    \n",
    "        # Insert string 'BLANK' where na\n",
    "        df[cols] = df[cols].fillna('BLANK')\n",
    "        \n",
    "        # Insert string 'BLANK' where there is whitespace character(s)\n",
    "        df[cols] = df[cols].replace(to_replace='^\\s+&', value='BLANK', regex=True)\n",
    "        \n",
    "        # Insert string 'BLANK' where there is an empty string like ''\n",
    "        df[cols] = df[cols].replace(to_replace='', value='BLANK', regex=False)\n",
    "    except ValueError as e:\n",
    "        cols1 = len(cols)\n",
    "        cols2 = len(df[cols].columns)\n",
    "        print('Cleaned items possible duplicate item. Columns starting with ITEM_ is {} while DataFrame columsn is {} (hint from data): '.format(cols1, cols2),\n",
    "              df[:1].iloc[:, : 10].to_csv(index=False, header=False))\n",
    "        print('Error was: ', e)\n",
    "    \n",
    "    df[cols].apply(lambda x: x.astype(str).str.upper())\n",
    "    \n",
    "    # Finally, validate the answer for all the items.\n",
    "    #cols2 = list(cols)    \n",
    "\n",
    "    if test == 'H08':\n",
    "        h08_cols = list(cols)\n",
    "        # High School so need to do two runs\n",
    "        # One for the final item which has numeric values\n",
    "        last_col = h08_cols.pop()            \n",
    "        df_last_col_mask = df[[last_col]].applymap(validate_answer)\n",
    "\n",
    "        # Two for all standard multiple choice questions    \n",
    "        df_standard_mask = df[h08_cols].applymap(validate_answer)\n",
    "        \n",
    "        if testing:\n",
    "            print(\"last_col: \", last_col)            \n",
    "            print(\"h08_cols: \", h08_cols)\n",
    "            display(df[[last_col]].applymap(validate_answer))\n",
    "            display(df[[last_col]].applymap(validate_answer).all().all())\n",
    "            display(df[h08_cols].applymap(validate_answer))\n",
    "            display(df[h08_cols].applymap(validate_answer).all().all())\n",
    "        \n",
    "        if not (df_last_col_mask.all().all() and df_standard_mask.all().all()):\n",
    "            \n",
    "            # Collect invalid items to return very specific feedback\n",
    "            invalid_items = []\n",
    "            for c in h08_cols: # errors in standard columns\n",
    "                if len(df_standard_mask[~df_standard_mask[c]].index.values) != 0:\n",
    "                    invalid_items.append(c+\" rows: \"+str(df_standard_mask[~df_standard_mask[c]].index.values + 2))\n",
    "                    \n",
    "            if len(df_last_col_mask[~df_last_col_mask[last_col]].index.values) != 0: # errors in last columns\n",
    "                invalid_items.append(last_col+\" rows: \"+str(df_last_col_mask[~df_last_col_mask[last_col]].index.values + 2))\n",
    "            \n",
    "            if not skip_incorrect_answers:\n",
    "                print('Invalid answers detected in test {} (note: supposedly a High School test) year {} (from excel file {}). Invalid answers are in {}'.format(\n",
    "                    df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name, str(invalid_items)))\n",
    "\n",
    "    else:\n",
    "        # Any other test (i.e. not High School)\n",
    "        df_standard_mask = df[cols].applymap(validate_answer)\n",
    "        #display(df[cols].applymap(validate_answer))\n",
    "        if not df_standard_mask.all().all():\n",
    "            \n",
    "            # Collect invalid items to return very specific feedback\n",
    "            invalid_items = []\n",
    "            for c in cols: # errors in all columns\n",
    "                if len(df_standard_mask[~df_standard_mask[c]].index.values) != 0:\n",
    "                    invalid_items.append(c+\" rows: \"+str(df_standard_mask[~df_standard_mask[c]].index.values + 2))\n",
    "            \n",
    "            if not skip_incorrect_answers:\n",
    "                print('Invalid answers detected in test {} year {} (from excel file {}). Invalid answers are in {}'.format(\n",
    "                    df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name, str(invalid_items)))\n",
    "            \n",
    "    if testing:\n",
    "        print('Cleaned items DataFrame from file {}.'.format(name))\n",
    "        display(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_students(df, name, testing=False):\n",
    "    \"\"\" Cleanup students data here. There is stuff from other functions like in the merge\n",
    "    above that could be put more cleanly here.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, required\n",
    "        The student results and enrol DataFrame\n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame) \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    genders = {\n",
    "        'Male': 'M',\n",
    "        'MALE': 'M',\n",
    "        'm': 'M',       \n",
    "        'M': 'M',       \n",
    "        'M,': 'M',\n",
    "        'M ': 'M',\n",
    "        'Boy': 'M',\n",
    "        'BOY': 'M',\n",
    "        'b': 'M',        \n",
    "        'B': 'M',\n",
    "        'n': 'M',\n",
    "        'mm': 'M',\n",
    "        'MM': 'M',\n",
    "        'FM': 'M',        \n",
    "        'm  m': 'M',\n",
    "        'Bm': 'M',\n",
    "        'Female': 'F',        \n",
    "        'FEMALE': 'F',\n",
    "        'f': 'F',       \n",
    "        'F': 'F',\n",
    "        'Girl': 'F',        \n",
    "        'GIRL': 'F',\n",
    "        'g': 'F',        \n",
    "        'G': 'F',\n",
    "        #'I': 'F',\n",
    "        '`f': 'F',\n",
    "        'FF': 'F',\n",
    "        'ff': 'F',\n",
    "        #'?': 'M',\n",
    "        #'??': 'M',\n",
    "        #'???': 'M',\n",
    "        #'????': 'M',\n",
    "        #'BLANK': 'M',\n",
    "        #'a': 'F',\n",
    "        #'A': 'F',\n",
    "        'BLANKm': 'M',\n",
    "        #',': 'M',\n",
    "        #'ERROR #3100': 'M',\n",
    "        #'**': 'M',\n",
    "    }\n",
    "    \n",
    "    yesno = {\n",
    "        'Yes': 'Yes',        \n",
    "        'YEs': 'Yes',\n",
    "        'YES': 'Yes',        \n",
    "        'yes': 'Yes',\n",
    "        'y': 'No',\n",
    "        'No': 'No',        \n",
    "        'NO': 'No',\n",
    "        'no': 'No',        \n",
    "        'n': 'No',\n",
    "    }\n",
    "\n",
    "    # Adjust the correct student ID where possible and generate UUID for all others\n",
    "    \n",
    "    # At this point student ID already there come from the EMIS\n",
    "    # Perhaps it might be useful to build a list of automatically assigned\n",
    "    # UUIDs as they get processed and look there as well?!\n",
    "    missing_student_id_tot = df['stuCardID'].isna().sum()\n",
    "    missing_student_ids = []\n",
    "\n",
    "    for i in range(missing_student_id_tot):\n",
    "        missing_student_ids.append(uuid.UUID(int=rd.getrandbits(128), version=4))\n",
    "\n",
    "    df.loc[df.stuCardID.isnull(), 'stuCardID'] = missing_student_ids    \n",
    "        \n",
    "    # Coalesce student genders\n",
    "    df['GenderFinal'] = df.stuGender.combine_first(df.Gender)\n",
    "    \n",
    "    # Clean genders (should we also flag?)\n",
    "    df['GenderFinal'] = df['GenderFinal'].str.strip() # strip out leading/trailing spaces\n",
    "    df['GenderFinal'] = df['GenderFinal'].map(genders)\n",
    "    # Tell me if the DataFrame has any unkown gender\n",
    "    df_badgenders = df_onlinesba[~df_onlinesba['Gender'].isin(list(genders.keys()))]\n",
    "    \n",
    "    if not df_badgenders.empty:\n",
    "        if accept_unknown_gender:\n",
    "            # Accept but \"fix\" the bad gender (is there anything to fix?)\n",
    "            pass\n",
    "        else:\n",
    "            print('Some unknown gender detected (these ones: {}) detected in test {} year {} (from excel file {})'.format(\n",
    "                set(df_badgenders['Gender'].unique()), df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "        if testing:\n",
    "            print('These records have bad genders')\n",
    "            display(df[df['GenderFinal'].isna()])\n",
    "    \n",
    "    # Clean some boolean (should we flag?)\n",
    "    df['SpEdCode'] = df['SpEdCode'].map(yesno)\n",
    "    df['SpEdCode'].fillna(value='No', inplace=True) # default to most common value\n",
    "    df['Accommodation'] = df['Accommodation'].map(yesno)\n",
    "    df['Accommodation'].fillna(value='No', inplace=True) # default to most common value\n",
    "    \n",
    "    # Student names with * or ??? to be flagged and/or handled\n",
    "    if df['StudentName'].str.contains('^ *\\?+ *$', na=False, regex=True).any() and not accept_unknown_student:\n",
    "        print('Student name with ??? (unknown/bad student name) detected in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "        \n",
    "    df['StudentName'] = df['StudentName'].replace(to_replace=r'^ *\\?+ *$', value=np.NaN, regex=True)\n",
    "    \n",
    "    # Student NaN\n",
    "    if df['StudentName'].isnull().values.any() and not accept_unknown_student:\n",
    "        print('Student name without any value (no student name) detected in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "        if testing:\n",
    "            display(df.loc[df['StudentName'].isnull()])\n",
    "    \n",
    "    # Replace all unknown with 'Unknown student 1', 'Unknown student 2', etc.\n",
    "    #df['StudentName'].fillna(value='Unknown', inplace=True)\n",
    "    mask = df['StudentName'].isna()\n",
    "    values = [f'Unknown student {x}' for x in range(1, mask.sum()+1)]        \n",
    "    df.loc[mask, 'StudentName'] = values\n",
    "    \n",
    "    # Student names repeating\n",
    "    \n",
    "    if testing:\n",
    "        print('Cleaned students DataFrame from file {}.'.format(name))\n",
    "        display(df)\n",
    "    \n",
    "    df = df.drop(['Gender'], 1)\n",
    "    df = df.rename(columns = {'GenderFinal': 'Gender'})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def clean_teachers(df, name, testing=False):\n",
    "    \"\"\" Mostly a placeholder at the moment. But might be desirable to cleanup\n",
    "    teachers, add teacher ID, etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, required\n",
    "        The student results (contains teachers) and enrol DataFrame\n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame) \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Teachers containing numbers instead of names\n",
    "    if pd.to_numeric(df_onlinesba['Teacher'], errors='coerce').any():\n",
    "        print('Teacher with numeric values detected in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "    # Clean it. The cleaning here is temporary and only so the remaining code works\n",
    "    # this should really cleaned up in source data\n",
    "    df['Teacher'] = df['Teacher'].astype('string')\n",
    "    \n",
    "    # Fill missing teachers\n",
    "    df['Teacher'].fillna(value='N/A', inplace=True)\n",
    "    \n",
    "    # Teachers names with ??? (Flag it)\n",
    "    if df['Teacher'].str.contains(' *\\?+ *', na=False, regex=True).any() and not accept_unknown_teacher:\n",
    "        print('Teacher with ?? as names detected in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "    # Clean it\n",
    "    df['Teacher'] = df['Teacher'].replace(to_replace=' *\\?+ *', value='Unknown', regex=True)\n",
    "    \n",
    "    # Teachers names with less then 3 alphanumeric charactors (Flag it)\n",
    "    if df['Teacher'].str.contains('^\\w{1,3}$', na=False, regex=True).any() and accept_teachers_with_three_chars_only:        \n",
    "        print('Teacher names with 3 characters or less detected (valid name?) in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "    # Clean it ?\n",
    "    #df['Teacher'] = df['Teacher'].replace(to_replace='\\w{1,3}', value='Unknown', regex=True)\n",
    "    \n",
    "    # Teachers without names\n",
    "    if df['Teacher'].str.contains('^\\s+$', na=False, regex=True).any() and df['Teacher'].hasnans and not accept_unknown_teacher:\n",
    "        print('Teacher without names detected in test {} year {} (from excel file {})'.format(\n",
    "            df['TestName'].iloc[0], df['SchoolYear'].iloc[0], name))\n",
    "    # Clean it\n",
    "    df['Teacher'] = df['Teacher'].replace(to_replace='^\\s+$', value='Unknown', regex=True)\n",
    "    \n",
    "    if testing:\n",
    "        print('Cleaned teachers DataFrame from file'.format(name))\n",
    "        display(df)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def convert_to_onlinesba(df, name, testing=False):\n",
    "    \"\"\" A pretty fat function that does some validation, cleaning and converting\n",
    "    to the OnlineSBA format. Function can be split if needed as this tools gets refine\n",
    "    through practicalities of real life usage\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, required\n",
    "        The student results and enrol DataFrame\n",
    "    name: str, required\n",
    "        The name of the excel file this DataFrame came from\n",
    "    testing: bool, required\n",
    "        Whether we are test (usually single DataFrame) \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        Could raise unknown error. Implement if it happens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.rename(columns = {\n",
    "        'stuCardID': 'STUDENTID', \n",
    "        'SpEdCode': 'SPED',\n",
    "        'Accommodation': 'ACCOM',\n",
    "        'StudentName': 'STUDENTNAME',\n",
    "        'SchoolID': 'SCHOOLID',\n",
    "        'Gender': 'GENDER',\n",
    "        'TestID': 'TESTID',\n",
    "        'Teacher': 'TEACHERNAME',\n",
    "        'SchoolYear': 'SCHOOLYEAR'\n",
    "        })\n",
    "    df = df.drop([\n",
    "        'RecordNo', 'TestName', 'IslandName', # 'SchoolYear',\n",
    "        'SchoolName', 'StudentID', 'Ethnicity', 'Disability', \n",
    "        'ELL', 'Migrant', 'FRLunch', 'StudentName2', 'Student',\n",
    "        'stuGender', 'stuDoB', 'schNo', 'stueYear', 'Student2'], 1, errors='ignore')\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    cols_items = [i for i in cols if 'ITEM_' in i]\n",
    "    cols_items.sort()\n",
    "\n",
    "    # Re-order. First set of colums will likely always be there and the same\n",
    "    # followed by a varying number of exam items\n",
    "    df = df[[\n",
    "        'SCHOOLYEAR','STUDENTID','SPED','ACCOM','STUDENTNAME','SCHOOLID','GENDER','TESTID',\n",
    "        'TEACHERNAME'] + cols_items]\n",
    "    \n",
    "    if testing:\n",
    "        print('Final OnlineSBA DataFrame for data from file {}.'.format(name))\n",
    "        display(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup DataFrame as OnlineSBA input format\n",
    "# Working with the single student exams file (for testing)\n",
    "df_onlinesba = clean_exams(df_students_results_and_enrol[testname], testname, testing=True)\n",
    "df_onlinesba = clean_schools(df_onlinesba, df_schools, testname, testing=True)\n",
    "df_onlinesba = clean_items(df_onlinesba, testname, testing=True)\n",
    "df_onlinesba = clean_students(df_onlinesba, testname, testing=True)\n",
    "df_onlinesba = clean_teachers(df_onlinesba, testname, testing=True)\n",
    "df_onlinesba = convert_to_onlinesba(df_onlinesba, testname, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cleanup DataFrame as OnlineSBA input format\n",
    "# Working with all student exams files (~17 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "df_onlinesba_dict = {}\n",
    "\n",
    "print('Processing exams data from excel files...')\n",
    "\n",
    "for file, df in tqdm(df_students_results_and_enrol_list.items()):\n",
    "    #tqdm.write('Processing exam ID {} for year {} from excel file {}'.format(df['TestID'].values[0], df['SchoolYear'].values[0], file))\n",
    "    df_onlinesba = clean_exams(df_students_results_and_enrol_list[file], file, testing=False)\n",
    "    df_onlinesba = clean_schools(df_onlinesba, df_schools, file, testing=False)\n",
    "    df_onlinesba = clean_items(df_onlinesba, file, testing=False)\n",
    "    df_onlinesba = clean_students(df_onlinesba, file, testing=False)\n",
    "    df_onlinesba = clean_teachers(df_onlinesba, file, testing=False)\n",
    "    df_onlinesba = convert_to_onlinesba(df_onlinesba, file, testing=False)\n",
    "    df_onlinesba_dict[file] = df_onlinesba\n",
    "\n",
    "len(df_onlinesba_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write processed data back into excel (or CSV directly)\n",
    "# Working with the single student exams file (for testing)\n",
    "\n",
    "data_xls = 'data/'+country+'/onlinesba-test.xlsx'\n",
    "data_csv = 'data/'+country+'/onlinesba-test.csv'\n",
    "filename_xls = os.path.join(cwd, data_xls)\n",
    "filename_csv = os.path.join(cwd, data_csv)\n",
    "\n",
    "with pd.ExcelWriter(filename_xls) as writer:\n",
    "    # add DataFrames you want to write to Excel here\n",
    "    df_onlinesba.to_excel(writer, index=False, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "df_onlinesba.to_csv(filename_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(list(df_onlinesba_dict.keys()))\n",
    "df_onlinesba_dict[list(df_onlinesba_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onlinesba_dict['AllSchools_A03_2008-09_Results.xls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Write processed data back into excel (or CSV directly much faster)\n",
    "# Working with all student exams files (~1min 52sec on iMac with i9 CPU and 32GB RAM for Excel, 2sec for CSV)\n",
    "from openpyxl import Workbook\n",
    "\n",
    "for file, df in tqdm(df_onlinesba_dict.items()):\n",
    "    schoolyear = df['SCHOOLYEAR'].values[0]\n",
    "    testid = df['TESTID'].values[0]\n",
    "    try:\n",
    "        # Could remove the SCHOOLYEAR if onlinesba really requires it\n",
    "        if export == 'csv':        \n",
    "            exam = 'data/'+country+'/onlinesba-load-files-csv/' + schoolyear + '-' + testid + '.csv'\n",
    "            filename = os.path.join(cwd, exam)\n",
    "            df.to_csv(exam, index=False)\n",
    "        else:\n",
    "            exam = 'data/'+country+'/onlinesba-load-files-xls/' + schoolyear + '-' + testid + '.xlsx'        \n",
    "            filename = os.path.join(cwd, exam)            \n",
    "            with pd.ExcelWriter(filename) as writer:\n",
    "                # add DataFrames you want to write to Excel here\n",
    "                df.to_excel(writer, index=False, sheet_name='Sheet1', engine='openpyxl')\n",
    "                # The excel version is used to load into FedEMIS and currently requires\n",
    "                # a Sheet 'ExamYear' to indicate the year in cell A1                \n",
    "                #tqdm.write(type(writer))\n",
    "                wb = writer.book\n",
    "                ws = wb.create_sheet(title='ExamYear')\n",
    "                ws['A1'] = '20'+schoolyear.split('-')[1]\n",
    "                \n",
    "        #tqdm.write('Writing file {}'.format(filename))\n",
    "    except TypeError:\n",
    "        tqdm.write('Problem with a type, cannot generate filename {}'.format(filename))\n",
    "    except Exception as e:\n",
    "        tqdm.write('Unknown error {} with file {}'.format(e, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact matches (i.e. exact name in exams data and the EMIS)\n",
    "# Working with the single student exams file (for testing)\n",
    "df_students_results_and_enrol_example = df_students_results_and_enrol[list(df_students_results_and_enrol.keys())[0]]\n",
    "df_exact_matches = df_students_results_and_enrol_example.dropna(how='all', subset=['stuCardID']) #subset=['stuCardID', 'stuGender', 'stuDoB', 'schNo', 'stueYear'])\n",
    "display(df_exact_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the exact matches (i.e. exact name in exams data and the EMIS)\n",
    "# Working with all student exams files (~23 seconds on iMac with i9 CPU and 32GB RAM)\n",
    "df_exact_matches_list = []\n",
    "for file, df in df_students_results_and_enrol_list.items():\n",
    "    df_exact_matches_list.append(df.dropna(how='all', subset=['stuCardID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# WARNING: Not currently running as df_student_enrol_nonambiguous is no longer globally defined\n",
    "# Commenting this out if ever needed\n",
    "\n",
    "# Just included for playing around. Not currently being used, just working with exact matches for now\n",
    "\n",
    "# Here we will get a bit more sophisticated in trying to match students to get their EMIS\n",
    "# canonical data (DoB, ID, etc.)\n",
    "# Instead of doing a simple name matching we will do fuzy search using the Levenshtein algorithm\n",
    "# That way we will capture students with slightly different name spellings\n",
    "\n",
    "# Is this time consuming search worth it?!\n",
    "\n",
    "#import fuzzy_pandas as fpd\n",
    "\n",
    "#exams_cols = list(set(df_student_results.columns))\n",
    "#stuen_cols = list(set(df_student_enrol_nonambiguous.columns))\n",
    "\n",
    "# the threshold is set high so we may not capture students with terribly\n",
    "# bad spellings but will capture things with only small mis-spelling\n",
    "# and reduce chances of false positive matching\n",
    "#df_fuzzy_matches = fpd.fuzzy_merge(\n",
    "#    df_student_results, df_student_enrol_nonambiguous,\n",
    "#    left_on=['StudentName2'], right_on=['Student2'],\n",
    "#    #keep='all',\n",
    "#    method='levenshtein',\n",
    "#    threshold=0.94, #0.9\n",
    "#    ignore_case=True,\n",
    "#    ignore_nonalpha=False,\n",
    "#    ignore_nonlatin=False,\n",
    "#    ignore_order_words=False,\n",
    "#    ignore_order_letters=False,\n",
    "#    ignore_titles=False,\n",
    "#    join='left-outer' # { 'inner', 'left-outer', 'right-outer', 'full-outer' }\n",
    "#)\n",
    "\n",
    "#df_fuzzy_matches\n",
    "\n",
    "#s = df_fuzzy_matches['stuCardID'] == ''\n",
    "#s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write various DataFrame into Excel to examine (testing)\n",
    "filename = os.path.join(cwd, 'data/'+country+'/soe-to-online-test.xlsx')\n",
    "\n",
    "df_student_results_example = df_student_results[list(df_student_results.keys())[0]]\n",
    "df_students_results_and_enrol_example = df_students_results_and_enrol[list(df_students_results_and_enrol.keys())[0]]\n",
    "\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    # add DataFrames you want to write to Excel here\n",
    "    df_student_results_example.to_excel(writer, index=False, sheet_name='Sheet1', engine='openpyxl')\n",
    "    df_students_results_and_enrol_example.to_excel(writer, index=False, sheet_name='Sheet2', engine='openpyxl')\n",
    "    #df_fuzzy_matches.to_excel(writer, index=False, sheet_name='Sheet3', engine='openpyxl')\n",
    "    df_onlinesba.to_excel(writer, index=False, sheet_name='Sheet4', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
